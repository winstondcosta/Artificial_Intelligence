{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ef63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")#en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac26cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "This is one of the greatest films ever made. Brilliant acting by George C. Scott and Diane Riggs. \n",
    "This movie is both disturbing and extremely deep. Don't be fooled into believing this is just a comedy. \n",
    "It is a brilliant satire about the medical profession. It is not a pretty picture.\n",
    " Healthy patients are killed by incompetent surgeons, who spend all their time making money outside the hospital. \n",
    " And yet, you really believe that this is a hospital. \n",
    " The producers were very careful to include real medical terminology and real medical cases. \n",
    " This movie really reveals how difficult in is to run a hospital, and how badly things already were in 1971. \n",
    " I loved this movie. P.S. - I noticed that the incompetent, wheeler dealer surgeon played the head of the firm in \n",
    " LA Law. The young doctor played in Lou Grant. \n",
    " I also noticed that the registration nurse has appeared since in Becker and other shows.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a12fad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '_bulk_merge', '_context', '_get_array_attrs', '_realloc', '_vector', '_vector_norm', 'cats', 'char_span', 'copy', 'count_by', 'doc', 'ents', 'extend_tensor', 'from_array', 'from_bytes', 'from_dict', 'from_disk', 'from_docs', 'from_json', 'get_extension', 'get_lca_matrix', 'has_annotation', 'has_extension', 'has_unknown_spaces', 'has_vector', 'is_nered', 'is_parsed', 'is_sentenced', 'is_tagged', 'lang', 'lang_', 'mem', 'noun_chunks', 'noun_chunks_iterator', 'remove_extension', 'retokenize', 'sentiment', 'sents', 'set_ents', 'set_extension', 'similarity', 'spans', 'tensor', 'text', 'text_with_ws', 'to_array', 'to_bytes', 'to_dict', 'to_disk', 'to_json', 'to_utf8_array', 'user_data', 'user_hooks', 'user_span_hooks', 'user_token_hooks', 'vector', 'vector_norm', 'vocab']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)  # tagger, parser, NER\n",
    "print(dir(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3171f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT            | LEMMA_          | POS_     | TAG_     | DEP_        | SHAPE_   | IS_ALPHA | IS_STOP  | \n",
      "This            | this            | PRON     | DT       | nsubj       | Xxxx     |        1 |        1 |\n",
      "is              | be              | AUX      | VBZ      | ROOT        | xx       |        1 |        1 |\n",
      "one             | one             | NUM      | CD       | attr        | xxx      |        1 |        1 |\n",
      "of              | of              | ADP      | IN       | prep        | xx       |        1 |        1 |\n",
      "the             | the             | DET      | DT       | det         | xxx      |        1 |        1 |\n",
      "greatest        | great           | ADJ      | JJS      | amod        | xxxx     |        1 |        0 |\n",
      "movie           | movie           | NOUN     | NN       | pobj        | xxxx     |        1 |        0 |\n",
      ".               | .               | PUNCT    | .        | punct       | .        |        0 |        0 |\n",
      "I               | I               | PRON     | PRP      | nsubj       | X        |        1 |        1 |\n",
      "loved           | love            | VERB     | VBD      | ROOT        | xxxx     |        1 |        0 |\n",
      "It              | it              | PRON     | PRP      | dobj        | Xx       |        1 |        1 |\n"
     ]
    }
   ],
   "source": [
    "text = \"This is one of the greatest movie. I loved It\"\n",
    "doc = nlp(text)\n",
    "print('{:15} | {:15} | {:8} | {:8} | {:11} | {:8} | {:8} | {:8} | '.format('TEXT','LEMMA_','POS_','TAG_','DEP_','SHAPE_','IS_ALPHA','IS_STOP'))\n",
    "\n",
    "for token in doc:\n",
    "  print('{:15} | {:15} | {:8} | {:8} | {:11} | {:8} | {:8} | {:8} |'.format(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1fbc12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.tag_ == \"VBZ\":\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dedf5937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct object'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"dobj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68483eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL:  GPE WORD India\n"
     ]
    }
   ],
   "source": [
    "ner_text = \"I love my country India, and I love Machine learning\"\n",
    "ner_doc = nlp(ner_text)\n",
    "for token in ner_doc.ents:\n",
    "    print(\"LABEL: \",token.label_,\"WORD\",token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46014f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"GPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd858764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I love my country \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", and I love Machine learning</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(docs=ner_doc, style=\"ent\", jupyter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
