{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d94974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f019150",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
    "                                transforms.Resize(224),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d561e7",
   "metadata": {},
   "source": [
    "### Standard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc74137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root=\"cifar10\", download=False, train=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root=\"cifar10\", download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d601280a",
   "metadata": {},
   "source": [
    "### Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee28f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.ImageFolder(\"/home/dell/Python_Files/Celebrities/training_set\",transform=transform)\n",
    "testset = datasets.ImageFolder(\"/home/dell/Python_Files/Celebrities/test_set\",transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02fdf18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = 0.2\n",
    "num_train = len(trainset)\n",
    "indices = [i for i in range(num_train)]\n",
    "num_val = int(split_size * num_train)\n",
    "train_idx, valid_idx = indices[num_val:], indices[:num_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9ef77a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e55a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataLoader(trainset, batch_size=10, sampler=train_sampler)\n",
    "val_generator = DataLoader(trainset, batch_size=5, sampler=valid_sampler)\n",
    "test_generator = DataLoader(testset, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a67a47c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 224, 224])\n",
      "tensor([4, 3, 4, 4, 4, 3, 4, 4, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "dataiterator = iter(train_generator)\n",
    "images, labels = next(dataiterator)\n",
    "print(images.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a5891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(16,16,3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(16,32,3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(64,128,3,padding=1)\n",
    "            \n",
    "        self.pool = nn.MaxPool2d((2,2))\n",
    "            \n",
    "        self.hidden1 = nn.Linear(7*7*128, 128)\n",
    "        self.hidden2 = nn.Linear(128, 256)\n",
    "        self.hidden3 = nn.Linear(256, 512)\n",
    "        self.output = nn.Linear(512,5)\n",
    "            \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool(x)\n",
    "            \n",
    "        x = x.view(-1, 7*7*128)\n",
    "            \n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b17336ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Using cached torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90cc5d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Conv2d: 1-1                            448\n",
      "├─Conv2d: 1-2                            2,320\n",
      "├─Conv2d: 1-3                            4,640\n",
      "├─Conv2d: 1-4                            18,496\n",
      "├─Conv2d: 1-5                            73,856\n",
      "├─MaxPool2d: 1-6                         --\n",
      "├─Linear: 1-7                            802,944\n",
      "├─Linear: 1-8                            33,024\n",
      "├─Linear: 1-9                            131,584\n",
      "├─Linear: 1-10                           2,565\n",
      "├─Dropout: 1-11                          --\n",
      "=================================================================\n",
      "Total params: 1,069,877\n",
      "Trainable params: 1,069,877\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Conv2d: 1-1                            448\n",
       "├─Conv2d: 1-2                            2,320\n",
       "├─Conv2d: 1-3                            4,640\n",
       "├─Conv2d: 1-4                            18,496\n",
       "├─Conv2d: 1-5                            73,856\n",
       "├─MaxPool2d: 1-6                         --\n",
       "├─Linear: 1-7                            802,944\n",
       "├─Linear: 1-8                            33,024\n",
       "├─Linear: 1-9                            131,584\n",
       "├─Linear: 1-10                           2,565\n",
       "├─Dropout: 1-11                          --\n",
       "=================================================================\n",
       "Total params: 1,069,877\n",
       "Trainable params: 1,069,877\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = Classifier()\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3a7022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "589ed637",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f050064a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.995614647865295\n",
      "43.66772413253784\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for i in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    model.train()\n",
    "    for images, labels in train_generator:\n",
    "        #print(images)\n",
    "        #print(labels)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(images)\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(loss.item())\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "        #print(train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    for images, labels in val_generator:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(images)\n",
    "        loss = criterion(pred, labels)\n",
    "        val_loss += loss.item()*images.size(0)\n",
    "        #print(val_loss)\n",
    "#print(len(train_generator))\n",
    "#print(len(val_generator))\n",
    "train_loss = train_loss/len(train_generator)\n",
    "val_loss = val_loss/len(val_generator)\n",
    "print(train_loss)\n",
    "print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22782d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1])\n",
      "tensor([2, 2, 2, 2, 2])\n",
      "tensor([3, 3, 3, 3, 3])\n",
      "tensor([4, 4, 4, 4, 4])\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = 0.0\n",
    "for images, labels in test_generator:\n",
    "    output = model(images)\n",
    "    #print(output)\n",
    "    _, pred = torch.max(output,1)\n",
    "    #print(_)\n",
    "    #print(pred)\n",
    "    #print(list(pred))\n",
    "    print(labels)\n",
    "    num_correct = 0\n",
    "    accuracy = 0.0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i]==labels[i]:\n",
    "            num_correct+=1\n",
    "    accuracy = (num_correct/images.size(0))*100\n",
    "    #print(accuracy)\n",
    "    test_accuracy += accuracy\n",
    "#print(test_accuracy)\n",
    "print(test_accuracy/len(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378e37d9",
   "metadata": {},
   "source": [
    "### Saving and Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fca2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"celebrity_pytorch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eef1aa4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"celebrity_pytorch.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7840dcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Conv2d: 1-1                            448\n",
      "├─Conv2d: 1-2                            2,320\n",
      "├─Conv2d: 1-3                            4,640\n",
      "├─Conv2d: 1-4                            18,496\n",
      "├─Conv2d: 1-5                            73,856\n",
      "├─MaxPool2d: 1-6                         --\n",
      "├─Linear: 1-7                            802,944\n",
      "├─Linear: 1-8                            33,024\n",
      "├─Linear: 1-9                            131,584\n",
      "├─Linear: 1-10                           2,565\n",
      "├─Dropout: 1-11                          --\n",
      "=================================================================\n",
      "Total params: 1,069,877\n",
      "Trainable params: 1,069,877\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Conv2d: 1-1                            448\n",
       "├─Conv2d: 1-2                            2,320\n",
       "├─Conv2d: 1-3                            4,640\n",
       "├─Conv2d: 1-4                            18,496\n",
       "├─Conv2d: 1-5                            73,856\n",
       "├─MaxPool2d: 1-6                         --\n",
       "├─Linear: 1-7                            802,944\n",
       "├─Linear: 1-8                            33,024\n",
       "├─Linear: 1-9                            131,584\n",
       "├─Linear: 1-10                           2,565\n",
       "├─Dropout: 1-11                          --\n",
       "=================================================================\n",
       "Total params: 1,069,877\n",
       "Trainable params: 1,069,877\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3703cab6",
   "metadata": {},
   "source": [
    "### Pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ded586a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       1,792\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─Conv2d: 2-3                       36,928\n",
      "|    └─ReLU: 2-4                         --\n",
      "|    └─MaxPool2d: 2-5                    --\n",
      "|    └─Conv2d: 2-6                       73,856\n",
      "|    └─ReLU: 2-7                         --\n",
      "|    └─Conv2d: 2-8                       147,584\n",
      "|    └─ReLU: 2-9                         --\n",
      "|    └─MaxPool2d: 2-10                   --\n",
      "|    └─Conv2d: 2-11                      295,168\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─Conv2d: 2-13                      590,080\n",
      "|    └─ReLU: 2-14                        --\n",
      "|    └─Conv2d: 2-15                      590,080\n",
      "|    └─ReLU: 2-16                        --\n",
      "|    └─MaxPool2d: 2-17                   --\n",
      "|    └─Conv2d: 2-18                      1,180,160\n",
      "|    └─ReLU: 2-19                        --\n",
      "|    └─Conv2d: 2-20                      2,359,808\n",
      "|    └─ReLU: 2-21                        --\n",
      "|    └─Conv2d: 2-22                      2,359,808\n",
      "|    └─ReLU: 2-23                        --\n",
      "|    └─MaxPool2d: 2-24                   --\n",
      "|    └─Conv2d: 2-25                      2,359,808\n",
      "|    └─ReLU: 2-26                        --\n",
      "|    └─Conv2d: 2-27                      2,359,808\n",
      "|    └─ReLU: 2-28                        --\n",
      "|    └─Conv2d: 2-29                      2,359,808\n",
      "|    └─ReLU: 2-30                        --\n",
      "|    └─MaxPool2d: 2-31                   --\n",
      "├─AdaptiveAvgPool2d: 1-2                 --\n",
      "├─Sequential: 1-3                        --\n",
      "|    └─Linear: 2-32                      102,764,544\n",
      "|    └─ReLU: 2-33                        --\n",
      "|    └─Dropout: 2-34                     --\n",
      "|    └─Linear: 2-35                      16,781,312\n",
      "|    └─ReLU: 2-36                        --\n",
      "|    └─Dropout: 2-37                     --\n",
      "|    └─Linear: 2-38                      4,097,000\n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Sequential: 1-1                        --\n",
       "|    └─Conv2d: 2-1                       1,792\n",
       "|    └─ReLU: 2-2                         --\n",
       "|    └─Conv2d: 2-3                       36,928\n",
       "|    └─ReLU: 2-4                         --\n",
       "|    └─MaxPool2d: 2-5                    --\n",
       "|    └─Conv2d: 2-6                       73,856\n",
       "|    └─ReLU: 2-7                         --\n",
       "|    └─Conv2d: 2-8                       147,584\n",
       "|    └─ReLU: 2-9                         --\n",
       "|    └─MaxPool2d: 2-10                   --\n",
       "|    └─Conv2d: 2-11                      295,168\n",
       "|    └─ReLU: 2-12                        --\n",
       "|    └─Conv2d: 2-13                      590,080\n",
       "|    └─ReLU: 2-14                        --\n",
       "|    └─Conv2d: 2-15                      590,080\n",
       "|    └─ReLU: 2-16                        --\n",
       "|    └─MaxPool2d: 2-17                   --\n",
       "|    └─Conv2d: 2-18                      1,180,160\n",
       "|    └─ReLU: 2-19                        --\n",
       "|    └─Conv2d: 2-20                      2,359,808\n",
       "|    └─ReLU: 2-21                        --\n",
       "|    └─Conv2d: 2-22                      2,359,808\n",
       "|    └─ReLU: 2-23                        --\n",
       "|    └─MaxPool2d: 2-24                   --\n",
       "|    └─Conv2d: 2-25                      2,359,808\n",
       "|    └─ReLU: 2-26                        --\n",
       "|    └─Conv2d: 2-27                      2,359,808\n",
       "|    └─ReLU: 2-28                        --\n",
       "|    └─Conv2d: 2-29                      2,359,808\n",
       "|    └─ReLU: 2-30                        --\n",
       "|    └─MaxPool2d: 2-31                   --\n",
       "├─AdaptiveAvgPool2d: 1-2                 --\n",
       "├─Sequential: 1-3                        --\n",
       "|    └─Linear: 2-32                      102,764,544\n",
       "|    └─ReLU: 2-33                        --\n",
       "|    └─Dropout: 2-34                     --\n",
       "|    └─Linear: 2-35                      16,781,312\n",
       "|    └─ReLU: 2-36                        --\n",
       "|    └─Dropout: 2-37                     --\n",
       "|    └─Linear: 2-38                      4,097,000\n",
       "=================================================================\n",
       "Total params: 138,357,544\n",
       "Trainable params: 138,357,544\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from torchvision.models import vgg16\n",
    "vgg_model = vgg16(pretrained=True)\n",
    "summary(vgg_model, input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81cacc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4394a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c8a1611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n",
      "[Linear(in_features=25088, out_features=4096, bias=True), ReLU(inplace=True), Dropout(p=0.5, inplace=False), Linear(in_features=4096, out_features=4096, bias=True), ReLU(inplace=True), Dropout(p=0.5, inplace=False)]\n",
      "[Linear(in_features=25088, out_features=4096, bias=True), ReLU(inplace=True), Dropout(p=0.5, inplace=False), Linear(in_features=4096, out_features=4096, bias=True), ReLU(inplace=True), Dropout(p=0.5, inplace=False), Linear(in_features=4096, out_features=10, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "num_features = vgg_model.classifier[-1].in_features\n",
    "print(num_features)\n",
    "layers = list(vgg_model.classifier.children())[:-1]\n",
    "print(layers)\n",
    "layers.extend([torch.nn.Linear(num_features, 10)])\n",
    "print(layers)\n",
    "vgg_model.classifier = torch.nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c52e1dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c12a5db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a32540cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7204e971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.433311939239502\n",
      "44.17114734649658\n",
      "67.85694122314453\n",
      "91.48366212844849\n",
      "22.06047773361206\n",
      "46.112399101257324\n",
      "68.12499046325684\n",
      "91.88085556030273\n",
      "21.800673007965088\n",
      "45.304930210113525\n",
      "69.0407657623291\n",
      "91.64718627929688\n",
      "23.44935894012451\n",
      "44.86655235290527\n",
      "67.98864841461182\n",
      "91.69105291366577\n",
      "22.262113094329834\n",
      "44.308719635009766\n",
      "68.19425106048584\n",
      "87.5666606426239\n",
      "22.56148099899292\n",
      "44.07512187957764\n",
      "66.82673692703247\n",
      "90.442054271698\n",
      "21.973888874053955\n",
      "45.16244173049927\n",
      "68.52227687835693\n",
      "92.36356496810913\n",
      "23.141815662384033\n",
      "48.74911546707153\n",
      "72.31582880020142\n",
      "96.47953987121582\n",
      "23.722898960113525\n",
      "47.21269130706787\n",
      "70.84500551223755\n",
      "92.93174505233765\n",
      "22.74005889892578\n",
      "47.458298206329346\n",
      "71.10028982162476\n",
      "94.73446607589722\n",
      "23.683616518974304\n",
      "10.925445556640625\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    vgg_model.train()\n",
    "    for images, labels in train_generator:\n",
    "        optimizer.zero_grad()\n",
    "        pred = vgg_model(images)\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "        print(train_loss)\n",
    "    vgg_model.eval()\n",
    "    for images, labels in val_generator:\n",
    "        optimizer.zero_grad()\n",
    "        pred = vgg_model(images)\n",
    "        loss = criterion(pred, labels)\n",
    "        val_loss += loss.item()*images.size(0)\n",
    "train_loss = train_loss/len(train_generator)\n",
    "val_loss = val_loss/len(val_generator)\n",
    "print(train_loss)\n",
    "print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "904e441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = 0.0\n",
    "for images, labels in test_generator:\n",
    "    output = model(images)\n",
    "    #rint(output)\n",
    "    _, pred = torch.max(output,1)\n",
    "    #print(list(pred))\n",
    "    #print(labels)\n",
    "    num_correct = 0\n",
    "    accuracy = 0.0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i]==labels[i]:\n",
    "            num_correct+=1\n",
    "    accuracy = (num_correct/images.size(0))*100\n",
    "    #print(accuracy)\n",
    "    test_accuracy += accuracy\n",
    "#print(test_accuracy)\n",
    "print(test_accuracy/len(test_generator))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
