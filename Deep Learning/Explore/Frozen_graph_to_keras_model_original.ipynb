{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e892391",
   "metadata": {},
   "source": [
    "### Yolov2 only Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "06595fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.framework import tensor_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "858399ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.gfile.GFile(\"/home/dell/Documents/pretrained_models/yolo_onlyrelu.pb\",'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bb660eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder Placeholder []\n",
      "Conv2D/filter Const []\n",
      "Conv2D Conv2D ['Placeholder', 'Conv2D/filter']\n",
      "BiasAdd/bias Const []\n",
      "BiasAdd BiasAdd ['Conv2D', 'BiasAdd/bias']\n",
      "Relu Relu ['BiasAdd']\n",
      "MaxPool2d MaxPool ['Relu']\n",
      "Conv2D_1/filter Const []\n",
      "Conv2D_1 Conv2D ['MaxPool2d', 'Conv2D_1/filter']\n",
      "BiasAdd_1/bias Const []\n",
      "BiasAdd_1 BiasAdd ['Conv2D_1', 'BiasAdd_1/bias']\n",
      "Relu_1 Relu ['BiasAdd_1']\n",
      "MaxPool2d_1 MaxPool ['Relu_1']\n",
      "Conv2D_2/filter Const []\n",
      "Conv2D_2 Conv2D ['MaxPool2d_1', 'Conv2D_2/filter']\n",
      "BiasAdd_2/bias Const []\n",
      "BiasAdd_2 BiasAdd ['Conv2D_2', 'BiasAdd_2/bias']\n",
      "Relu_2 Relu ['BiasAdd_2']\n",
      "Conv2D_3/filter Const []\n",
      "Conv2D_3 Conv2D ['Relu_2', 'Conv2D_3/filter']\n",
      "BiasAdd_3/bias Const []\n",
      "BiasAdd_3 BiasAdd ['Conv2D_3', 'BiasAdd_3/bias']\n",
      "Relu_3 Relu ['BiasAdd_3']\n",
      "Conv2D_4/filter Const []\n",
      "Conv2D_4 Conv2D ['Relu_3', 'Conv2D_4/filter']\n",
      "BiasAdd_4/bias Const []\n",
      "BiasAdd_4 BiasAdd ['Conv2D_4', 'BiasAdd_4/bias']\n",
      "Relu_4 Relu ['BiasAdd_4']\n",
      "MaxPool2d_2 MaxPool ['Relu_4']\n",
      "Conv2D_5/filter Const []\n",
      "Conv2D_5 Conv2D ['MaxPool2d_2', 'Conv2D_5/filter']\n",
      "BiasAdd_5/bias Const []\n",
      "BiasAdd_5 BiasAdd ['Conv2D_5', 'BiasAdd_5/bias']\n",
      "Relu_5 Relu ['BiasAdd_5']\n",
      "Conv2D_6/filter Const []\n",
      "Conv2D_6 Conv2D ['Relu_5', 'Conv2D_6/filter']\n",
      "BiasAdd_6/bias Const []\n",
      "BiasAdd_6 BiasAdd ['Conv2D_6', 'BiasAdd_6/bias']\n",
      "Relu_6 Relu ['BiasAdd_6']\n",
      "Conv2D_7/filter Const []\n",
      "Conv2D_7 Conv2D ['Relu_6', 'Conv2D_7/filter']\n",
      "BiasAdd_7/bias Const []\n",
      "BiasAdd_7 BiasAdd ['Conv2D_7', 'BiasAdd_7/bias']\n",
      "Relu_7 Relu ['BiasAdd_7']\n",
      "MaxPool2d_3 MaxPool ['Relu_7']\n",
      "Conv2D_8/filter Const []\n",
      "Conv2D_8 Conv2D ['MaxPool2d_3', 'Conv2D_8/filter']\n",
      "BiasAdd_8/bias Const []\n",
      "BiasAdd_8 BiasAdd ['Conv2D_8', 'BiasAdd_8/bias']\n",
      "Relu_8 Relu ['BiasAdd_8']\n",
      "Conv2D_9/filter Const []\n",
      "Conv2D_9 Conv2D ['Relu_8', 'Conv2D_9/filter']\n",
      "BiasAdd_9/bias Const []\n",
      "BiasAdd_9 BiasAdd ['Conv2D_9', 'BiasAdd_9/bias']\n",
      "Relu_9 Relu ['BiasAdd_9']\n",
      "Conv2D_10/filter Const []\n",
      "Conv2D_10 Conv2D ['Relu_9', 'Conv2D_10/filter']\n",
      "BiasAdd_10/bias Const []\n",
      "BiasAdd_10 BiasAdd ['Conv2D_10', 'BiasAdd_10/bias']\n",
      "Relu_10 Relu ['BiasAdd_10']\n",
      "Conv2D_11/filter Const []\n",
      "Conv2D_11 Conv2D ['Relu_10', 'Conv2D_11/filter']\n",
      "BiasAdd_11/bias Const []\n",
      "BiasAdd_11 BiasAdd ['Conv2D_11', 'BiasAdd_11/bias']\n",
      "Relu_11 Relu ['BiasAdd_11']\n",
      "Conv2D_12/filter Const []\n",
      "Conv2D_12 Conv2D ['Relu_11', 'Conv2D_12/filter']\n",
      "BiasAdd_12/bias Const []\n",
      "BiasAdd_12 BiasAdd ['Conv2D_12', 'BiasAdd_12/bias']\n",
      "Relu_12 Relu ['BiasAdd_12']\n",
      "MaxPool2d_4 MaxPool ['Relu_12']\n",
      "Conv2D_13/filter Const []\n",
      "Conv2D_13 Conv2D ['Relu_12', 'Conv2D_13/filter']\n",
      "BiasAdd_13/bias Const []\n",
      "BiasAdd_13 BiasAdd ['Conv2D_13', 'BiasAdd_13/bias']\n",
      "Relu_13 Relu ['BiasAdd_13']\n",
      "Conv2D_14/filter Const []\n",
      "Conv2D_14 Conv2D ['MaxPool2d_4', 'Conv2D_14/filter']\n",
      "BiasAdd_14/bias Const []\n",
      "BiasAdd_14 BiasAdd ['Conv2D_14', 'BiasAdd_14/bias']\n",
      "Relu_14 Relu ['BiasAdd_14']\n",
      "Conv2D_15/filter Const []\n",
      "Conv2D_15 Conv2D ['Relu_14', 'Conv2D_15/filter']\n",
      "BiasAdd_15/bias Const []\n",
      "BiasAdd_15 BiasAdd ['Conv2D_15', 'BiasAdd_15/bias']\n",
      "Relu_15 Relu ['BiasAdd_15']\n",
      "Conv2D_16/filter Const []\n",
      "Conv2D_16 Conv2D ['Relu_15', 'Conv2D_16/filter']\n",
      "BiasAdd_16/bias Const []\n",
      "BiasAdd_16 BiasAdd ['Conv2D_16', 'BiasAdd_16/bias']\n",
      "Relu_16 Relu ['BiasAdd_16']\n",
      "Conv2D_17/filter Const []\n",
      "Conv2D_17 Conv2D ['Relu_16', 'Conv2D_17/filter']\n",
      "BiasAdd_17/bias Const []\n",
      "BiasAdd_17 BiasAdd ['Conv2D_17', 'BiasAdd_17/bias']\n",
      "Relu_17 Relu ['BiasAdd_17']\n",
      "Conv2D_18/filter Const []\n",
      "Conv2D_18 Conv2D ['Relu_17', 'Conv2D_18/filter']\n",
      "BiasAdd_18/bias Const []\n",
      "BiasAdd_18 BiasAdd ['Conv2D_18', 'BiasAdd_18/bias']\n",
      "Relu_18 Relu ['BiasAdd_18']\n",
      "Conv2D_19/filter Const []\n",
      "Conv2D_19 Conv2D ['Relu_18', 'Conv2D_19/filter']\n",
      "BiasAdd_19/bias Const []\n",
      "BiasAdd_19 BiasAdd ['Conv2D_19', 'BiasAdd_19/bias']\n",
      "Relu_19 Relu ['BiasAdd_19']\n",
      "Conv2D_20/filter Const []\n",
      "Conv2D_20 Conv2D ['Relu_19', 'Conv2D_20/filter']\n",
      "BiasAdd_20/bias Const []\n",
      "BiasAdd_20 BiasAdd ['Conv2D_20', 'BiasAdd_20/bias']\n",
      "Relu_20 Relu ['BiasAdd_20']\n",
      "SpaceToDepth SpaceToDepth ['Relu_13']\n",
      "concat/axis Const []\n",
      "concat ConcatV2 ['SpaceToDepth', 'Relu_20', 'concat/axis']\n",
      "Conv2D_21/filter Const []\n",
      "Conv2D_21 Conv2D ['concat', 'Conv2D_21/filter']\n",
      "BiasAdd_21/bias Const []\n",
      "BiasAdd_21 BiasAdd ['Conv2D_21', 'BiasAdd_21/bias']\n",
      "Relu_21 Relu ['BiasAdd_21']\n",
      "Conv2D_22/filter Const []\n",
      "Conv2D_22 Conv2D ['Relu_21', 'Conv2D_22/filter']\n",
      "BiasAdd_22/bias Const []\n",
      "BiasAdd_22 BiasAdd ['Conv2D_22', 'BiasAdd_22/bias']\n",
      "Reshape/shape Const []\n",
      "Reshape Reshape ['BiasAdd_22', 'Reshape/shape']\n",
      "init NoOp []\n"
     ]
    }
   ],
   "source": [
    "master_dict = {}\n",
    "for i in graph_def.node:\n",
    "    print(i.name, i.op, i.input)\n",
    "    master_dict[i.name] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55485f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "biases = {}\n",
    "\n",
    "for node in graph_def.node:\n",
    "    if node.op == 'Conv2D':\n",
    "        for i in node.input:\n",
    "            inp = master_dict[i]\n",
    "            if inp.op == 'Const' and inp.attr['dtype'].type<=1:\n",
    "                weights[node.name] = tensor_util.MakeNdarray(inp.attr['value'].tensor)\n",
    "    elif node.op == 'MatMul':\n",
    "        for i in node.input:\n",
    "            inp = master_dict[i]\n",
    "            if inp.op == 'Identity':\n",
    "                inp = master_dict[inp.input[0]]   \n",
    "                #print(inp.name)\n",
    "                if inp.op == 'Const' and inp.attr['dtype'].type<=1:\n",
    "                    weights[node.name] = tensor_util.MakeNdarray(inp.attr['value'].tensor)\n",
    "    elif node.op == 'BiasAdd':\n",
    "        for i in node.input:\n",
    "            inp = master_dict[i]\n",
    "            if inp.op == 'Const' and inp.attr['dtype'].type<=1:\n",
    "                biases[node.name] = tensor_util.MakeNdarray(inp.attr['value'].tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a1d29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D (3, 3, 3, 32)\n",
      "Conv2D_1 (3, 3, 32, 64)\n",
      "Conv2D_2 (3, 3, 64, 128)\n",
      "Conv2D_3 (1, 1, 128, 64)\n",
      "Conv2D_4 (3, 3, 64, 128)\n",
      "Conv2D_5 (3, 3, 128, 256)\n",
      "Conv2D_6 (1, 1, 256, 128)\n",
      "Conv2D_7 (3, 3, 128, 256)\n",
      "Conv2D_8 (3, 3, 256, 512)\n",
      "Conv2D_9 (1, 1, 512, 256)\n",
      "Conv2D_10 (3, 3, 256, 512)\n",
      "Conv2D_11 (1, 1, 512, 256)\n",
      "Conv2D_12 (3, 3, 256, 512)\n",
      "Conv2D_13 (1, 1, 512, 64)\n",
      "Conv2D_14 (3, 3, 512, 1024)\n",
      "Conv2D_15 (1, 1, 1024, 512)\n",
      "Conv2D_16 (3, 3, 512, 1024)\n",
      "Conv2D_17 (1, 1, 1024, 512)\n",
      "Conv2D_18 (3, 3, 512, 1024)\n",
      "Conv2D_19 (3, 3, 1024, 1024)\n",
      "Conv2D_20 (3, 3, 1024, 1024)\n",
      "Conv2D_21 (3, 3, 1280, 1024)\n",
      "Conv2D_22 (1, 1, 1024, 125)\n"
     ]
    }
   ],
   "source": [
    "weights_new = {}\n",
    "count = -1\n",
    "for i in weights:\n",
    "    count += 1\n",
    "    print(i, np.shape(weights[i]))\n",
    "    weights_new[count] = weights[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9efc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Conv2D (3, 3, 3, 32)\n",
      "1 Conv2D_1 (3, 3, 32, 64)\n",
      "2 Conv2D_2 (3, 3, 64, 128)\n",
      "3 Conv2D_3 (1, 1, 128, 64)\n",
      "4 Conv2D_4 (3, 3, 64, 128)\n",
      "5 Conv2D_5 (3, 3, 128, 256)\n",
      "6 Conv2D_6 (1, 1, 256, 128)\n",
      "7 Conv2D_7 (3, 3, 128, 256)\n",
      "8 Conv2D_8 (3, 3, 256, 512)\n",
      "9 Conv2D_9 (1, 1, 512, 256)\n",
      "10 Conv2D_10 (3, 3, 256, 512)\n",
      "11 Conv2D_11 (1, 1, 512, 256)\n",
      "12 Conv2D_12 (3, 3, 256, 512)\n",
      "19 Conv2D_13 (1, 1, 512, 64)\n",
      "13 Conv2D_14 (3, 3, 512, 1024)\n",
      "14 Conv2D_15 (1, 1, 1024, 512)\n",
      "15 Conv2D_16 (3, 3, 512, 1024)\n",
      "16 Conv2D_17 (1, 1, 1024, 512)\n",
      "17 Conv2D_18 (3, 3, 512, 1024)\n",
      "18 Conv2D_19 (3, 3, 1024, 1024)\n",
      "20 Conv2D_20 (3, 3, 1024, 1024)\n",
      "21 Conv2D_21 (3, 3, 1280, 1024)\n",
      "22 Conv2D_22 (1, 1, 1024, 125)\n"
     ]
    }
   ],
   "source": [
    "weights_new = {}\n",
    "count = -1\n",
    "for i in weights:\n",
    "    if i == 'Conv2D_13':\n",
    "        print(19,i, np.shape(weights[i]))\n",
    "        weights_new[19] = weights[i]\n",
    "    else:\n",
    "        count += 1\n",
    "        if count == 19:\n",
    "            count += 1\n",
    "            print(count,i, np.shape(weights[i]))\n",
    "            weights_new[count] = weights[i]\n",
    "        else:\n",
    "            print(count,i, np.shape(weights[i]))\n",
    "            weights_new[count] = weights[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14cbd455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 3, 3, 32)\n",
      "1 (3, 3, 32, 64)\n",
      "2 (3, 3, 64, 128)\n",
      "3 (1, 1, 128, 64)\n",
      "4 (3, 3, 64, 128)\n",
      "5 (3, 3, 128, 256)\n",
      "6 (1, 1, 256, 128)\n",
      "7 (3, 3, 128, 256)\n",
      "8 (3, 3, 256, 512)\n",
      "9 (1, 1, 512, 256)\n",
      "10 (3, 3, 256, 512)\n",
      "11 (1, 1, 512, 256)\n",
      "12 (3, 3, 256, 512)\n",
      "19 (1, 1, 512, 64)\n",
      "13 (3, 3, 512, 1024)\n",
      "14 (1, 1, 1024, 512)\n",
      "15 (3, 3, 512, 1024)\n",
      "16 (1, 1, 1024, 512)\n",
      "17 (3, 3, 512, 1024)\n",
      "18 (3, 3, 1024, 1024)\n",
      "20 (3, 3, 1024, 1024)\n",
      "21 (3, 3, 1280, 1024)\n",
      "22 (1, 1, 1024, 125)\n"
     ]
    }
   ],
   "source": [
    "for i in weights_new:\n",
    "    print(i, np.shape(weights_new[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c93a378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 BiasAdd\n",
      "1 BiasAdd_1\n",
      "2 BiasAdd_2\n",
      "3 BiasAdd_3\n",
      "4 BiasAdd_4\n",
      "5 BiasAdd_5\n",
      "6 BiasAdd_6\n",
      "7 BiasAdd_7\n",
      "8 BiasAdd_8\n",
      "9 BiasAdd_9\n",
      "10 BiasAdd_10\n",
      "11 BiasAdd_11\n",
      "12 BiasAdd_12\n",
      "13 BiasAdd_13\n",
      "14 BiasAdd_14\n",
      "15 BiasAdd_15\n",
      "16 BiasAdd_16\n",
      "17 BiasAdd_17\n",
      "18 BiasAdd_18\n",
      "19 BiasAdd_19\n",
      "20 BiasAdd_20\n",
      "21 BiasAdd_21\n",
      "22 BiasAdd_22\n"
     ]
    }
   ],
   "source": [
    "bias_new = {}\n",
    "for index,i in enumerate(biases):\n",
    "    print(index, i)\n",
    "    bias_new[index] = biases[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1448c9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ -1.8597115    0.80969214   0.9792444    2.0638185    1.7674338\n",
      "   0.93087447  -1.1662121   -5.1038103   -0.75286084  -2.9061337\n",
      "  -4.558983    -9.949564    -3.1445312   -4.1784315    0.9554825\n",
      "   0.39355847   0.16686863   0.17337888   0.9371103   -2.5834892\n",
      "   0.7592212    0.09492081  -0.6412301    3.0944235   -2.601602\n",
      "   0.523043     0.5701028   -4.0018363   -1.879976     0.70069563\n",
      " -12.463739     0.4860712 ]\n",
      "1 [ 3.1406405  -2.6548128  -1.7482661   1.9401557  -8.10507     0.87604856\n",
      " -5.7029657   3.4385355   1.7620897   0.6134293   0.73148006  2.526691\n",
      "  0.9091644   3.003093   -0.8640492   2.4932184  -0.46212506  4.4514484\n",
      " -0.87494105  3.519568    0.33657897  1.6837816   0.3670628   1.1090213\n",
      " -2.2255387   0.15425068  2.2111602  -0.07022238  0.35442698  1.919349\n",
      "  2.6407144   2.2065127   1.9444373   1.3878111   0.36017078  1.440069\n",
      "  0.96824384  1.3066959   0.43374652  2.3210416   0.3674745   0.6546715\n",
      "  1.234313    1.1945094  -0.31181085  0.72825414  0.881246    0.6410059\n",
      "  3.4515777   2.787705    0.12135871  1.7468222   0.967413    1.5824804\n",
      "  2.847671    2.9695451   1.4343007   2.6260335   1.2761087  -9.3774\n",
      "  0.8586071   0.39915967  2.8812423   0.7399858 ]\n",
      "2 [ 6.82824075e-01  1.16538286e-01  2.56316280e+00  1.51102448e+00\n",
      "  1.87912035e+00  5.61952829e-01 -1.53277397e-01  7.75265396e-01\n",
      " -4.03526604e-01  1.55103302e+00 -9.88876462e-01  2.46681762e+00\n",
      "  8.12997937e-01  1.80087209e+00  3.56731653e-01  3.73398328e+00\n",
      "  1.19270575e+00  5.70601702e-01 -8.62526536e-01 -5.56918740e-01\n",
      "  1.24032259e+00  1.71253645e+00  1.24920809e+00  2.24619091e-01\n",
      " -3.69919014e+00  7.32291222e-01  1.06166220e+00  8.03623319e-01\n",
      "  3.47563457e+00  9.23831835e-02  8.12080503e-02 -1.40859759e+00\n",
      "  2.42652225e+00  1.56754375e-01 -3.35062772e-01  1.16836989e+00\n",
      "  9.83747482e-01  2.75060058e+00  1.29345179e+00 -3.66428494e-02\n",
      "  1.81613505e+00  3.36258769e-01 -3.67008269e-01  1.04990697e+00\n",
      "  8.62896740e-01 -4.34198260e-01 -2.52485394e-01  2.20605683e+00\n",
      " -1.28085637e+00  1.46489573e+00 -5.96434832e-01 -2.35851124e-01\n",
      "  1.54416636e-01  4.90393996e-01  2.40834379e+00  9.31374669e-01\n",
      "  1.07281041e+00  2.73232269e+00  1.93367934e+00  2.98832059e-01\n",
      "  3.77858400e-01  2.20399332e+00  3.81094396e-01  2.00724673e+00\n",
      "  5.73247528e+00  3.13218117e+00  2.31546855e+00  1.65528119e+00\n",
      " -9.36852098e-01  4.12283301e-01  2.00235844e+00  1.39818394e+00\n",
      "  2.36161113e+00 -6.14676952e-01 -1.52960157e+00 -2.02524096e-01\n",
      " -7.62994885e-02  1.92039967e+00  1.29416549e+00  6.60193086e-01\n",
      "  9.36178744e-01  9.32693183e-02  1.47427642e+00  1.98529232e+00\n",
      "  1.12602711e+00  2.04589987e+00  2.74429679e+00 -5.06791449e+00\n",
      "  4.26932144e+00  8.79350424e-01 -4.19980288e-03  1.85718358e+00\n",
      " -9.33001041e-02  9.72543955e-02  1.28518558e+00  5.62378943e-01\n",
      "  7.79576182e-01 -1.40935171e+00 -4.22810316e+00  5.62177598e-01\n",
      "  7.54153371e-01  1.41420257e+00  1.42582273e+00  1.42466116e+00\n",
      "  4.18205976e-01  1.75181890e+00  1.31835294e+00  1.43982387e+00\n",
      "  1.10776567e+00  3.67739534e+00  2.18001795e+00  2.74747896e+00\n",
      "  2.25368071e+00  3.03433299e+00 -5.96829414e-01  2.38109684e+00\n",
      " -1.49228024e+00  2.72898769e+00  2.36153603e+00 -6.74202025e-01\n",
      " -6.07291579e-01  1.05893517e+00 -9.66572583e-01  3.07832748e-01\n",
      "  1.56454951e-01  1.41115189e+00  1.80550587e+00 -1.76409698e+00]\n",
      "3 [ 2.6374989   1.5759289   0.41195524  2.0883923   0.24368274  0.29369307\n",
      "  1.9678316  -2.8200338   5.4891944   2.7381155   2.9733753   1.6115412\n",
      "  0.39686048 -0.12841868 -0.7079047   1.4036313  -5.8877225   1.8724239\n",
      "  2.722071   -0.9855834  -0.48307025  0.02772546  3.009766    2.3629096\n",
      "  2.825297    3.7010221  -1.7068936  -3.831608    5.157379    2.0250096\n",
      "  0.02740973 -1.4531311   3.3754814   1.8542205   3.1837978  -0.21055502\n",
      "  1.9899789  -2.778253   -2.021038   -0.28596336  3.7299573  -0.45800352\n",
      "  2.4058816   0.97105706  2.7941906   1.5747219   5.689286    0.48914796\n",
      "  3.9271238   0.8065523  -2.3981345   1.4842796   2.4714863   2.372728\n",
      "  3.9968157   4.039956    2.892974    3.4136086   0.25619578  1.924883\n",
      "  2.2184389   1.0921968   1.7356124   3.6268058 ]\n",
      "4 [-4.2280426  -0.6776958  -0.54127085 -0.10257524  0.20908177 -0.52688444\n",
      "  1.1365533   0.04480451  1.1639398  -0.8034439   1.6502272  -4.3494534\n",
      "  0.8563391  -0.5622933  -0.29066265 -0.3862903   0.3735323   0.4875145\n",
      "  5.204837    0.38152206  0.02580118  0.8947065   1.8155273  -1.2220008\n",
      " -0.8401134   1.2285919   1.4848833   1.3220963   0.16330981  0.47984135\n",
      "  1.871685   -1.0134006  -1.0464057  -0.4144777   0.9680731   0.08583248\n",
      " -3.4689403   0.07721239  0.1690141  -0.01658106  0.6690347  -1.8405411\n",
      "  0.6732814  -0.66534066  0.40612948 -0.14627358 -0.51433897 -0.884362\n",
      " -0.3301563   1.3512645   0.15225494  1.1578782  -0.17593712 -0.5749749\n",
      " -0.54996866  0.40910554  0.7166358  -0.2803734  -0.81165123 -0.65681374\n",
      "  1.3722752   0.97282875  0.41458023  0.2923379  -0.28566957  0.13530421\n",
      "  1.6848042   0.43442178 -0.10335922  4.4348335   0.0105319  -0.24860495\n",
      "  0.02492237  6.093525   -0.6968864   0.45657128  0.5360099  -0.59266603\n",
      " -0.1212438  -0.053931    0.49005377  0.23088157  1.2924327  -0.32764173\n",
      "  0.8223314  -1.5152808  -0.12134868 -0.26772597  0.7786217   0.00664759\n",
      " -1.6520792   2.7112966   0.823437    0.63092226  0.25502706 -0.63006127\n",
      " -0.06682168 -0.883487   -0.28080505 -0.52506185 -0.1982342   2.227937\n",
      " -0.7667726  -1.2811908   1.0993009   0.3480587   0.87878984 -0.95456576\n",
      " -0.9378902   0.61287844 -0.55410784  0.9818114   0.11456692  1.2038604\n",
      "  3.0961518  -0.3099243  -0.6805231   0.75629616  0.22029024 -3.3404267\n",
      " -0.42253178  1.3240883   2.0220914   0.01813948  0.8671324  -1.659559\n",
      " -0.85292065  0.3922137 ]\n",
      "5 [-1.3828993   1.3084471  -1.5412036   1.1449507  -0.21347106  0.3573861\n",
      " -0.73407906  0.42942905 -1.2688468  -3.2428935  -0.34899366 -0.31038755\n",
      "  0.68549895  0.5899267   1.7839266  -2.0953152  -2.9280095   0.33676696\n",
      "  0.98888135 -3.1415668   0.77954865 -1.3053305  -1.4559497  -0.10882056\n",
      " -1.0987322  -0.70283437  1.083354   -1.461489   -2.378125   -1.1272854\n",
      " -1.8404117  -2.2795084  -0.73160666  0.2753259   1.8956081  -1.1646372\n",
      " -0.7480908   0.31071222  0.88456523 -1.9432309  -0.6029217   0.91260326\n",
      "  0.42549977  1.5223447  -1.7615128   1.1441486  -1.1036636   1.0937998\n",
      " -0.48135668  0.11813429  0.5566796  -2.9385023   0.5116868  -2.992959\n",
      " -1.3017615  -0.785747   -2.2087533  -1.8120215  -1.0742835   0.01333028\n",
      " -2.7295737  -1.246376    0.5204957   0.48330608  0.92664444  1.4841213\n",
      " -0.47300166  0.9862714  -0.32472306 -1.7532462   0.1990974  -1.0198765\n",
      " -2.1599102  -0.45780623 -0.312161   -1.6927657   0.19021419 -0.7710382\n",
      "  0.95875335  0.29117227 -1.2533412  -0.1669156   0.8626797  -0.38924938\n",
      "  1.3852835  -1.3216197   0.6860959  -1.391754   -1.6102316  -0.45435345\n",
      " -0.44130307  1.4975592  -0.12741339 -1.334489   -0.87484914  1.9199568\n",
      " -1.5476459  -0.48691553  1.3409929  -1.2838418   0.9316972  -0.41422212\n",
      "  0.604327   -0.7408102  -0.11002535 -2.919486   -0.2783895  -4.4132285\n",
      "  1.2427528   0.07402194  0.7105011   0.8794639  -2.266601   -0.23564303\n",
      "  0.08467543  0.12175443  0.8962036  -0.49835142  0.8729041  -0.10507838\n",
      "  0.16476321  0.43647105  0.5741629   0.50474733 -2.4555597  -2.3240585\n",
      " -0.3605466   4.0681343  -2.2875576   1.0697337  -0.3788605   0.13644049\n",
      "  0.23054594  2.5203347  -0.52740586 -2.9416785  -0.5207648  -0.6598962\n",
      "  0.3152287   0.92287314  0.773949   -0.4157042  -1.0979241   0.604725\n",
      "  0.33362776  4.7869434  -1.0951967   0.98241675 -3.5722003  -0.08172455\n",
      " -2.348588    1.4956154  -0.76008743 -0.22915646  0.741596   -0.05653754\n",
      " -0.83595324  0.69802797 -2.6870046   1.1750889   0.15919575 -1.7362201\n",
      " -0.91527593 -3.7676272   0.8808309  -2.2753258  -0.9897971  -2.488687\n",
      " -2.5899053  -1.3883533  -0.7657102  -1.2846719   2.2949576   0.6425625\n",
      "  1.04836     0.94220054  1.3852333  -4.5666213  -0.15427387 -0.19773644\n",
      "  0.24554202 -0.01400535 -2.4858646  -0.77500564  0.28814948 -1.9247351\n",
      " -0.9038306  -0.4090801  -0.6079794   0.5367161  -0.44749582  0.37231812\n",
      "  0.71595645  0.5884372   3.8034034   0.3278911  -2.977201    0.54111856\n",
      " -0.37656486 -1.061714   -2.5641766   0.50075114 -0.5493648  -0.01639831\n",
      "  0.8276316  -0.01665786  0.7551538   1.5312432  -0.2322886  -2.0316758\n",
      " -2.4519303  -0.5757445  -0.3623975  -0.3529095  -0.4532822   0.21122865\n",
      " -0.02734104 -1.1949546  -1.6549611  -2.9905014   2.873107   -1.0207429\n",
      " -0.14350696 -0.01967883 -1.2203418   1.3290381  -1.001349    0.96446645\n",
      "  1.4915868   1.9477855  -0.90042746 -0.45079553  0.49379736 -0.5225554\n",
      "  0.40562987  0.75475746 -0.6209896  -0.53698057 -1.1703439   1.175518\n",
      " -0.5141543   0.41263807  0.8599968  -0.39348006 -2.6530588  -0.02831343\n",
      " -0.7347081  -0.49499878 -1.1801746  -2.3281102  -0.5005912  -0.37823707\n",
      " -2.1897712   0.29554328 -0.7214049   1.1072294 ]\n",
      "6 [ 0.00681996 -4.4324603   0.44404733  0.88980657  3.9720721  -1.6905797\n",
      "  1.1072731   2.529871    1.1743416   3.2206483   1.0917776  -1.2196153\n",
      "  4.3478327   0.29515398  0.11271307  0.10182348  0.7428222   5.4437685\n",
      " -0.02127588  0.16608015  1.4134256   0.30892107  4.37211     1.111438\n",
      "  0.55078924  4.2772274  -0.68892455 -0.30748466 -1.9463991   1.587709\n",
      " -0.97229993  2.5851998   0.08001918  4.0798483   3.501357   -0.02054361\n",
      "  2.1793277   2.8844047  -0.21647081 -0.11487097  2.125728    3.7161567\n",
      "  3.6909814   0.84865135  1.4254749   1.7991343   1.7878749  -1.5217419\n",
      "  0.2734201   1.4257709   1.280134   -1.5503056   1.1319848  -1.2196835\n",
      " -1.4170836   2.7696273   1.7028733  -0.67419696  1.8844316   4.4185076\n",
      "  3.493717    1.1460452   0.22426897  1.2584583   1.2260879  -3.9879642\n",
      "  1.0029775   0.7026909   0.50334775  0.87012756 -0.04885232 -1.2712168\n",
      " -4.278931   -0.3809343   1.659531    1.8504014   0.9234381   1.3458724\n",
      "  1.1161549  -3.4041846   0.6630218   0.47455847  3.030929   -0.28032637\n",
      "  0.9880836   0.5967979   1.0642632   0.29392737  3.1457222   2.703864\n",
      "  1.0263886  -0.6977308   0.32532722 -4.2329173   1.2185735   1.7053057\n",
      " -0.3580854  -2.697291   -0.05510551  1.2576588   0.54478943 -3.5626175\n",
      "  3.7007601  -1.014954    1.6139423   1.6781554  -1.3820909   0.93961\n",
      "  0.55138    -2.1246493   2.8704655   1.0934485   0.55716664  0.23944908\n",
      "  2.198743    3.3277626   2.4941719   2.6163003   1.5311371   2.6017108\n",
      "  1.2598156   1.128575    1.7694489   3.8956287   1.4981905   1.5707095\n",
      "  0.32907844  2.6674447 ]\n",
      "7 [-8.28424633e-01  1.19069554e-01  1.70458794e-01  4.77390528e-01\n",
      "  4.22066927e-01  6.22538090e-01  1.18694568e+00  1.55222464e+00\n",
      " -5.00005603e-01  5.67940712e-01  1.05641294e+00 -6.79088116e-01\n",
      "  1.31432080e+00 -6.40704036e-02  1.48056555e+00  5.46676397e-01\n",
      " -3.85931134e-01 -7.15610921e-01  8.77308726e-01  7.19903350e-01\n",
      "  4.62994456e-01  4.86897230e-01  5.98103881e-01  1.45613849e+00\n",
      "  1.67681277e+00  9.62124109e-01 -9.99116421e-01 -3.69843006e-01\n",
      "  9.25202966e-02  1.75121164e+00  9.42499399e-01 -6.21525168e-01\n",
      "  8.48758221e-01  1.21693921e+00  9.97363567e-01  1.97689342e+00\n",
      " -1.45763266e+00  2.58106470e-01  5.74390888e-01  2.61392283e+00\n",
      "  7.64450550e-01  1.04320085e+00 -1.17083740e+00 -3.20859575e+00\n",
      "  3.26500416e-01 -6.21487439e-01 -1.20647907e-01  8.16412210e-01\n",
      "  3.54753613e-01  2.72181511e-01  7.87917256e-01  6.15302444e-01\n",
      " -3.28191280e-01 -2.41751075e-01 -2.54339170e+00  3.79261494e-01\n",
      "  6.30613804e-01 -6.84700012e-01 -1.20853877e+00  1.06122351e+00\n",
      "  4.15722221e-01  1.96691990e-01  1.91459179e-01  3.11080527e+00\n",
      "  1.01307106e+00 -1.01037836e+00  5.18882036e-01  1.68465948e+00\n",
      "  2.03991234e-02  4.28679466e-01  1.62659657e+00  1.44333541e+00\n",
      " -1.57850003e+00 -4.92796421e-01  7.99872398e-01  8.96834731e-01\n",
      "  1.29117978e+00  9.56885993e-01  1.76249874e+00 -2.28912592e-01\n",
      " -8.18777442e-01  1.39036536e+00  1.72997773e+00  1.91073930e+00\n",
      "  1.50349498e+00  3.87530446e-01  4.95209217e-01  2.73062944e-01\n",
      "  3.70865130e+00  9.97031212e-01  2.71944165e-01 -3.57575774e-01\n",
      " -1.23533368e+00  1.01691318e+00 -9.19193983e-01  5.02759933e-01\n",
      " -3.66181374e-01 -1.82406831e+00  1.20453835e+00 -6.62761211e-01\n",
      "  1.69302988e+00  2.61675668e+00  1.13927054e+00  4.35974884e+00\n",
      "  1.39871359e-01  3.87724042e-01  2.89515114e+00 -6.83619380e-01\n",
      "  8.53467941e-01  1.36676669e-01 -4.03452992e-01  1.81317377e+00\n",
      "  7.52387226e-01  1.06927133e+00  8.18719149e-01  1.02476430e+00\n",
      "  1.78265285e+00  2.33157039e-01 -1.36548400e+00 -4.25096810e-01\n",
      "  9.61980999e-01 -4.15115952e-01 -1.29197443e+00 -3.86794806e-02\n",
      " -1.57620668e-01  9.65507030e-02 -1.47334576e-01  4.88671303e-01\n",
      "  9.36366558e-01 -2.19275117e-01  9.78835583e-01  1.49427056e-01\n",
      " -1.18865156e+00  2.36472368e-01  5.93996644e-01  3.54003906e-03\n",
      " -2.79309392e-01  6.63514733e-01  1.36909473e+00  8.65718126e-01\n",
      " -2.79047799e+00  1.52070260e+00  1.25920761e+00  2.54260850e+00\n",
      "  7.14765310e-01  4.82215524e-01  3.39449883e-01 -1.16424036e+00\n",
      "  4.00797129e-01  4.92771029e-01  1.15388381e+00  7.50696301e-01\n",
      "  1.02941751e+00 -3.67185593e-01  3.82813931e-01 -1.94732463e+00\n",
      " -1.10923755e+00 -1.25364065e-02  8.55200171e-01  1.26837683e+00\n",
      "  6.82919502e-01  1.44343090e+00 -3.91389847e-01 -1.16570139e+00\n",
      "  1.63424754e+00  1.98655665e-01  2.59223223e-01  3.60353112e-01\n",
      "  4.19072628e-01 -4.08314705e-01 -3.48275185e-01 -1.46498585e+00\n",
      " -1.62897587e-01  4.41346169e-02  9.70716000e-01 -1.23331487e-01\n",
      "  1.46938312e+00 -1.61976099e-01 -6.31722867e-01  5.37095308e-01\n",
      "  1.49728024e+00 -5.65062881e-01  1.65035248e-01  1.42069912e+00\n",
      " -7.19610095e-01  5.79071522e-01 -8.72832179e-01  1.30869210e+00\n",
      "  1.12719297e+00  3.94231558e-01  3.99554133e-01  6.84730053e-01\n",
      "  1.19319177e+00  3.75118494e-01  2.22373605e-01 -1.17745519e-01\n",
      "  8.37843060e-01  8.28982115e-01  1.36360335e+00  8.05248260e-01\n",
      "  5.25980115e-01  1.01898170e+00  8.95333886e-01  2.29793143e+00\n",
      "  5.63791394e-01  3.13995719e-01 -1.26875007e+00  2.12293339e+00\n",
      "  1.59788644e+00  7.60717511e-01  1.55606198e+00  4.23099756e-01\n",
      " -3.63778114e-01 -1.94117308e-01 -2.41875947e-02 -5.05061150e-02\n",
      "  9.90784764e-01  1.60649931e+00  4.46093678e-01 -2.16069937e-01\n",
      "  6.47181630e-01  4.39184904e-01 -6.05228066e-01  1.03948677e+00\n",
      "  6.94870949e-02  1.53020239e+00  1.90602088e+00 -1.82574987e-01\n",
      "  1.21699619e+00 -3.89428759e+00 -5.58542132e-01  1.51759899e+00\n",
      "  3.77939105e-01  4.89788949e-01  1.25352478e+00  2.11907816e+00\n",
      " -3.16868663e-01  1.25025964e+00  1.40586734e-01  5.22011518e-01\n",
      " -5.61330080e-01 -8.75460327e-01 -7.25635767e-01 -7.86147118e-02\n",
      "  1.65294063e+00  1.73947477e+00  1.27457678e+00 -5.89291573e-01\n",
      " -2.36204624e+00  5.54358959e-01 -3.92525196e-02  1.38693845e+00\n",
      " -5.59713364e-01 -1.45605183e+00  8.50726962e-01  1.10992634e+00]\n",
      "8 [-1.83396697e+00  2.12361261e-01  3.19708616e-01 -1.50747180e-01\n",
      " -2.21503687e+00  4.17320549e-01 -1.08932745e+00 -1.80468035e+00\n",
      " -3.85613680e-01 -2.08568394e-01 -3.68319452e-01 -7.69151747e-01\n",
      " -1.23189926e-01  6.04467213e-01  2.10557222e-01 -9.73532557e-01\n",
      " -1.89230525e+00  3.76694322e-01 -4.14181650e-01  4.26140487e-01\n",
      "  6.01336360e-01 -1.60073817e+00 -1.03943920e+00 -3.80068541e-01\n",
      " -9.12954390e-01 -1.34677434e+00  2.58312136e-01  2.55000800e-01\n",
      " -1.88209224e+00 -3.64398539e-01 -1.22163725e+00 -4.24048841e-01\n",
      "  3.04871470e-01 -5.15815496e-01 -2.31188357e-01  5.90519309e-02\n",
      " -1.41181314e+00 -1.62375021e+00 -4.66976702e-01 -2.90418506e-01\n",
      "  7.58740306e-01  3.80425811e-01  2.11894929e-01 -1.08296365e-01\n",
      " -1.09735215e+00 -1.24630260e+00  2.05943227e-01 -6.85158968e-01\n",
      " -4.89420667e-02 -1.21959019e+00 -2.94507408e+00 -1.25789070e+00\n",
      " -9.81804430e-01 -1.77874243e+00 -1.34722161e+00 -1.29843831e-01\n",
      "  3.32184672e-01  5.24340689e-01 -1.11102259e+00 -7.82547534e-01\n",
      "  9.01685357e-02 -9.23143864e-01  1.45997286e+00 -4.27843601e-01\n",
      " -1.11014938e+00  2.95413613e-01 -1.62266147e+00 -6.88836634e-01\n",
      " -1.53355062e-01 -1.45527554e+00 -2.77700257e+00 -2.19393373e+00\n",
      "  6.65301800e-01 -2.03305125e-01 -1.01022148e+00 -3.28052431e-01\n",
      " -4.56370783e+00 -2.97762156e-01 -7.17956305e-01 -1.48907435e+00\n",
      " -1.23620361e-01 -6.43467605e-01 -3.39751601e-01 -2.86565065e-01\n",
      " -1.63303506e+00 -1.73646629e-01 -8.71239245e-01  3.40243459e-01\n",
      " -1.29874635e+00 -1.44400418e+00 -1.32252049e+00 -1.58033061e+00\n",
      " -1.50512531e-01 -1.40554905e-02 -6.14735484e-02 -1.51768899e+00\n",
      " -2.21653271e+00 -2.88410962e-01 -1.09123051e-01 -5.91747105e-01\n",
      "  5.33234477e-01 -6.00505948e-01 -7.50478208e-02 -1.53794849e+00\n",
      " -5.87704003e-01 -5.59585869e-01 -3.03012192e-01 -1.55244899e+00\n",
      " -1.75700569e+00 -1.17666900e+00 -4.02051270e-01  3.43832612e-01\n",
      " -1.15726531e+00 -1.17411959e+00 -6.26213551e-01  4.83251810e-02\n",
      "  1.46523118e-01 -8.47389936e-01 -7.94120550e-01  2.67867327e-01\n",
      " -2.43300533e+00 -5.27110934e-01 -3.84901047e-01 -3.11265755e+00\n",
      " -5.56642294e-01 -1.94241643e-01 -8.98111165e-01 -3.15046728e-01\n",
      " -8.42238069e-01 -5.80196261e-01 -3.18096220e-01 -1.81399918e+00\n",
      " -1.26203179e-01 -3.60211313e-01 -1.29691553e+00 -1.53010297e+00\n",
      " -2.61569881e+00 -1.78393096e-01  7.96420574e-01 -1.51419699e-01\n",
      "  4.41137671e-01  1.18658352e+00 -2.19446182e+00  7.67055303e-02\n",
      "  2.16133296e-01 -1.13915682e+00 -1.00828958e+00 -2.22722411e+00\n",
      " -1.57297421e+00 -1.40053523e+00  4.73928690e-01 -1.32819343e+00\n",
      "  8.41492787e-02 -2.31131816e+00 -1.54202473e+00  1.04587317e-01\n",
      " -5.57545781e-01 -1.67159784e+00 -1.36043370e-01  5.18659949e-02\n",
      "  2.99588442e-02 -1.22970688e+00 -1.78885293e+00  1.27001369e+00\n",
      "  1.34367138e-01 -1.94720745e-01  1.51738882e-01  2.51420587e-02\n",
      " -1.13199461e+00 -2.11133748e-01 -1.75085902e+00  4.73122895e-01\n",
      " -4.53674197e-02 -1.45865846e+00  7.45425701e-01 -1.99890947e+00\n",
      " -2.72022188e-02 -8.04839492e-01  2.11392939e-01 -8.48065019e-01\n",
      "  1.61898673e-01  4.57490683e-02 -4.75072265e-01 -1.32390749e+00\n",
      " -1.29352069e+00 -1.15337443e+00 -6.31905198e-02 -1.70105904e-01\n",
      " -5.91678917e-01 -1.00997078e+00 -2.61718839e-01 -6.85710728e-01\n",
      "  6.93277001e-01 -8.32618475e-01 -3.67544442e-01  5.32547832e-02\n",
      "  3.28910708e-01 -2.09407806e+00  1.55007660e+00 -1.25535965e+00\n",
      "  3.53507757e-01 -2.17216039e+00 -3.44472468e-01  4.06648815e-02\n",
      "  2.32014060e-02 -2.57897973e+00 -1.62926018e-01 -8.57663691e-01\n",
      " -2.54803509e-01  4.55929041e-01 -1.70441735e+00 -1.38326478e+00\n",
      " -1.65493786e+00 -1.72443748e+00  2.64884591e-01 -8.35319579e-01\n",
      " -7.67013252e-01  4.83055353e-01 -2.51374602e-01  4.66885746e-01\n",
      "  5.06662488e-01  4.19975460e-01 -1.64369345e-02 -1.10533464e+00\n",
      " -7.00157940e-01 -1.05791545e+00  3.82088482e-01 -1.27220988e+00\n",
      " -1.25007224e+00 -2.17108667e-01  1.26268864e-02 -8.32731366e-01\n",
      " -3.35558951e-01  2.32023045e-01 -6.86206818e-02 -2.32136667e-01\n",
      " -1.44237626e+00 -2.14152575e+00 -7.18852997e-01  4.04125512e-01\n",
      " -1.13705516e-01  3.25006127e-01 -2.78245163e+00 -1.83867800e+00\n",
      "  1.80396318e-01 -8.14414024e-02 -1.34232849e-01 -1.34051979e-01\n",
      " -8.81084681e-01  5.15093088e-01 -1.97395110e+00 -9.86726880e-01\n",
      " -1.59677911e+00 -2.04136276e+00  2.67356157e-01  7.26032794e-01\n",
      "  3.73580128e-01 -3.12275577e+00  4.45891470e-02 -1.47315010e-01\n",
      "  6.38983130e-01  2.43217021e-01 -1.49084377e+00 -1.22469807e+00\n",
      "  1.25131488e-01 -7.67222643e-01 -1.13651919e+00 -6.41619921e-01\n",
      "  1.44974709e-01  9.67503786e-02 -2.53871799e-01 -5.59595287e-01\n",
      " -1.43759370e+00  4.30020630e-01  3.95780563e-01  8.39644969e-02\n",
      " -1.89861059e-01 -5.52440405e-01  6.26268268e-01 -1.37644649e+00\n",
      " -2.80336142e-01  1.92025661e-01 -2.79613733e-01  2.44681478e-01\n",
      " -1.00040424e+00 -9.68267918e-01 -1.28222823e+00 -1.49180329e+00\n",
      " -1.69405174e+00 -5.75111508e-02 -6.16250396e-01  1.98415339e-01\n",
      " -1.09959364e+00  3.28701735e-03 -2.26850605e+00  4.21069264e-02\n",
      " -1.13966811e+00  1.66333735e+00  1.16716325e-01 -1.12638760e+00\n",
      "  2.34108537e-01 -2.27469826e+00 -1.03724456e+00  8.84939551e-01\n",
      " -1.18207932e+00  2.02483535e-02 -1.37197948e+00 -2.40703678e+00\n",
      " -3.32862329e+00  6.29308343e-01 -1.03675056e+00  1.87287772e+00\n",
      "  3.11024785e-02 -1.88376188e+00 -1.71297991e+00  4.30832148e-01\n",
      " -1.32638216e+00 -1.62919116e+00  1.04555666e-01 -1.35644722e+00\n",
      "  4.55999136e-01 -1.96004343e+00 -1.93612981e+00 -5.23188114e-02\n",
      "  1.84109628e-01 -1.37269688e+00  1.06478024e+00  1.22372061e-01\n",
      " -1.52706218e+00 -6.59025908e-02 -2.54556465e+00 -2.43927526e+00\n",
      "  3.05194944e-01 -1.22536302e+00 -5.28341949e-01  1.94698298e+00\n",
      " -1.87648785e+00 -3.95072281e-01  1.29826069e-02 -1.50872636e+00\n",
      "  5.39159775e-03  2.26656532e+00  1.16195083e-01 -4.49146748e+00\n",
      " -1.91609049e+00 -1.62515259e+00 -1.40766931e+00 -6.59015656e-01\n",
      " -1.98303580e+00 -3.48056257e-01 -3.01071346e-01 -2.55563378e+00\n",
      "  8.39355230e-01 -1.66710508e+00 -9.44216609e-01 -2.44028139e+00\n",
      " -1.14566946e+00 -8.54809821e-01  5.28462112e-01  1.35718912e-01\n",
      " -2.72509933e-01 -2.17388678e+00 -1.19476187e+00 -1.16068316e+00\n",
      "  9.83616710e-02  2.02575177e-01 -9.52677548e-01  9.04840231e-03\n",
      " -3.81391615e-01 -6.01818487e-02 -9.13543940e-01 -1.89003646e-02\n",
      " -3.19493365e+00 -6.42007589e-02 -1.88785243e+00 -1.67327142e+00\n",
      "  6.39443994e-01 -1.43761182e+00  7.43027091e-01 -9.01950359e-01\n",
      " -7.70288706e-03 -4.25776631e-01 -1.21921492e+00 -1.75550807e+00\n",
      " -6.80946112e-01  3.57593507e-01 -7.76907921e-01 -1.46262598e+00\n",
      " -4.08229709e-01 -1.15379453e+00 -2.32883310e+00 -4.49660003e-01\n",
      " -2.20350051e+00 -1.53277445e+00 -3.30672264e-02 -8.89604270e-01\n",
      "  4.07949984e-02 -1.23265016e+00  4.37838435e-02 -4.76691067e-01\n",
      " -2.40117610e-02 -2.76385093e+00 -4.87559378e-01 -4.10196185e-02\n",
      "  4.72225308e-01 -5.54125369e-01 -9.39431012e-01  5.90903044e-01\n",
      "  1.53189230e+00 -6.90317690e-01 -1.75787181e-01 -6.41672313e-02\n",
      " -1.15410817e+00 -1.29590839e-01 -2.00881863e+00  6.34044468e-01\n",
      " -1.11101389e+00 -5.06577194e-01 -4.64293301e-01 -1.94299960e+00\n",
      " -1.28022146e+00  8.29164743e-01 -1.58720553e-01 -1.40386319e+00\n",
      " -5.79241753e-01  7.43601143e-01 -5.62577724e-01 -1.16538882e-01\n",
      "  1.45778656e-02  7.63224721e-01 -1.32518816e+00 -7.61323869e-02\n",
      " -1.41616774e+00 -9.97879505e-02 -8.07241499e-01 -1.49470913e+00\n",
      "  5.70495725e-02 -2.14014030e+00 -9.39098597e-01 -2.29255289e-01\n",
      " -2.16324925e-02 -2.64827347e+00 -4.45387542e-01 -9.99517322e-01\n",
      "  6.95707917e-01 -5.61620474e-01 -3.80646527e-01 -6.71554089e-01\n",
      " -1.78403592e+00 -8.42801034e-01 -8.40148330e-03 -1.79058909e-01\n",
      " -6.29333377e-01  1.07369363e-01 -9.05508637e-01 -1.29586482e+00\n",
      " -1.99341416e-01  3.00404757e-01 -2.25741237e-01  2.34024262e+00\n",
      "  9.94245410e-02 -2.27541924e-02  2.49588773e-01 -2.44102359e-01\n",
      " -2.19078445e+00 -1.89536303e-01 -1.99475241e+00  7.09564686e-02\n",
      " -1.65912509e-02  2.22839147e-01 -4.64112163e-01  1.04499757e-01\n",
      " -8.56164336e-01 -3.34715307e-01 -2.67995024e+00 -1.04734743e+00\n",
      "  7.98009455e-01 -1.38890028e-01  1.95960909e-01  2.73958325e-01\n",
      " -2.59132028e-01 -1.27653921e+00 -1.71695805e+00 -1.05860913e+00\n",
      " -5.65203071e-01 -3.16441536e+00 -3.98311257e-01  2.16974199e-01\n",
      " -5.74158549e-01 -2.03103185e-01 -1.27290797e+00 -1.43352699e+00\n",
      "  8.12733054e-01 -2.46025944e+00 -8.69259596e-01 -5.17270148e-01\n",
      " -1.31366837e+00 -2.29440570e-01 -1.45514643e+00 -4.41198051e-01\n",
      " -2.72497535e-02 -1.32160759e+00 -1.59106851e+00 -5.55253267e-01\n",
      " -3.62015367e-02 -2.74654567e-01 -2.44751364e-01 -1.18491066e+00\n",
      " -2.40756202e+00 -1.24957013e+00 -5.65524220e-01 -1.35978997e+00]\n",
      "9 [-0.16244945  0.52733105 -0.03875601  0.19107378  0.9135614   1.9143717\n",
      "  1.0495374   0.8213359   0.43146673  1.891756    0.590399    0.6190915\n",
      "  0.3397044   0.35405868  0.19718027  0.35895765 -0.22843169 -0.44949663\n",
      "  0.5037784  -0.18946856  0.20329672  0.92635155  0.20723787 -0.26428366\n",
      " -0.6589147   0.40471047 -2.6538227   0.6132858  -0.29559034  0.34649277\n",
      " -2.6452699  -1.0003712   1.3029417  -1.0017116  -0.01448232 -1.9677072\n",
      "  0.63369703  0.5769495  -2.086146   -2.3323386   0.6961444   1.0443726\n",
      "  0.07042812  0.20847869  1.6273087  -0.21174176  0.46342486 -0.15635371\n",
      " -0.22431785 -0.5394894   0.13115847  0.40470868 -0.33738995  0.35578766\n",
      "  0.62985796  0.01633728  1.0984567   0.8472931  -0.59020406  1.2730551\n",
      " -0.51718235 -0.50640947  0.75115037 -0.31283945 -0.2391212   0.08255076\n",
      "  1.9231169   0.37284893 -0.51892203  2.4963377   1.3451155   1.1917055\n",
      "  0.7300166   0.13915737  0.9870453   1.0464941   2.1371536   1.7895527\n",
      "  0.21007717  0.37426364 -1.0802449  -0.27651498  0.9981075   0.37755805\n",
      "  0.9831388   0.9159451  -0.48740196  1.2939804   2.766574   -0.07463342\n",
      "  1.2610743  -0.39826244  0.9729896   1.1272411  -1.7018224   0.30968243\n",
      " -1.2243446   0.5843892   1.0451672   0.71914756  0.08328956  1.0853862\n",
      " -1.0353736  -0.5693889   1.453932    0.73975515  0.6246146   0.7209792\n",
      "  0.7589017   1.3909197  -0.5988164   0.81901705 -0.6498967   0.07740687\n",
      " -4.3640532  -1.955248   -1.8410687   1.4243277   1.419002   -0.31601048\n",
      " -0.82027805 -0.00553614 -0.03893768  0.90343904 -0.04801416 -1.7115304\n",
      "  0.06634575 -0.09959093 -0.81442493  0.54441637  0.5604402  -0.90421605\n",
      "  1.8097137   0.37946922 -0.8628072  -0.10236895  0.9778868   0.6185786\n",
      "  0.30728537  5.0788584   0.28732038  0.03584123  0.62040293 -0.33049768\n",
      "  0.29302835 -1.1364816   0.5385626   0.18413413  0.01642483  0.14745653\n",
      "  0.13733214  0.78403383  1.1070101   0.3407328   0.6604941   0.06310809\n",
      "  0.16057879  0.43438166  2.738776    0.6569185  -0.8606896   0.7637594\n",
      "  0.8540379  -0.95461047  0.17875075  0.92337584  0.56318295  0.9485967\n",
      "  1.3819811   0.59962213  0.71675897 -0.4393807   1.2276986   0.8578544\n",
      "  0.9397204  -2.1294358   0.5047419  -0.5180199  -0.36936167 -1.4501946\n",
      "  1.2101862   1.0795108   0.17371908  0.2564539  -0.16526186  0.6024857\n",
      "  1.3868095   0.7505321   1.7466942   1.44664     0.46795765  1.0939347\n",
      "  0.76504713  0.2622875   1.8868258   0.4457009   0.6401412   0.4056077\n",
      " -1.6153843   0.5249354   0.5684376  -0.15418565 -0.6634915  -1.0530754\n",
      "  2.2725258   0.80169994  1.4182324   1.5935496  -0.5805012   1.2062179\n",
      " -0.72852945  0.83909875  1.8984888   1.7309105  -0.39595163  0.5169894\n",
      " -0.69385034 -0.46447635  1.2526867  -0.67807245  1.7582669   0.7850187\n",
      "  1.2743245   1.0189418   1.0223547   1.332578    1.3598855   1.199915\n",
      " -0.52001786  0.92861813 -1.8578426  -0.3309503   0.8684083   0.09552151\n",
      "  1.2037795  -0.9279038  -0.36442816  0.8921793   1.2105806   0.60514736\n",
      "  0.52452785 -0.28750706 -1.3669553   0.3802426   0.55648124 -2.559177\n",
      "  0.8103137  -3.765378    0.81208336  0.31148934  1.1168958  -2.835862\n",
      "  0.61483085 -5.4931483   0.85596687  0.52922976]\n",
      "10 [ 4.09102559e-01 -1.21004677e+00  1.13489366e+00  1.17242146e+00\n",
      " -4.46412042e-02  7.01844096e-01  3.23676825e-01  5.88529050e-01\n",
      " -4.49029255e+00  3.84767592e-01 -3.43078882e-01  7.40542471e-01\n",
      " -1.45396173e-01  8.11138988e-01  2.73241371e-01  1.04450381e+00\n",
      "  9.16459411e-02  1.48124790e+00 -3.04866493e-01  5.43368578e-01\n",
      "  1.11049938e+00 -6.84176311e-02 -1.15275884e+00 -6.49942398e-01\n",
      " -7.14331567e-01 -1.83460891e-01  6.45886302e-01  8.51131320e-01\n",
      "  5.75666368e-01 -9.72715974e-01  5.65257311e-01 -7.87097752e-01\n",
      " -1.10110015e-01  4.93750632e-01  6.84424400e-01 -4.72058058e-02\n",
      "  1.15721893e+00 -2.43044662e+00  3.94405514e-01 -9.06338573e-01\n",
      "  7.67397940e-01  5.25825739e-01  1.79449886e-01 -2.02236682e-01\n",
      " -1.59818307e-02  9.32147920e-01  2.79562175e-03  4.06559199e-01\n",
      "  1.25068200e+00  8.96627665e-01  8.20799530e-01 -3.98489177e-01\n",
      "  8.26921403e-01  2.33703643e-01 -5.77259719e-01  1.89843953e-01\n",
      "  1.07771373e+00 -5.81145287e-01  5.68633676e-01 -3.93848538e-01\n",
      "  1.22310305e+00 -1.27659452e+00  1.96481013e+00 -1.33432496e+00\n",
      " -3.37631434e-01  6.08926475e-01  6.62633002e-01  8.19898367e-01\n",
      "  8.09405744e-01  1.06495786e+00  1.19269395e+00  4.17237818e-01\n",
      "  6.85838699e-01  9.93781567e-01  4.44646776e-01  1.53374434e-01\n",
      "  2.00600564e-01  6.30137444e-01 -3.37812483e-01  4.90820765e-01\n",
      "  7.30109215e-01  9.19103682e-01 -6.32044315e-01  5.14042079e-02\n",
      " -8.99762392e-01  7.36337543e-01  8.80476356e-01  1.54117033e-01\n",
      " -3.61361027e-01  3.65701556e-01  7.15076149e-01 -5.13774157e-01\n",
      "  5.36855161e-01  6.59310937e-01 -1.83565605e+00  1.11870259e-01\n",
      "  8.95028889e-01 -5.34211099e-01  2.01282835e+00 -9.94789600e-03\n",
      "  4.25939083e-01  9.55790877e-02  5.52740157e-01  5.52336574e-01\n",
      " -3.27517927e-01 -8.18596482e-02  7.69112229e-01 -2.44147229e+00\n",
      "  3.22347999e-01 -7.73228765e-01  8.74293625e-01 -1.68691015e+00\n",
      " -6.89997017e-01 -8.61599445e-02  7.75247216e-01  1.74872845e-01\n",
      "  1.23992294e-01 -3.18119347e-01  3.62398267e-01  1.13482749e+00\n",
      " -3.27953696e-03  1.70406222e-01  1.83062077e-01  8.54271710e-01\n",
      " -1.02812147e+00 -2.90337801e-01  5.46292961e-01  7.64329851e-01\n",
      " -8.53051722e-01  7.59931803e-02  1.15578324e-01 -2.01402903e-01\n",
      "  5.80250740e-01 -1.57052293e-01  8.17386031e-01  2.28506422e+00\n",
      "  6.85086399e-02  4.49282169e-01 -4.31578368e-01 -1.10924220e+00\n",
      " -6.79967821e-01  1.60418928e-01  6.53241515e-01  1.03170693e+00\n",
      " -8.60422552e-02 -3.06704789e-01 -1.66043651e+00 -1.14345014e+00\n",
      "  8.14593434e-01 -1.20897341e+00  5.48677504e-01  1.54037631e+00\n",
      " -5.26837349e-01  1.34822631e+00  6.25156641e-01 -2.27625556e-02\n",
      "  8.75787437e-01 -2.06195384e-01  4.12209332e-01  3.87538254e-01\n",
      " -1.03345740e+00  5.57440519e-01 -9.77784038e-01 -2.07672882e+00\n",
      " -2.21701074e+00 -4.15294230e-01 -1.48811907e-01  6.63716614e-01\n",
      "  7.12696850e-01  2.83242702e-01  4.08645838e-01  1.27242887e+00\n",
      "  3.01779449e-01  8.93668652e-01 -4.67074871e-01  8.83211732e-01\n",
      "  3.57428765e+00  4.36762393e-01  6.32476032e-01  3.95851195e-01\n",
      "  1.02876461e+00  1.60089552e-01  4.27091986e-01 -3.38368034e+00\n",
      " -4.42317605e-01  1.30942777e-01  4.59207922e-01  3.31981599e-01\n",
      "  3.18166405e-01  6.69656098e-01  2.97093296e+00  1.32677424e+00\n",
      "  2.50682533e-01  5.30590415e-01  8.72876346e-01 -7.02847838e-02\n",
      "  2.14049745e+00 -3.07750654e+00 -7.64816701e-01  1.26922488e+00\n",
      "  8.28250349e-01  2.96706057e+00  7.75467098e-01  7.19811857e-01\n",
      "  5.71031749e-01  8.23287487e-01 -3.16440439e+00  1.28737378e+00\n",
      "  9.18533504e-01 -3.16477865e-02  7.66961217e-01  6.20574132e-03\n",
      "  1.33089733e+00 -1.20275199e+00 -8.97790551e-01  1.11200154e+00\n",
      " -1.09898758e+00 -2.71109045e-02  1.97200105e-01  7.75867701e-01\n",
      "  8.47205758e-01  6.47162437e-01  6.58790886e-01 -3.73945642e+00\n",
      " -1.67060363e+00 -7.59691000e-03  1.27065349e+00  1.46003747e+00\n",
      "  3.62931043e-01 -1.65612972e+00  8.01723361e-01  2.17875600e-01\n",
      "  1.36177778e+00  1.28966260e+00 -5.55378199e-01  8.60877872e-01\n",
      " -6.23333573e-01  4.39923584e-01  8.22159588e-01  6.58369660e-01\n",
      "  7.02447891e-01  3.85926151e+00 -1.40956712e+00  5.27789474e-01\n",
      "  1.28668249e-01 -1.24729502e+00 -2.64524728e-01  3.12454194e-01\n",
      "  6.35634959e-01  6.51583493e-01 -1.13948083e+00  6.01480365e-01\n",
      "  2.90874124e-01  9.17446375e-01  4.74936128e-01  8.81507993e-01\n",
      "  1.50820017e-01  9.00567114e-01  4.13565367e-01  8.54560018e-01\n",
      " -3.90185922e-01  2.22526836e+00  5.97132027e-01 -6.40484571e-01\n",
      "  5.13007045e-01 -4.95475471e-01  8.46458375e-01 -1.60831380e+00\n",
      "  6.79203987e-01  8.68594170e-01 -1.85538256e+00 -3.96666527e-01\n",
      " -6.10977590e-01  7.30618954e-01  1.08164892e-01 -1.48719400e-01\n",
      "  5.38828373e-01  5.47690213e-01  2.75770724e-01  3.94928098e-01\n",
      "  9.95331526e-01  6.20425403e-01  7.69998670e-01  1.73392817e-01\n",
      "  2.46396184e-01  5.54783106e-01 -1.82480931e+00 -7.60613084e-01\n",
      " -4.77025658e-02 -2.64441848e+00 -1.45755067e-01  6.29636049e-01\n",
      " -2.14871317e-01 -4.21579599e-01  1.02401257e+00 -2.97293186e-01\n",
      "  3.00147057e-01  1.01226902e+00  8.26111794e-01  3.55580717e-01\n",
      "  8.91505837e-01  4.08169508e-01  9.99361813e-01  1.85659993e+00\n",
      "  7.11580753e-01 -5.04023433e-02 -1.18101072e+00  5.42029858e-01\n",
      "  7.99188733e-01  7.16523349e-01  9.49082017e-01 -6.69332743e-02\n",
      " -1.71811783e+00  4.42825139e-01  9.07709658e-01  4.35781032e-01\n",
      "  1.76976991e+00  2.31184721e-01  8.35698068e-01  1.11925030e+00\n",
      "  9.15331066e-01  1.04057717e+00 -1.46176565e+00  7.69438088e-01\n",
      "  1.06149435e+00  1.51102281e+00  1.94443345e-01  6.00514948e-01\n",
      " -5.78763485e-01  1.98924273e-01  1.19536400e-01 -2.19950032e+00\n",
      "  2.43713260e-01 -2.15185285e-02  1.01798022e+00  4.89493966e-01\n",
      " -5.78393579e-01  7.03073740e-01  7.80658066e-01 -1.14611294e-02\n",
      "  3.03671002e-01 -1.26262510e+00  7.30724275e-01  1.58645421e-01\n",
      "  5.78447759e-01  4.47143078e-01  5.98901868e-01  1.91917926e-01\n",
      "  3.55971432e+00  2.18143970e-01  1.66513669e+00 -5.82956612e-01\n",
      "  5.97170174e-01 -9.13927555e-02 -6.88129663e-03  4.28572208e-01\n",
      "  3.88381153e-01  9.49626327e-01  1.42452136e-01  9.39090073e-01\n",
      " -6.48804784e-01  1.09982479e+00  1.87068522e-01  1.10222816e+00\n",
      " -3.54728878e-01  4.55799103e-01  4.51285362e-01  1.26617873e+00\n",
      " -7.97768235e-01  5.56778193e-01  6.33218884e-01 -7.65140772e-01\n",
      "  6.81837797e-02  3.70963216e-01  8.39170814e-02  3.51927608e-01\n",
      " -7.50634551e-01  6.77106857e-01  1.00439358e+00  1.06088114e+00\n",
      "  6.17132783e-01  1.16093266e+00 -2.44168580e-01  1.54846215e+00\n",
      " -4.95437741e-01  4.40416396e-01  3.27508688e-01  6.97643161e-01\n",
      "  1.62505090e-01  9.44324970e-01  8.91687870e-01 -6.00621462e-01\n",
      " -1.65505672e+00  1.09084511e+00  8.22612762e-01  4.17093337e-01\n",
      "  1.28528678e+00 -4.93479252e-01 -8.46720338e-01 -4.82643008e-01\n",
      "  4.16470766e-01  6.43730521e-01  9.83512878e-01  1.41274977e+00\n",
      "  5.78393102e-01  6.73756123e-01  7.05880165e-01  3.93086910e-01\n",
      " -4.39860404e-01 -6.06491745e-01  3.16873193e-03  9.00027215e-01\n",
      " -1.54004622e+00 -2.27024078e-01  1.13401699e+00 -1.44297659e-01\n",
      "  6.58666492e-01 -8.93319964e-01  2.08231032e-01  2.51492572e+00\n",
      "  6.31874800e-01  6.90989316e-01  1.45870495e+00  9.84802842e-01\n",
      "  3.17373037e-01 -6.15339339e-01  9.06791210e-01  1.83209562e+00\n",
      "  2.91322917e-01  4.45835829e-01 -3.63168597e-01  8.06410193e-01\n",
      "  1.83032966e+00  2.09998131e-01  5.02950609e-01 -7.16699243e-01\n",
      "  1.26536918e+00 -6.75542712e-01  3.36706638e-04  1.90049076e+00\n",
      "  4.37427878e-01  1.53794527e+00  4.39310849e-01  1.37118125e+00\n",
      "  3.94737661e-01  9.53460515e-01  5.55700660e-02  8.10065269e-02\n",
      "  6.83518171e-01  5.63884974e-01  3.68900299e-01  3.58647346e-01\n",
      "  4.59833890e-01 -6.78582489e-03  9.09663320e-01  5.13005137e-01\n",
      "  2.85454810e-01  3.07120824e+00  9.23190266e-02  2.82190204e-01\n",
      " -2.02671170e+00  2.58618414e-01 -3.34628642e-01  3.72565687e-01\n",
      "  9.95537937e-02 -1.11004867e-01  8.57538104e-01  1.81353021e+00\n",
      "  5.91432452e-01  3.15605044e-01  9.96326566e-01  5.84639311e-01\n",
      " -1.95093274e-01  2.69255817e-01  3.91542524e-01  6.01677716e-01\n",
      "  5.50366282e-01  6.28066778e-01  7.24408507e-01  2.39647239e-01\n",
      " -7.30609417e-01  1.04559827e+00  1.21325660e+00  9.64893758e-01\n",
      "  7.34955072e-01 -7.93553710e-01  4.03141290e-01  1.20616293e+00\n",
      "  2.10775167e-01  1.34226322e+00 -1.78404641e+00  8.92769456e-01\n",
      " -2.09271014e-01  4.21209753e-01 -1.32816866e-01  5.07167220e-01\n",
      "  3.20233643e-01  1.35547018e+00  7.54840493e-01 -5.92478216e-02\n",
      " -5.54785848e-01  7.27683663e-01 -2.31250334e+00  1.20933104e+00\n",
      "  5.95958650e-01  3.18588585e-01  1.96063519e-01  2.65206933e-01\n",
      "  4.89665270e-01 -1.62589812e+00 -2.85026431e-02  8.14355791e-01]\n",
      "11 [ 2.3298275e-01  1.3689523e+00  2.1173635e+00  9.5609868e-01\n",
      "  9.0486437e-01  1.5314357e+00  1.4731007e+00  1.6601967e+00\n",
      "  1.7797188e+00  1.4336661e+00 -7.2818100e-02  2.8132510e-01\n",
      "  1.8572298e+00  2.0913477e+00  2.6476294e-02  1.1859982e+00\n",
      " -5.2477390e-01  1.1622553e+00 -4.3403259e-01  3.8977391e-01\n",
      "  1.7856147e+00  1.1071274e+00 -8.3161008e-01  1.6504610e+00\n",
      "  2.6158433e+00  2.9050698e+00  9.0137398e-01  1.5574408e+00\n",
      " -6.5197587e-01  2.8258257e+00  1.0022957e+00  4.3974009e+00\n",
      "  9.6385330e-01  1.1376258e+00  1.1891659e+00  2.3332624e+00\n",
      "  5.7860154e-01  1.1188209e+00  2.1049745e+00 -7.5859249e-01\n",
      " -1.4900848e-01  1.7285473e+00  1.3632635e+00  1.2071397e+00\n",
      "  6.8496788e-01  7.5384074e-01  2.6790279e-01  3.2918673e+00\n",
      "  2.4786224e+00  1.3317037e-01 -1.2738551e-01  1.7371898e+00\n",
      "  5.1323175e-01  1.1615584e+00  1.3142177e+00  1.9702873e+00\n",
      " -1.3850300e+00  5.4186678e-01 -1.1050196e+00  2.2530744e+00\n",
      "  1.1397393e+00  8.7673169e-01  1.1189682e+00  6.7891777e-02\n",
      "  7.4662298e-01  2.7621489e+00  2.6758146e+00  1.0705609e+00\n",
      "  7.8949678e-01  1.7924562e+00  9.2828453e-02  2.6238972e-01\n",
      "  1.0085461e+00  2.9397175e+00  3.1162324e+00  1.5262429e+00\n",
      "  3.7432447e-01  1.5044737e-01  9.9796546e-01 -9.9993658e-01\n",
      "  1.0740523e+00 -1.7002887e-01 -1.6741602e-01  6.7663109e-01\n",
      "  2.7517962e-01  8.2536286e-01  3.5346991e-01 -4.7490031e-02\n",
      "  1.1292260e+00  1.1040368e+00  3.0648342e-01  4.0264683e+00\n",
      "  2.0720940e+00  3.2286091e+00  3.6907196e-04  8.9913249e-02\n",
      "  1.5149324e+00  2.2750230e+00  7.5637150e-01  4.1110423e-01\n",
      "  2.4012182e+00  1.2810392e+00  1.3396957e+00  1.7364883e+00\n",
      "  1.1207198e+00  2.2634945e+00  4.9974105e-01  3.7171233e-01\n",
      "  1.6571945e-01  1.1748004e+00  1.1278113e+00  1.4036824e+00\n",
      " -5.7762089e+00 -1.5253029e+00  3.0385094e+00  9.0641838e-01\n",
      " -1.9788890e-01  1.6028215e+00  1.0389689e+00 -7.9141700e-01\n",
      "  1.5059768e+00  1.8032868e+00  1.0731685e-01  1.8148214e+00\n",
      " -9.7139138e-01 -3.8869524e-01 -1.0819592e+00  2.3828204e+00\n",
      "  1.8296041e+00  4.9804607e-01 -6.5205777e-01  8.9632821e-01\n",
      "  1.4809291e+00  2.3830419e+00  2.0566983e+00  6.6693485e-01\n",
      "  1.6684389e+00  1.1097337e+00  4.0912285e+00  3.1631267e-01\n",
      "  3.3221978e-01  3.8976628e-01  2.3631614e-01  2.7270908e+00\n",
      " -4.8514023e+00 -1.0085964e-01 -1.4914781e-02  1.9830313e+00\n",
      "  1.2356058e+00  8.6333019e-01  8.2140923e-01  1.0765469e-01\n",
      "  1.6113054e+00  2.0019705e+00  1.1767600e+00  3.1224513e+00\n",
      " -4.8401952e-04  1.4430599e+00 -5.8679575e-01  7.4452221e-01\n",
      "  1.2663337e+00  3.0031830e-02  9.3849230e-01  1.3492193e+00\n",
      "  1.2894746e+00  1.0264993e+00  1.8707916e+00 -8.4988689e-01\n",
      "  1.8467700e+00  1.8413675e+00 -1.8406218e-01  1.5251468e+00\n",
      "  2.1048880e+00  1.5546257e+00  7.7433312e-01  1.1549319e+00\n",
      "  1.4012300e+00  2.5029361e-02  3.2329941e-01  1.8223218e+00\n",
      "  1.9659559e+00  1.4464824e+00  2.8033713e-01  1.9538229e+00\n",
      "  8.8836682e-01  1.1162285e+00  1.5095412e+00  1.9992188e+00\n",
      "  1.9076730e+00  1.9861435e+00  1.0026395e+00  3.6510744e+00\n",
      " -2.3024712e+00  1.9445924e+00  1.8323063e+00  1.7857695e+00\n",
      "  2.8629631e-02  1.0091326e+00 -4.3383378e-01  1.1239955e+00\n",
      "  3.1762552e+00  2.0028343e+00  3.2638628e+00  1.3968180e+00\n",
      "  1.0835483e+00  4.0802112e-01  1.6296405e+00 -6.1195982e-01\n",
      "  2.2700996e+00  1.1633980e+00  3.0141225e+00  1.2620199e+00\n",
      "  1.5192357e+00  1.0557388e+00  2.5258121e+00  1.5068275e+00\n",
      "  9.8772722e-01 -7.3697954e-01 -2.8388381e-02  1.9398110e+00\n",
      " -6.5492356e-01  1.9095600e+00  4.4267311e+00  1.8404881e+00\n",
      "  1.1442772e+00  9.5984501e-01  2.0586641e+00  1.3507848e+00\n",
      "  1.7513609e+00 -3.1562266e-01  1.5185850e+00  1.4980217e+00\n",
      "  1.2972397e+00  1.4824936e-01  1.1341002e+00  9.0849411e-01\n",
      "  1.9240370e+00  1.7292002e+00  1.5363210e+00  1.4946868e+00\n",
      "  2.2424608e-01  2.1586280e+00  1.7323804e+00  2.0716054e+00\n",
      " -2.4669287e-01  2.8233027e-01 -8.1162530e-01  4.1012163e+00\n",
      "  1.6588359e+00  2.3412609e-01  4.8885909e-01 -8.5944223e-01\n",
      "  9.0050805e-01  1.2305866e+00 -1.3599892e+00  1.0472314e+00]\n",
      "12 [-1.04380667e+00 -8.41842294e-01 -9.50069547e-01 -5.52155256e-01\n",
      " -7.84330010e-01 -2.26069689e-02  9.19552803e-01 -2.53083825e-01\n",
      " -1.66891813e-01 -2.71920323e-01  7.67149329e-01 -4.95254397e-01\n",
      " -1.86275160e+00  3.31369638e-02 -6.75213933e-01 -1.22250664e+00\n",
      "  2.41718769e-01  1.00736189e+00 -3.66725922e-02  2.68336177e-01\n",
      " -9.38252747e-01 -3.61041546e-01 -7.19269037e-01  7.21687198e-01\n",
      " -6.65626109e-01  5.98713160e-02  9.21781778e-01 -6.91361308e-01\n",
      " -1.85213685e-02  1.22684789e+00 -4.72229481e-01 -7.42251649e-02\n",
      " -6.87411308e-01 -1.21092629e+00 -1.47272909e+00 -1.74594569e+00\n",
      "  6.29346967e-01  6.87872291e-01  3.35910797e-01 -1.40399122e+00\n",
      "  1.30939841e-01  9.45760012e-02 -6.82345867e-01 -1.01942492e+00\n",
      "  6.35689974e-01 -7.80691385e-01 -6.68389440e-01 -1.42454147e+00\n",
      " -9.73180532e-01 -1.14354277e+00  1.10656261e-01  4.65786219e-01\n",
      " -1.23360157e-01 -9.98533010e-01 -8.53329301e-01 -7.89262772e-01\n",
      " -3.19338918e-01 -7.65143156e-01 -6.92123175e-02  2.45068431e-01\n",
      " -2.03206897e+00  7.22665429e-01  1.72747493e-01 -3.98840070e-01\n",
      "  2.44099021e-01 -6.81335092e-01 -1.98440671e-01 -2.01300979e-01\n",
      " -3.94002616e-01  3.60010624e-01 -7.83690810e-01 -2.82226324e-01\n",
      " -5.68018079e-01 -4.99824286e-01  2.05723524e-01 -2.48525381e-01\n",
      "  2.66177654e-02 -1.93736434e-01  8.37781012e-01 -9.55156028e-01\n",
      " -1.11888134e+00  1.87257051e-01 -9.72927809e-02 -8.84103298e-01\n",
      " -9.11787808e-01  1.05788517e+00 -3.64377499e-01  4.33585644e-02\n",
      "  3.20936680e-01 -4.35472608e-01  4.57621455e-01 -4.04223204e-01\n",
      " -3.30988944e-01 -4.57629323e-01 -7.54083395e-02 -1.42331541e-01\n",
      "  2.82491744e-01 -5.77083349e-01  6.91970825e-01 -9.06073809e-01\n",
      " -1.17709804e+00  5.22623062e-02 -4.43280339e-01 -3.52064729e-01\n",
      " -2.70496249e-01  6.61207557e-01  2.02165365e-01 -3.67572665e-01\n",
      " -9.58216071e-01 -1.01121271e+00  1.73546338e+00 -2.85909057e-01\n",
      " -4.40020084e-01 -2.39389181e-01 -9.15486813e-02 -1.78446639e+00\n",
      " -3.58201265e-02 -5.73596597e-01 -2.75752544e-02  7.75266767e-01\n",
      " -5.01251221e-02 -6.11371100e-01  3.13596636e-01 -5.19788980e-01\n",
      " -2.23685861e-01  2.58245468e-01 -4.05254841e-01 -1.01030457e+00\n",
      " -1.99973524e-01 -2.80428314e+00 -9.26852226e-02 -1.45698512e+00\n",
      "  2.45517492e-01 -4.82869565e-01 -1.30556822e-01  3.36718351e-01\n",
      " -2.50999999e+00 -8.64778280e-01 -6.42319798e-01  9.37633991e-01\n",
      "  1.90454602e-01 -1.41136336e+00 -5.35604596e-01 -5.12247562e-01\n",
      " -8.83248091e-01  6.54120564e-01  9.48810577e-02 -2.97613442e-01\n",
      "  6.79649591e-01 -3.38685036e-01 -2.90243506e-01  2.54950523e-02\n",
      "  3.34784150e-01 -9.48468804e-01 -5.06125927e-01 -1.75033474e+00\n",
      " -5.55751562e-01 -1.04677296e+00 -7.77220070e-01 -4.37204003e-01\n",
      " -2.21189260e-01 -1.26163542e-01  4.09692526e-02 -1.02320552e-01\n",
      "  4.48210120e-01 -6.22760653e-02 -4.98487353e-01 -1.41938090e+00\n",
      " -1.31087482e-01 -1.13108504e+00 -8.34236741e-01 -1.86390042e+00\n",
      "  1.62625551e-01 -9.32384968e-01  1.80403829e-01  2.87556946e-01\n",
      " -9.91885304e-01 -2.03674853e-01 -7.66065121e-02  7.96648264e-02\n",
      " -1.06379545e+00 -8.62090707e-01 -4.08466816e-01  1.14609241e-01\n",
      " -3.78825903e-01 -7.08277345e-01 -1.34050584e+00 -7.53299832e-01\n",
      "  1.12628937e-03  4.40690458e-01 -9.34989631e-01 -4.22480345e-01\n",
      " -1.67347550e-01 -1.18211293e+00 -4.80610669e-01 -4.87899780e-03\n",
      " -1.84459686e-01 -1.01678896e+00 -1.12604868e+00  1.16547167e-01\n",
      " -4.55079079e-02 -4.09681559e-01 -5.41511059e-01 -7.58169651e-01\n",
      " -3.41604948e-01  3.58910441e-01  2.21359789e-01  2.17951536e-02\n",
      " -4.61041212e-01 -9.21412826e-01 -9.10728335e-01 -3.25237274e-01\n",
      " -8.91379595e-01  9.16787505e-01 -3.53126168e-01 -4.48808193e-01\n",
      "  9.79014635e-02 -7.02348948e-01  2.05660045e-01  2.27381408e-01\n",
      "  5.44214249e-03 -3.90229225e-01  6.36776686e-02 -2.09893823e-01\n",
      "  2.01094210e-01 -1.04703569e+00 -2.04691887e-01  3.81666183e-01\n",
      " -6.37178898e-01 -8.09752345e-01  5.46176195e-01 -1.43941689e+00\n",
      "  6.76446497e-01 -1.79729223e-01  6.48967266e-01  7.97651529e-01\n",
      "  7.24427700e-02 -2.02164769e+00 -2.49531031e-01  6.94270015e-01\n",
      " -9.50213790e-01 -2.73144436e+00 -8.41194391e-02 -7.53201485e-01\n",
      "  7.21461296e-01 -1.40316093e+00  1.20586753e-02  2.60514736e-01\n",
      " -1.42761886e+00 -1.21319079e+00  3.81892920e-01 -3.43001246e-01\n",
      " -1.67680264e-01 -4.85347509e-02 -9.57038999e-02  2.62318254e-01\n",
      " -2.97736049e-01 -1.01853943e+00 -1.65051949e+00 -3.10518861e-01\n",
      " -4.01449084e-01 -3.12637210e-01  3.08184862e-01 -5.65509796e-01\n",
      " -3.54801655e-01 -5.04996717e-01 -1.44240618e+00 -7.66330957e-02\n",
      " -3.64037991e-01 -9.51768637e-01  3.58312607e-01 -5.39080262e-01\n",
      " -3.45731020e-01 -8.82347941e-01 -1.54573321e-01 -1.68350029e+00\n",
      " -1.33160114e-01 -5.24648190e-01 -1.39540792e-01 -5.81544042e-01\n",
      "  8.28779936e-02  4.20376301e-01 -1.47608638e+00 -1.79620504e+00\n",
      "  2.82746196e-01 -4.75410938e-01 -4.58751351e-01 -5.81223726e-01\n",
      "  2.50343561e-01 -1.21175170e-01 -1.94965363e-01 -6.38103366e-01\n",
      "  7.63310194e-02 -6.82681918e-01  5.56944385e-02 -2.80058384e-02\n",
      " -1.96247828e+00  6.50121331e-01  2.10591555e-01  2.98664093e-01\n",
      "  1.51380301e-01 -1.77268147e-01 -2.27813244e+00 -1.70398927e+00\n",
      " -4.72008705e-01 -7.26761818e-02 -1.01694465e-01 -5.43624878e-01\n",
      " -7.00079799e-01 -6.23784304e-01 -6.58530474e-01  7.82979727e-01\n",
      " -6.26802504e-01  2.19271779e-01 -7.95888484e-01  6.02302551e-02\n",
      "  9.49095845e-01 -9.36404228e-01  4.50357199e-02  3.87716293e-02\n",
      "  5.07380962e-02 -3.89606237e-01  1.04838967e-01  2.01921892e+00\n",
      "  6.45844221e-01  9.33998466e-01 -1.05135632e+00  1.20619130e+00\n",
      "  2.54927754e-01 -9.78211880e-01 -2.72123575e-01 -7.93066442e-01\n",
      " -2.55788475e-01 -1.32186055e-01 -1.17948449e+00 -7.75616050e-01\n",
      " -1.19025922e+00 -4.81145024e-01 -7.65149891e-01 -1.02552819e+00\n",
      " -8.35283101e-01 -4.97175574e-01 -3.16043854e-01 -7.79253840e-02\n",
      " -7.16467381e-01 -3.65071297e-02  7.08909154e-01  5.90416431e-01\n",
      " -8.12157393e-02 -9.52729940e-01 -8.93684864e-01 -4.67986524e-01\n",
      " -5.19336581e-01 -1.09735727e+00 -1.51771092e+00 -6.88596725e-01\n",
      " -9.13335919e-01 -9.68389928e-01 -7.82842636e-01 -6.54922843e-01\n",
      "  5.98348618e-01 -5.14941216e-02  2.30545282e-01 -1.44400573e+00\n",
      " -2.56641626e-01 -7.31701255e-01  1.04187533e-01 -2.93315411e-01\n",
      " -1.36668026e+00 -7.02022076e-01  3.82541060e-01 -7.77762532e-01\n",
      " -4.32188153e-01  1.99113727e-01 -5.37242413e-01  2.24180341e-01\n",
      " -6.82701528e-01 -1.03607178e+00 -4.00692463e-01 -3.56822848e-01\n",
      " -5.35070360e-01 -9.76630449e-02 -9.32280838e-01  9.18457508e-02\n",
      "  1.91974878e-01 -5.36056042e-01  7.79487491e-02 -7.62814999e-01\n",
      " -6.85888052e-01  3.33714247e-01 -1.37763724e-01 -1.89331889e-01\n",
      " -1.51535404e+00 -9.64533925e-01 -9.43369985e-01 -4.45508897e-01\n",
      "  7.50653744e-02  1.05082750e-01 -1.16618991e-01 -1.69275153e+00\n",
      "  1.58325207e+00 -2.72182226e-02 -5.19045711e-01 -7.51396179e-01\n",
      "  4.19167161e-01 -6.01842046e-01  5.87149143e-01 -1.09408259e+00\n",
      " -6.63476765e-01 -1.86354220e+00 -1.55553818e-02 -1.00009108e+00\n",
      " -7.22295761e-01 -2.04598546e-01 -1.27561092e-01 -1.39697075e-01\n",
      " -2.01138198e-01 -1.45184278e-01  2.26529360e-01 -4.04079795e-01\n",
      " -1.42597711e+00 -1.53821850e+00  9.43504572e-02 -1.34391785e-02\n",
      " -7.35203743e-01  5.64851522e-01 -1.42239809e+00 -2.68445015e-02\n",
      " -1.25311089e+00  2.12355196e-01  1.77775216e+00  2.67966837e-01\n",
      " -2.59451723e+00 -8.36076140e-01 -4.56640005e-01  1.53732300e-02\n",
      "  2.28950739e-01 -1.29351795e-01 -4.88632917e-01 -7.00013876e-01\n",
      "  7.51627207e-01 -1.95896626e-01 -6.21614397e-01 -1.36321270e+00\n",
      " -1.45523453e+00 -4.41408396e-01  4.68825400e-01 -6.81760311e-02\n",
      " -6.89052343e-01 -2.58927822e-01  7.17403412e-01  7.01882184e-01\n",
      "  9.34557915e-02  1.21666431e-01 -2.39807367e-02 -4.83675241e-01\n",
      " -3.16428781e-01 -3.06763053e-01  4.63100195e-01 -1.35639262e+00\n",
      " -1.61278844e-01 -4.74600613e-01 -3.36828887e-01 -4.61079657e-01\n",
      " -5.07517338e-01  5.92975199e-01 -1.31257486e+00 -1.87591076e+00\n",
      "  4.00312662e-01 -1.15663528e+00 -7.36212254e-01 -6.67572677e-01\n",
      "  2.64291525e-01 -3.27690721e-01  3.51700455e-01  1.19918823e-01\n",
      "  1.34940779e+00 -4.81782198e-01 -5.66717744e-01 -4.66724396e-01\n",
      "  3.15759838e-01 -2.09622574e+00  3.07617903e-01  4.04433370e-01\n",
      "  6.16745710e-01 -8.82545471e-01 -1.86629295e-02  2.41552949e-01\n",
      " -5.00113010e-01 -2.06551909e-01 -9.09689665e-01  7.06770420e-02\n",
      "  7.76005983e-02 -4.12509203e-01 -8.09991598e-01  9.81361210e-01\n",
      " -1.29809213e+00 -2.60702467e+00 -1.76679850e-01 -8.84741485e-01\n",
      " -5.56429744e-01 -1.09001517e-01 -9.04518604e-01 -6.23661280e-02\n",
      " -7.64528394e-01 -8.42579484e-01 -4.71754074e-01 -1.21362746e-01\n",
      " -8.21021795e-02  1.59735441e-01  1.33965385e+00  8.26051235e-02]\n",
      "13 [ 0.09354159  0.03424485 -0.06730844  0.37149653  0.12483163 -0.05729956\n",
      "  0.02248229  0.41305616  0.04229622  0.0994842  -0.1481284   0.01470295\n",
      "  0.10990582 -0.09876701  0.02553686 -0.00262263 -0.00655891 -0.05703558\n",
      " -0.12611811 -0.01099927 -0.03844909 -0.4488549   0.64316106  0.09613668\n",
      "  0.19351274 -0.09998967  0.02469688  0.10234599  0.38309565  0.10166939\n",
      " -0.00559564 -0.03092575 -0.01370505  0.14382812  0.03651411 -0.27077225\n",
      "  0.3228188   0.3593367   0.27613452 -0.02580225  0.51193947  0.08266371\n",
      "  0.0508527   0.15497026  0.34069848  0.08025844  0.03375604  0.5047996\n",
      "  0.02822558 -0.23158121  0.11182867  0.02181732 -0.06885923  0.01129453\n",
      " -0.44196418 -0.11282973 -0.05893234 -0.08811973 -0.11843988 -0.15644634\n",
      "  0.53622955  0.43446192 -0.05726632  0.16123301]\n",
      "14 [-0.6839526  -0.79994303 -0.5330805  ...  0.10796487 -0.00920859\n",
      " -0.31360596]\n",
      "15 [ 1.36146736e+00  8.42661619e-01 -9.97910798e-02  3.20406318e-01\n",
      " -3.59831870e-01  5.74350476e-01  1.10052955e+00 -4.24505472e-02\n",
      " -2.26404428e-01  1.39193797e+00  6.17007494e-01 -3.30550790e-01\n",
      " -4.59748149e-01 -3.51767778e-01 -4.10917103e-02  4.21602011e-01\n",
      " -1.87480569e-01  6.41186595e-01  4.67844546e-01  2.58724689e-02\n",
      "  5.67537129e-01 -1.05449343e+00  9.41946507e-01  7.00261593e-02\n",
      "  3.52521002e-01  2.61757851e-01  8.77511501e-02  6.56006813e-01\n",
      "  5.53220749e-01  1.30967498e-02 -2.44825482e-01  5.18794298e-01\n",
      "  6.87627554e-01  2.34185576e-01  6.31276727e-01  1.11337066e-01\n",
      " -2.03890085e-01  5.33605516e-01  9.30753350e-02  2.77340531e-01\n",
      "  8.99482489e-01  4.05063510e-01 -1.19540215e-01  3.30261588e-01\n",
      "  5.03856778e-01 -3.01005483e-01  8.09739828e-01  1.85476422e-01\n",
      "  1.01545763e+00 -4.66349006e-01  7.19251871e-01  1.89788818e-01\n",
      "  4.33948070e-01  4.87020254e-01 -1.34784579e-01  1.42312837e+00\n",
      "  3.72842550e-01  5.25689125e-01  8.86800766e-01  3.80180478e-02\n",
      "  9.98805940e-01  2.27117181e-01  8.80438209e-01 -2.35564888e-01\n",
      "  3.56247425e-01  7.93777704e-01  1.11719131e-01  8.89755964e-01\n",
      "  8.38775456e-01  5.49245715e-01  5.53303838e-01 -7.28308856e-01\n",
      "  1.09298420e+00  1.03358340e+00 -6.67264223e-01  2.45792150e-01\n",
      "  2.84653842e-01  5.81321716e-01  5.46466708e-02  7.15707481e-01\n",
      " -5.08024812e-01  6.20537281e-01 -2.63080120e-01  8.80923450e-01\n",
      " -5.22507966e-01  7.75996327e-01 -5.29145002e-02  9.48677063e-02\n",
      "  1.19943535e+00 -1.04707539e+00  6.61049843e-01 -3.64144230e+00\n",
      "  1.72611475e-02 -1.23504102e-01 -1.80689692e-01  7.73543239e-01\n",
      " -2.81473458e-01  8.84254932e-01  5.98229766e-02 -3.89694095e-01\n",
      "  1.50125861e-01  2.62081027e-01 -7.32972920e-02 -3.06510687e-01\n",
      " -2.07480001e+00  4.36214924e-01 -3.68111014e-01 -4.14204657e-01\n",
      "  4.50556874e-01  2.03049064e-01 -7.93680787e-01  8.79541159e-01\n",
      "  2.42707729e-01 -4.71638560e-01 -4.11347151e-02  2.61063337e-01\n",
      "  2.17530012e-01  4.21595573e-01  7.73859024e-02 -2.98773646e-01\n",
      " -1.07759297e-01  4.79363203e-02  6.76388860e-01  1.73749924e-01\n",
      "  1.53588593e-01 -1.65805817e-02  4.32164073e-01  6.25357270e-01\n",
      "  1.47553086e-01  9.01047051e-01 -2.31199265e-01  9.01820600e-01\n",
      " -1.11643708e+00  7.57627964e-01  5.92954278e-01 -8.74141455e-02\n",
      " -5.19211292e-02  5.33696294e-01 -5.37139177e-02  5.61005354e-01\n",
      "  6.84310913e-01  3.32000852e-01  1.29486322e-01  9.42225218e-01\n",
      " -3.69851828e-01 -2.59328961e-01  7.78132677e-01  7.46611357e-01\n",
      " -1.63307190e-01  4.37702298e-01  7.19456673e-01  2.73624182e-01\n",
      "  1.18503737e+00  4.67082381e-01  5.36022782e-01 -2.34032094e-01\n",
      "  9.96809483e-01  7.51086175e-01 -5.58456540e-01  4.28809404e-01\n",
      "  9.89781260e-01  1.80038524e+00  9.71886396e-01  7.29230225e-01\n",
      "  3.88352096e-01  4.99983788e-01  7.00229049e-01  1.01754260e+00\n",
      "  4.88391638e-01  2.37590432e-01 -1.34056973e+00  2.96668530e-01\n",
      " -3.99450183e-01  5.79293966e-01  8.44214559e-01  5.15236735e-01\n",
      "  2.24634767e-01  9.85437870e-01  8.91290009e-01  9.72716331e-01\n",
      " -8.45497310e-01  5.91066003e-01  9.09581244e-01  2.75396824e-01\n",
      "  3.94097835e-01  3.13973188e-01  9.35513496e-01  2.50087231e-01\n",
      "  4.94153798e-01  5.26687086e-01  4.87494648e-01  1.00510454e+00\n",
      "  1.92889488e+00  8.62564445e-01  1.39988971e+00 -1.08143196e-01\n",
      " -2.87405342e-01  6.47054911e-02 -9.60751772e-02  5.70095360e-01\n",
      " -7.03612491e-02  1.52202487e-01 -7.82048702e-02  7.17836976e-01\n",
      " -5.52620888e-02  4.52046752e-01  1.01529074e+00  5.14555812e-01\n",
      "  1.27177751e+00 -2.90523767e-02  8.79805446e-01  7.77137041e-01\n",
      "  1.30179405e-01 -3.32854986e-01  8.52610767e-01  3.71271789e-01\n",
      "  4.04165685e-01 -1.05910635e+00  3.82687807e-01  1.01079333e+00\n",
      "  3.84185076e-01  5.63956141e-01  1.25127435e-02  5.77843308e-01\n",
      "  9.42776799e-01  2.79069692e-01 -1.47347569e-01  9.29637432e-01\n",
      " -1.68722093e-01  6.79686308e-01 -8.56977701e-02  5.63175797e-01\n",
      "  1.74816012e-01  6.26565516e-01  4.53489125e-01  7.30772972e-01\n",
      " -1.70326233e-02  7.71106720e-01  1.72087121e+00 -4.53188479e-01\n",
      " -4.42305028e-01  5.90878725e-02 -1.96790695e-03  2.79442072e-02\n",
      "  1.07976282e+00  1.75010681e-01  1.14496565e+00  1.11278296e-01\n",
      "  4.13275301e-01  2.91892648e-01  4.48871732e-01  9.77758169e-01\n",
      "  1.02485895e-01  5.70401907e-01  1.30527532e+00  2.44933963e-01\n",
      "  3.34527612e-01  3.68219614e-01  1.85732245e-01  3.60661864e-01\n",
      "  3.41190934e-01 -2.02531070e-01  5.89934111e-01  1.29828644e+00\n",
      " -1.99559331e-03  1.25155121e-01 -1.17830038e-02  1.22853208e+00\n",
      "  6.73737288e-01  3.44386220e-01  6.33150339e-01  5.39923787e-01\n",
      " -6.57073140e-01  9.70537663e-01  3.55127811e-01  7.09867358e-01\n",
      "  2.12132394e-01  8.48577023e-01  3.07930231e-01  7.75993347e-01\n",
      "  5.66819310e-01  2.36737251e-01  4.65784252e-01  2.13276148e-02\n",
      "  8.61820102e-01  8.14561129e-01  9.44285750e-01  6.28970861e-01\n",
      "  5.47385693e-01  4.76223767e-01  1.30697817e-01  3.44708085e-01\n",
      "  1.09364212e-01  9.69053149e-01 -3.35391164e-02  8.87599587e-01\n",
      "  1.79260373e-01  7.60298133e-01 -3.97017956e-01  5.13286352e-01\n",
      "  3.91322732e-01  4.34736788e-01  7.14717865e-01  5.79536796e-01\n",
      "  2.88363934e-01  2.91673541e-01  9.29795504e-02  5.09088039e-01\n",
      "  2.06853747e-02  5.79510927e-01 -5.27432680e-01 -8.04334939e-01\n",
      "  3.77186716e-01  8.15183163e-01  4.03571963e-01  1.27558351e+00\n",
      "  5.90182543e-02  2.82811999e-01  4.53589559e-01  3.81701708e-01\n",
      "  9.32337642e-01  2.93462694e-01  7.15577185e-01  3.40312243e-01\n",
      "  4.50671315e-01  8.25874865e-01 -4.53973085e-01  8.43861103e-01\n",
      "  1.17023396e+00  7.30833888e-01  5.58319211e-01  1.63835287e-03\n",
      "  5.51504612e-01 -2.77572036e-01  6.12344027e-01  8.03572893e-01\n",
      "  7.63056874e-01  4.25190389e-01  2.50874162e-02 -5.85069239e-01\n",
      "  1.55870914e-02 -6.01884484e-01 -3.22680324e-01 -6.80787444e-01\n",
      "  3.78688365e-01  5.12648702e-01  9.80858207e-01 -2.69289732e-01\n",
      "  3.15251350e-02  6.91733360e-01  2.95552611e-02  3.48440289e-01\n",
      "  6.83187246e-01 -5.92025518e-01 -2.91840911e-01  5.90413690e-01\n",
      "  6.37525260e-01  6.16997957e-01  9.34965730e-01 -4.16122079e-01\n",
      "  5.62988281e-01  1.49787962e-01  1.03821874e-01 -4.80354249e-01\n",
      "  7.67294466e-01  7.94447660e-02  8.09960485e-01  3.77852678e-01\n",
      "  8.80203247e-01  1.23740804e+00  9.84131455e-01  2.16735601e-02\n",
      "  5.92750728e-01 -7.44466543e-01  3.43453407e-01  1.09558737e+00\n",
      "  1.45997822e+00 -5.28880978e+00  1.36010468e-01  1.85849667e-02\n",
      " -1.51448131e-01  4.16128159e-01  5.98228335e-01  8.43763351e-02\n",
      "  7.78573394e-01  6.09628439e-01  2.95424223e-01 -9.25050974e-02\n",
      "  9.00876045e-01  1.18660355e+00  7.93159306e-01  7.44007707e-01\n",
      "  2.31727839e-01  8.77676010e-02  1.40283477e+00  9.91208911e-01\n",
      "  7.57868826e-01 -5.10893941e-01  2.75796890e-01 -2.86412239e-01\n",
      "  1.57965660e-01  7.29408383e-01  6.31919682e-01  6.96916163e-01\n",
      "  2.71858454e-01  4.85771298e-01  1.22801423e-01  1.74729156e+00\n",
      "  4.47672129e-01  4.09016967e-01  3.82737398e-01  2.11527705e-01\n",
      "  4.88633811e-01  1.26289511e+00  7.82371640e-01  9.09208655e-01\n",
      "  7.45746613e-01  5.89233756e-01  2.92217493e-01  1.29370618e+00\n",
      " -1.70092106e-01  1.20572627e-01  4.83475596e-01  8.49575996e-01\n",
      "  9.55897689e-01  4.97725308e-01 -4.61022139e-01  1.05113924e-01\n",
      "  6.96046174e-01  4.75854039e-01  8.91133726e-01  5.12116134e-01\n",
      " -2.18802854e-01  6.51295781e-01  7.54925251e-01  2.86746025e-02\n",
      "  3.02400231e-01  4.35713768e-01  3.33474278e-01  6.13583446e-01\n",
      "  4.49392915e-01 -3.46258938e-01  4.99476790e-01  3.30926716e-01\n",
      "  1.31243992e+00  1.19903588e+00  1.09488523e+00  2.49290943e-01\n",
      "  5.84434032e-01  2.49865785e-01  3.06174874e-01  1.75947905e+00\n",
      "  7.95257092e-03  1.38860226e-01 -2.80586302e-01  1.05529344e+00\n",
      " -7.36953497e-01  7.08282292e-01  9.30577338e-01 -3.28693330e-01\n",
      "  1.88349605e-01  2.89083540e-01  2.45065331e-01  1.60063297e-01\n",
      " -2.81518459e-01  7.66230822e-01  5.52454650e-01 -2.76960373e-01\n",
      "  7.10842609e-02  6.69786811e-01  1.22937083e+00  5.06586909e-01\n",
      "  6.92613244e-01  3.30231309e-01  1.68148518e-01  5.18054962e-02\n",
      "  2.59189248e-01  7.69520044e-01  1.82619095e-01 -6.19518042e-01\n",
      "  7.56493330e-01  8.81668448e-01  7.13581383e-01  5.00247300e-01\n",
      "  7.14424729e-01  2.97358155e-01  8.93800735e-01  3.79922569e-01\n",
      "  8.98464203e-01  1.99035048e-01  5.21439433e-01  1.10032201e-01\n",
      "  4.23874617e-01  8.83081257e-01 -6.53684616e-01  4.95812535e-01\n",
      "  7.17090666e-02  4.24897611e-01  4.73248035e-01 -4.08827722e-01\n",
      "  1.79141790e-01  4.70170617e-01  1.05692232e+00 -8.97390842e-02\n",
      "  4.21122313e-02  8.07791352e-01 -1.83702469e-01  3.67789268e-02\n",
      "  6.55152321e-01  1.05947709e+00  2.66650379e-01  8.23600292e-01]\n",
      "16 [ 0.12868327 -0.8757365  -0.45918903 ...  1.1571367  -0.28349972\n",
      "  0.67133784]\n",
      "17 [ 6.87430859e-01  7.45754480e-01  1.19016027e+00  1.74280989e+00\n",
      "  6.34015501e-01  9.76923347e-01  9.83356833e-01  1.28795087e+00\n",
      "  2.52028346e-01  1.13431430e+00  5.37979603e-01  5.92135191e-01\n",
      "  1.50439453e+00  6.88350916e-01  8.72714639e-01  1.35887098e+00\n",
      "  1.02719486e+00  6.96835756e-01  2.16853380e-01  1.07374406e+00\n",
      "  5.75284123e-01  6.52501583e-01  5.41130722e-01  8.78412008e-01\n",
      "  7.69428372e-01  6.99312329e-01  3.93850923e-01  9.53699112e-01\n",
      "  1.17532408e+00  6.66267157e-01  1.22479928e+00  6.39058828e-01\n",
      "  1.15332127e+00  1.48849583e+00 -1.19231880e-01  1.36780405e+00\n",
      "  6.03291273e-01  1.29756892e+00  2.68221617e-01  3.65185857e-01\n",
      "  1.42892206e+00  4.24288988e-01  8.45434785e-01  1.28741264e-01\n",
      "  5.44992328e-01  1.08253288e+00  1.68014228e-01  2.41033614e-01\n",
      "  1.11598003e+00  7.63078928e-01  1.25352645e+00  9.88214731e-01\n",
      "  7.26164341e-01  7.03122258e-01  8.86881948e-01  2.40246892e-01\n",
      "  1.68615317e+00  6.67472124e-01 -7.71102667e-01 -6.25475645e-02\n",
      "  7.69266486e-01  7.56792545e-01  6.34160876e-01  1.02156878e+00\n",
      "  5.70437670e-01  9.36879039e-01  1.19057345e+00  1.05645323e+00\n",
      "  7.68979430e-01  7.23081589e-01  1.36099207e+00  4.84040737e-01\n",
      "  7.66543031e-01  7.47390389e-01  9.58464742e-01  1.25091648e+00\n",
      "  1.66564226e-01  6.06593609e-01  1.05680263e+00  8.76811504e-01\n",
      "  1.47909975e+00  4.04389739e-01  9.46228147e-01  6.42704964e-01\n",
      "  1.19868731e+00 -1.31519675e-01  1.31084108e+00  7.68729687e-01\n",
      "  7.27564335e-01  4.34193850e-01  5.53845763e-01  9.01716828e-01\n",
      " -3.17699718e+00  8.67131114e-01  1.68556786e+00  1.07682550e+00\n",
      "  7.17333913e-01  1.31283677e+00  8.76475811e-01 -2.95174122e-03\n",
      "  1.22478521e+00  1.64701855e+00  8.70827138e-01  2.50917578e+00\n",
      "  4.82409954e-01  5.30108094e-01  7.82949924e-01  6.77931547e-01\n",
      "  4.60575938e-01  1.13132179e+00  9.42806721e-01  8.55010271e-01\n",
      "  1.19580126e+00 -1.29687667e-01  6.45433426e-01  2.28490114e-01\n",
      "  8.06801498e-01  5.26111603e-01  4.12491620e-01  5.52144289e-01\n",
      "  5.75465322e-01  7.41193771e-01  3.82615507e-01 -1.07103825e-01\n",
      "  1.11056304e+00  8.03577662e-01  8.93078685e-01  1.06108093e+00\n",
      "  1.15678561e+00  5.50055981e-01  9.60580349e-01  1.06902599e+00\n",
      "  7.58386374e-01  4.21226919e-01  9.89950180e-01  8.95480633e-01\n",
      "  1.09218287e+00  1.26853395e+00  1.15086460e+00 -6.09874725e-03\n",
      "  4.61746573e-01  6.70292258e-01 -3.00269842e-01 -2.36766338e-02\n",
      " -6.10962987e-01  8.21801186e-01  1.61353755e+00  1.15231609e+00\n",
      "  1.48608804e+00  6.46604180e-01  2.15903330e+00  1.33751559e+00\n",
      "  9.10099387e-01  1.64786434e+00  1.00061202e+00  1.52857327e+00\n",
      "  9.78216529e-01  1.12775064e+00  1.75628638e+00  1.87307835e+00\n",
      "  5.54640114e-01  9.41981792e-01  5.00069261e-01  5.15414834e-01\n",
      "  8.82790565e-01  1.06629992e+00  1.47837353e+00  7.00470805e-01\n",
      "  9.45667624e-01  2.57127881e-02  3.33935261e-01  5.43704987e-01\n",
      "  6.72285199e-01  9.34459388e-01  4.67763901e-01  6.49510622e-01\n",
      "  7.52039790e-01  1.27425158e+00  7.76542664e-01  7.26281524e-01\n",
      "  7.87981689e-01  7.08706915e-01  1.12012255e+00  1.44286025e+00\n",
      "  1.80606842e-01  1.35124099e+00  7.38942623e-01  1.10560787e+00\n",
      "  8.05733442e-01  6.45790458e-01  5.79780936e-01  2.33360529e-01\n",
      "  1.08985877e+00  1.62579238e+00  1.10204196e+00  1.84329820e+00\n",
      "  1.31060696e+00  1.25684237e+00  9.94197726e-01  7.70915031e-01\n",
      "  2.06558347e-01  1.05405521e+00  5.38019180e-01  1.33314753e+00\n",
      "  1.46809995e+00  1.20364666e-01  6.90482140e-01  9.04206812e-01\n",
      "  7.72219658e-01  6.26428127e-01  7.70575047e-01  2.39870405e+00\n",
      "  6.66134000e-01  2.60870337e-01  1.15304232e-01  8.33246827e-01\n",
      "  7.10424542e-01  1.15733230e+00  1.17964768e+00  1.29303491e+00\n",
      "  6.28293395e-01  1.38189650e+00  4.45283651e-02  8.55593622e-01\n",
      "  7.76254892e-01  4.07307625e-01  8.86849403e-01 -5.24577916e-01\n",
      "  8.77563000e-01  1.32175636e+00  4.87317801e-01  2.18683195e+00\n",
      "  1.60132909e+00  9.62068915e-01  6.08831882e-01  2.43953276e+00\n",
      "  1.49866748e+00  1.04746640e+00  5.00121236e-01  1.27765572e+00\n",
      "  6.97526217e-01  1.04905164e+00  8.71676326e-01  1.23084450e+00\n",
      "  1.64309669e+00  5.23878336e-01  9.91780162e-01  8.25916409e-01\n",
      "  1.23046696e+00  6.54240370e-01  1.02611017e+00  3.75853777e-01\n",
      "  1.01529622e+00  9.91965055e-01  9.79964018e-01  2.24425507e+00\n",
      "  4.47544903e-01  5.61133683e-01  1.01535892e+00  1.14581323e+00\n",
      "  1.64103961e+00  7.92033792e-01  1.65832758e+00  6.37429059e-01\n",
      "  1.06161976e+00  5.43742537e-01  9.40949917e-01  6.70153558e-01\n",
      "  1.33375406e+00  8.46780181e-01 -8.36897492e-02  4.73077536e-01\n",
      "  6.73354030e-01  6.10380769e-01  9.41661477e-01  1.23728395e+00\n",
      "  1.43388271e+00  1.11417413e-01  7.47777224e-01  2.80855298e-01\n",
      "  1.63169503e-01  1.47389674e+00  5.16857386e-01  1.58590734e+00\n",
      "  1.44517624e+00  1.06402683e+00  8.26355338e-01  8.92878771e-01\n",
      "  3.38760257e-01  3.72117877e-01  7.96898603e-01  6.24049664e-01\n",
      "  1.06133318e+00  6.92968130e-01  9.25841570e-01  6.92780018e-01\n",
      "  5.68460464e-01  9.05720830e-01  9.11571741e-01  4.39032197e-01\n",
      "  1.36568832e+00  1.28288245e+00  1.19007659e+00  7.06246614e-01\n",
      "  1.27124667e+00  1.47575092e+00  5.82006931e-01  7.60950208e-01\n",
      "  4.71366048e-01  2.95958996e-01  8.88928235e-01 -1.80161822e+00\n",
      "  1.14743650e+00  1.18060398e+00  6.13573194e-01  1.04280055e+00\n",
      "  1.46391118e+00 -1.75838470e-02  6.09999537e-01  1.59583151e-01\n",
      "  7.83286572e-01  8.49541426e-02  1.11487198e+00  4.80311275e-01\n",
      "  1.05435443e+00  5.25891542e-01  1.22373223e+00  1.42338121e+00\n",
      "  3.54623795e-01  6.39714718e-01  1.07012761e+00  9.48549151e-01\n",
      "  1.16258514e+00 -6.14123106e-01  1.76555920e+00  2.29188561e-01\n",
      "  7.49615729e-01  8.65233898e-01  1.12905967e+00  8.28153491e-01\n",
      "  1.23757839e+00  1.73244262e+00 -1.36639357e-01  5.39123833e-01\n",
      "  9.33529019e-01  8.46975565e-01  1.06152952e+00  6.97718263e-01\n",
      "  9.44927216e-01  3.58812809e-01  7.91481256e-01  1.11803854e+00\n",
      "  1.03405249e+00  1.05830801e+00  5.41289032e-01  5.75580418e-01\n",
      "  5.98840356e-01  1.27498436e+00  4.27783489e-01  1.10035670e+00\n",
      "  3.81793737e-01  8.17058086e-01  1.13510227e+00  9.67178464e-01\n",
      "  1.10756421e+00  3.77210617e-01  3.32634091e-01  1.30566239e+00\n",
      "  1.03136837e+00  1.54814458e+00  2.09741235e-01  2.32720637e+00\n",
      "  8.12850237e-01  1.01477873e+00  1.61202908e-01  8.81202459e-01\n",
      "  3.59642863e-01  4.43990707e-01  1.72904241e+00  1.31738830e+00\n",
      "  7.61506319e-01  1.65463448e-01  1.05253816e+00  9.70591545e-01\n",
      "  6.85021162e-01  9.27020431e-01  1.60100126e+00  8.37790251e-01\n",
      "  1.05935764e+00  7.51633286e-01  5.30760825e-01  9.72042799e-01\n",
      "  1.89964473e-01  1.21668637e+00  9.61920261e-01  1.20828068e+00\n",
      "  1.32428026e+00  1.62455249e+00  9.12229180e-01  1.93865871e+00\n",
      "  7.57577896e-01  6.92656279e-01  1.19771004e+00  1.07521796e+00\n",
      "  8.39740634e-01  1.03364062e+00  1.23383868e+00  3.53689909e-01\n",
      "  1.16026485e+00  8.04508924e-01  1.37355566e+00  8.73110771e-01\n",
      "  9.92662549e-01  1.08087587e+00  2.06653476e+00  3.75037313e-01\n",
      "  5.18784046e-01  4.97781515e-01  1.58565164e-01  1.36759233e+00\n",
      "  7.47056246e-01  1.07475972e+00  4.98415112e-01  5.22076011e-01\n",
      "  1.03898501e+00  1.89326739e+00  1.25563979e+00  9.27692652e-01\n",
      "  1.21186304e+00  6.41698837e-01  8.52097034e-01  7.62431383e-01\n",
      "  1.25750446e+00  1.15550613e+00  5.32659411e-01  1.31543946e+00\n",
      "  6.20416284e-01  6.57746732e-01  1.21304846e+00  1.20880020e+00\n",
      "  5.48758745e-01  6.63147092e-01  1.03437424e+00  1.20881689e+00\n",
      "  1.20118320e+00 -4.17341113e-01  2.74534583e-01  1.02053094e+00\n",
      "  1.13132000e-01  1.52827549e+00  1.16632366e+00  9.11397934e-01\n",
      "  8.53644371e-01  7.74818063e-01  9.85682249e-01 -1.61333203e-01\n",
      "  1.41881669e+00  1.12671113e+00  7.98845410e-01  7.34907627e-01\n",
      "  8.14297915e-01  8.67869854e-01  2.37838387e+00  5.36780834e-01\n",
      "  9.95745301e-01  8.48831296e-01  1.05511379e+00  1.55299067e-01\n",
      "  7.80969620e-01 -4.61370587e-01  1.98268890e-01  7.80673981e-01\n",
      "  4.92787838e-01  8.61772060e-01  8.23314428e-01  7.13181615e-01\n",
      "  7.42105246e-02  1.17424750e+00  3.30912113e-01  1.49627137e+00\n",
      "  5.57107329e-01  2.47387648e-01  1.51637411e+00  7.37109184e-01\n",
      "  8.30842614e-01  1.29918253e+00  3.14658642e-01  9.38589454e-01\n",
      "  5.72247863e-01  3.07924747e-02  6.50746226e-01  1.32303691e+00\n",
      "  5.65437675e-01  6.61016226e-01  6.08361721e-01  9.98299718e-01\n",
      "  1.29860640e+00  3.66068125e-01  1.86835265e+00  5.74957848e-01\n",
      " -4.41482067e-02  1.37243152e+00  1.07509530e+00  2.10243845e+00\n",
      "  9.92803812e-01  4.26051497e-01  5.89532256e-01 -9.19743776e-02\n",
      "  1.72087598e+00  5.10518312e-01  4.67181921e-01  9.42267060e-01]\n",
      "18 [-1.2170541  -1.7581753  -0.6214261  ... -0.02964616 -2.2442136\n",
      "  0.1312902 ]\n",
      "19 [ 0.26940057  0.05425627  0.08847105 ... -0.03313461  0.6826448\n",
      "  0.02499386]\n",
      "20 [ 4.6275339e-01  1.8042588e+00 -1.8436709e-02 ... -5.4111594e-04\n",
      "  2.6012149e-02  1.3989705e+00]\n",
      "21 [-0.20333542  0.00661636  1.9498783  ... -0.03985103  1.7053616\n",
      " -0.4247474 ]\n",
      "22 [ 1.0025661e-04  1.7065780e-02  1.3534359e-02  8.0378935e-02\n",
      " -1.9264258e-01 -3.1886805e-02  7.5196242e-04  2.4080215e-02\n",
      " -1.2246167e-02  9.2876358e-03 -2.8694417e-02  3.9724734e-02\n",
      " -2.2117043e-02  1.8986356e-02  1.5503471e-02 -1.5319362e-02\n",
      "  3.9806184e-03 -3.0276895e-02 -5.7422835e-03  1.4943394e-02\n",
      " -2.6409347e-03  1.6784916e-02 -2.8470913e-02 -4.0303171e-02\n",
      " -1.4766250e-02 -7.7563091e-03  2.2188215e-02  2.3471911e-03\n",
      "  3.4541093e-02 -1.3228242e-01  1.1970168e-02  2.3526337e-02\n",
      "  1.6285416e-02 -4.6076607e-03 -1.5291864e-02 -1.7791223e-02\n",
      "  2.5153583e-02 -2.7815079e-02  4.4214342e-02 -1.6916426e-02\n",
      "  4.5072553e-03  2.2065911e-02  5.0595105e-03  1.7657967e-02\n",
      "  1.9272678e-02 -2.9454587e-03 -1.2389580e-02 -2.3682985e-02\n",
      "  1.0553345e-02  2.8284015e-02 -1.0752392e-02  6.7696637e-03\n",
      "  1.1001317e-02  1.9626884e-02 -1.4775963e-01 -3.2714833e-02\n",
      "  1.4608124e-02 -9.0097766e-03  5.7199663e-03  1.6275007e-02\n",
      " -1.4187104e-02 -1.3603845e-03  4.7482061e-03  2.8427558e-02\n",
      " -2.9520032e-03 -1.4661203e-02  1.8445876e-03 -2.7376853e-02\n",
      " -1.1899206e-02  2.8169639e-02  3.1755831e-02  1.1343694e-02\n",
      "  6.7603984e-04  1.8860254e-02 -5.4383227e-03 -1.5718680e-02\n",
      "  1.8213710e-02  1.8805508e-02  2.8067397e-02 -1.5770701e-01\n",
      "  1.4760222e-02 -6.0685221e-03  2.0064304e-02  3.0427756e-02\n",
      "  1.4665950e-02 -1.2159227e-02  2.4152476e-02 -2.9669179e-02\n",
      "  8.8696061e-03 -4.7365515e-03  1.6165741e-02  2.4553467e-02\n",
      " -2.6460495e-02 -5.4717874e-03 -3.7767985e-04  4.1299788e-03\n",
      " -3.2559231e-02 -1.9800675e-03  1.2399862e-03  1.9454977e-02\n",
      "  1.1150013e-02 -1.5771933e-02  5.9015867e-03  1.9265775e-02\n",
      " -1.4467070e-01 -1.8845814e-03  2.4779798e-02 -1.3913716e-02\n",
      "  5.7830741e-03 -1.8582633e-02  2.4220103e-02  7.7935087e-04\n",
      " -1.3806484e-02  7.7134054e-03 -1.7496709e-02  1.1455060e-02\n",
      "  1.8591285e-02  2.3099471e-02  1.7915305e-03  6.7359647e-03\n",
      " -8.6529087e-03 -8.1208060e-03  1.2818706e-02  1.1869518e-02\n",
      "  2.2965064e-02]\n"
     ]
    }
   ],
   "source": [
    "for i in bias_new:\n",
    "    print(i, bias_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44c1ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda, ReLU, concatenate\n",
    "#from tensorflow.keras.layers.advanced_activations import LeakyReLU\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
    "def space_to_depth_x2(x):\n",
    "    return tf.nn.space_to_depth(x, block_size=2)\n",
    "\n",
    "def ConvBatchReLu(x,filters,kernel_size,index,trainable):\n",
    "    # when strides = None, strides = pool_size.\n",
    "    x = Conv2D(filters, kernel_size, strides=(1,1), \n",
    "               padding='same', name='conv_{}'.format(index), \n",
    "               use_bias=False, trainable=trainable)(x)\n",
    "    x = BatchNormalization(name='norm_{}'.format(index), trainable=trainable)(x)\n",
    "    x = ReLU()(x)\n",
    "    return(x)\n",
    "    \n",
    "def ConvBatchReLu_loop(x,index,convstack,trainable):\n",
    "    for para in convstack:\n",
    "        x = ConvBatchReLu(x,para[\"filters\"],para[\"kernel_size\"],index,trainable)\n",
    "        index += 1\n",
    "    return(x)\n",
    "\n",
    "def define_YOLOv2(IMAGE_H,IMAGE_W,GRID_H,GRID_W,TRUE_BOX_BUFFER,BOX,CLASS, trainable=False):\n",
    "    convstack3to5  = [{\"filters\":128, \"kernel_size\":(3,3)},  # 3\n",
    "                      {\"filters\":64,  \"kernel_size\":(1,1)},  # 4\n",
    "                      {\"filters\":128, \"kernel_size\":(3,3)}]  # 5\n",
    "                    \n",
    "    convstack6to8  = [{\"filters\":256, \"kernel_size\":(3,3)},  # 6\n",
    "                      {\"filters\":128, \"kernel_size\":(1,1)},  # 7\n",
    "                      {\"filters\":256, \"kernel_size\":(3,3)}]  # 8\n",
    "    \n",
    "    convstack9to13 = [{\"filters\":512, \"kernel_size\":(3,3)},  # 9\n",
    "                      {\"filters\":256, \"kernel_size\":(1,1)},  # 10\n",
    "                      {\"filters\":512, \"kernel_size\":(3,3)},  # 11\n",
    "                      {\"filters\":256, \"kernel_size\":(1,1)},  # 12\n",
    "                      {\"filters\":512, \"kernel_size\":(3,3)}]  # 13\n",
    "        \n",
    "    convstack14to20 = [{\"filters\":1024, \"kernel_size\":(3,3)}, # 14 \n",
    "                       {\"filters\":512,  \"kernel_size\":(1,1)}, # 15\n",
    "                       {\"filters\":1024, \"kernel_size\":(3,3)}, # 16\n",
    "                       {\"filters\":512,  \"kernel_size\":(1,1)}, # 17\n",
    "                       {\"filters\":1024, \"kernel_size\":(3,3)}, # 18\n",
    "                       {\"filters\":1024, \"kernel_size\":(3,3)}, # 19\n",
    "                       {\"filters\":1024, \"kernel_size\":(3,3)}] # 20\n",
    "    \n",
    "    input_image = Input(shape=(IMAGE_H, IMAGE_W, 3),name=\"input_image\")\n",
    "    true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4),name=\"input_hack\")    \n",
    "    # Layer 1\n",
    "    x = ConvBatchReLu(input_image,filters=32,kernel_size=(3,3),index=1,trainable=trainable)\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(2, 2),name=\"maxpool1_416to208\")(x)\n",
    "    # Layer 2\n",
    "    x = ConvBatchReLu(x,filters=64,kernel_size=(3,3),index=2,trainable=trainable)\n",
    "    x = MaxPooling2D(pool_size=(2, 2),name=\"maxpool1_208to104\")(x)\n",
    "    \n",
    "    # Layer 3 - 5\n",
    "    x = ConvBatchReLu_loop(x,3,convstack3to5,trainable)\n",
    "    x = MaxPooling2D(pool_size=(2, 2),name=\"maxpool1_104to52\")(x)\n",
    "    \n",
    "    # Layer 6 - 8 \n",
    "    x = ConvBatchReLu_loop(x,6,convstack6to8,trainable)\n",
    "    x = MaxPooling2D(pool_size=(2, 2),name=\"maxpool1_52to26\")(x) \n",
    "\n",
    "    # Layer 9 - 13\n",
    "    x = ConvBatchReLu_loop(x,9,convstack9to13,trainable)\n",
    "        \n",
    "    skip_connection = x\n",
    "    x = MaxPooling2D(pool_size=(2, 2),name=\"maxpool1_26to13\")(x)\n",
    "    \n",
    "    # Layer 14 - 20\n",
    "    x = ConvBatchReLu_loop(x,14,convstack14to20,trainable)\n",
    "\n",
    "    # Layer 21\n",
    "    skip_connection = ConvBatchReLu(skip_connection,filters=64,\n",
    "                                     kernel_size=(1,1),index=21,trainable=trainable)\n",
    "    skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "    x = concatenate([skip_connection, x])\n",
    "\n",
    "    # Layer 22\n",
    "    x = ConvBatchReLu(x,filters=1024,kernel_size=(3,3),index=22,trainable=trainable)\n",
    "\n",
    "    # Layer 23\n",
    "    x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "    output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS),name=\"final_output\")(x)\n",
    "    \n",
    "    output = Lambda(lambda args: args[0],name=\"hack_layer\")([output, true_boxes])\n",
    "    \n",
    "    model = Model([input_image, true_boxes], output)\n",
    "    return (model,true_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7603853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ANCHORS = np.array([1.3221, 1.73145, 3.19275, 4.00944, 5.05587, 8.09892, 9.47112, 4.84053, 11.2364, 10.0071])\n",
    "\n",
    "LABELS = ['aeroplane',  'bicycle', 'bird',  'boat',      'bottle', \n",
    "          'bus',        'car',      'cat',  'chair',     'cow',\n",
    "          'diningtable','dog',    'horse',  'motorbike', 'person',\n",
    "          'pottedplant','sheep',  'sofa',   'train',   'tvmonitor']\n",
    "\n",
    "IMAGE_H, IMAGE_W  = 416, 416\n",
    "GRID_H,  GRID_W   = 13 , 13\n",
    "TRUE_BOX_BUFFER   = 50\n",
    "BOX               = int(len(ANCHORS)/2)\n",
    "CLASS             = len(LABELS)\n",
    "model, true_boxes = define_YOLOv2(IMAGE_H,IMAGE_W,GRID_H,GRID_W,TRUE_BOX_BUFFER,BOX,CLASS, \n",
    "                                  trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9e90cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1, 50, 4), dtype=tf.float32, name='input_hack'), name='input_hack', description=\"created by layer 'input_hack'\")\n"
     ]
    }
   ],
   "source": [
    "print(true_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5ee698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 416, 416, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 416, 416, 32) 864         input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 416, 416, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 416, 416, 32) 0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_416to208 (MaxPooling2D (None, 208, 208, 32) 0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 208, 208, 64) 18432       maxpool1_416to208[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 208, 208, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 208, 208, 64) 0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_208to104 (MaxPooling2D (None, 104, 104, 64) 0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 104, 104, 128 73728       maxpool1_208to104[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 104, 104, 128 512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 104, 104, 128 0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 104, 104, 64) 8192        re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 104, 104, 64) 256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 104, 104, 64) 0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 104, 104, 128 73728       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 104, 104, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 104, 104, 128 0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_104to52 (MaxPooling2D) (None, 52, 52, 128)  0           re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 52, 52, 256)  294912      maxpool1_104to52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 52, 52, 256)  0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 52, 52, 128)  32768       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 52, 52, 128)  512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 52, 52, 128)  0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 52, 52, 256)  294912      re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 52, 52, 256)  0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_52to26 (MaxPooling2D)  (None, 26, 26, 256)  0           re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 26, 26, 512)  1179648     maxpool1_52to26[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)     (None, 26, 26, 512)  2048        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 26, 26, 512)  0           norm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 26, 26, 256)  131072      re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 26, 26, 256)  0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 26, 26, 512)  1179648     re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 26, 26, 512)  0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 26, 26, 256)  131072      re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 26, 26, 256)  0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 26, 26, 512)  1179648     re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 26, 26, 512)  0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_26to13 (MaxPooling2D)  (None, 13, 13, 512)  0           re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 13, 13, 1024) 4718592     maxpool1_26to13[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 13, 13, 1024) 0           norm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 13, 13, 512)  524288      re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 13, 13, 512)  0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 13, 13, 1024) 4718592     re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 13, 13, 1024) 0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 13, 13, 512)  524288      re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 13, 13, 512)  0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 13, 13, 1024) 4718592     re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 13, 13, 1024) 0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 13, 13, 1024) 9437184     re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 26, 26, 64)   32768       re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 13, 13, 1024) 0           norm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 26, 26, 64)   256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 13, 13, 1024) 9437184     re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 26, 26, 64)   0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 13, 13, 256)  0           re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 13, 13, 1024) 0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 13, 13, 1280) 0           lambda[0][0]                     \n",
      "                                                                 re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 13, 13, 1024) 11796480    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 13, 13, 1024) 0           norm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 13, 13, 125)  128125      re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Reshape)          (None, 13, 13, 5, 25 0           conv_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_hack (InputLayer)         [(None, 1, 1, 1, 50, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hack_layer (Lambda)             (None, 13, 13, 5, 25 0           final_output[0][0]               \n",
      "                                                                 input_hack[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 50,676,061\n",
      "Trainable params: 128,125\n",
      "Non-trainable params: 50,547,936\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5d9c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_core(y_true,\n",
    "                     y_pred,\n",
    "                     true_boxes,\n",
    "                     GRID_W,\n",
    "                     GRID_H,\n",
    "                     BATCH_SIZE,\n",
    "                     ANCHORS,\n",
    "                     LAMBDA_COORD,\n",
    "                     LAMBDA_CLASS,\n",
    "                     LAMBDA_NO_OBJECT, \n",
    "                     LAMBDA_OBJECT):\n",
    "    '''\n",
    "    y_true : (N batch, N grid h, N grid w, N anchor, 4 + 1 + N classes)\n",
    "    y_true[irow, i_gridh, i_gridw, i_anchor, :4] = center_x, center_y, w, h\n",
    "    \n",
    "        center_x : The x coordinate center of the bounding box.\n",
    "                   Rescaled to range between 0 and N gird  w (e.g., ranging between [0,13)\n",
    "        center_y : The y coordinate center of the bounding box.\n",
    "                   Rescaled to range between 0 and N gird  h (e.g., ranging between [0,13)\n",
    "        w        : The width of the bounding box.\n",
    "                   Rescaled to range between 0 and N gird  w (e.g., ranging between [0,13)\n",
    "        h        : The height of the bounding box.\n",
    "                   Rescaled to range between 0 and N gird  h (e.g., ranging between [0,13)\n",
    "                   \n",
    "    y_true[irow, i_gridh, i_gridw, i_anchor, 4] = ground truth confidence\n",
    "        \n",
    "        ground truth confidence is 1 if object exists in this (anchor box, gird cell) pair\n",
    "    \n",
    "    y_true[irow, i_gridh, i_gridw, i_anchor, 5 + iclass] = 1 if the object is in category <iclass> else 0\n",
    "    \n",
    "    =====================================================\n",
    "    tensor that connect to the YOLO model's hack input \n",
    "    =====================================================    \n",
    "    \n",
    "    true_boxes    \n",
    "    \n",
    "    =========================================\n",
    "    training parameters specification example \n",
    "    =========================================\n",
    "    GRID_W             = 13\n",
    "    GRID_H             = 13\n",
    "    BATCH_SIZE         = 34\n",
    "    ANCHORS = np.array([1.07709888,  1.78171903,  # anchor box 1, width , height\n",
    "                        2.71054693,  5.12469308,  # anchor box 2, width,  height\n",
    "                       10.47181473, 10.09646365,  # anchor box 3, width,  height\n",
    "                        5.48531347,  8.11011331]) # anchor box 4, width,  height\n",
    "    LAMBDA_NO_OBJECT = 1.0\n",
    "    LAMBDA_OBJECT    = 5.0\n",
    "    LAMBDA_COORD     = 1.0\n",
    "    LAMBDA_CLASS     = 1.0\n",
    "    ''' \n",
    "    BOX = int(len(ANCHORS)/2)    \n",
    "    # Step 1: Adjust prediction output\n",
    "    cell_grid   = get_cell_grid(GRID_W,GRID_H,BATCH_SIZE,BOX)\n",
    "    pred_box_xy, pred_box_wh, pred_box_conf, pred_box_class = adjust_scale_prediction(y_pred,cell_grid,ANCHORS)\n",
    "    # Step 2: Extract ground truth output\n",
    "    true_box_xy, true_box_wh, true_box_conf, true_box_class = extract_ground_truth(y_true)\n",
    "    # Step 3: Calculate loss for the bounding box parameters\n",
    "    loss_xywh, coord_mask = calc_loss_xywh(true_box_conf,LAMBDA_COORD,\n",
    "                                           true_box_xy, pred_box_xy,true_box_wh,pred_box_wh)\n",
    "    # Step 4: Calculate loss for the class probabilities\n",
    "    loss_class  = calc_loss_class(true_box_conf,LAMBDA_CLASS,\n",
    "                                   true_box_class,pred_box_class)\n",
    "    # Step 5: For each (grid cell, anchor) pair, \n",
    "    #         calculate the IoU between predicted and ground truth bounding box\n",
    "    true_box_conf_IOU = calc_IOU_pred_true_assigned(true_box_conf,\n",
    "                                                    true_box_xy, true_box_wh,\n",
    "                                                    pred_box_xy, pred_box_wh)\n",
    "    # Step 6: For each predicted bounded box from (grid cell, anchor box), \n",
    "    #         calculate the best IOU, regardless of the ground truth anchor box that each object gets assigned.\n",
    "    best_ious = calc_IOU_pred_true_best(pred_box_xy,pred_box_wh,true_boxes)\n",
    "    # Step 7: For each grid cell, calculate the L_{i,j}^{noobj}\n",
    "    conf_mask = get_conf_mask(best_ious, true_box_conf, true_box_conf_IOU,LAMBDA_NO_OBJECT, LAMBDA_OBJECT)\n",
    "    # Step 8: Calculate loss for the confidence\n",
    "    loss_conf = calc_loss_conf(conf_mask,true_box_conf_IOU, pred_box_conf)\n",
    "    \n",
    "    loss = loss_xywh + loss_conf + loss_class\n",
    "    return(loss)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    loss = custom_loss_core(y_true,\n",
    "                     y_pred,\n",
    "                     true_boxes,\n",
    "                     GRID_W,\n",
    "                     GRID_H,\n",
    "                     BATCH_SIZE,\n",
    "                     ANCHORS,\n",
    "                     LAMBDA_COORD,\n",
    "                     LAMBDA_CLASS,\n",
    "                     LAMBDA_NO_OBJECT, \n",
    "                     LAMBDA_OBJECT)\n",
    "\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eedc3a",
   "metadata": {},
   "source": [
    "### Cutom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829aba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo2_decode(feats, anchors, num_classes, input_shape, scale_x_y=None, calc_loss=False):\n",
    "    \"\"\"Decode final layer features to bounding box parameters.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    grid_shape = K.shape(feats)[1:3] # height, width\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n",
    "        [1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
    "        [grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    grid = K.cast(grid, K.dtype(feats))\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    if scale_x_y:\n",
    "        # Eliminate grid sensitivity trick involved in YOLOv4\n",
    "        #\n",
    "        # Reference Paper & code:\n",
    "        #     \"YOLOv4: Optimal Speed and Accuracy of Object Detection\"\n",
    "        #     https://arxiv.org/abs/2004.10934\n",
    "        #     https://github.com/opencv/opencv/issues/17148\n",
    "        #\n",
    "        box_xy_tmp = K.sigmoid(feats[..., :2]) * scale_x_y - (scale_x_y - 1) / 2\n",
    "        box_xy = (box_xy_tmp + grid) / K.cast(grid_shape[..., ::-1], K.dtype(feats))\n",
    "    else:\n",
    "        box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[..., ::-1], K.dtype(feats))\n",
    "    #box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(grid_shape[..., ::-1], K.dtype(feats))\n",
    "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[..., ::-1], K.dtype(feats))\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.softmax(feats[..., 5:])\n",
    "\n",
    "    if calc_loss == True:\n",
    "        return grid, feats, box_xy, box_wh\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab2635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from common.loss_utils import box_iou, box_iou_loss, smooth_labels\n",
    "\n",
    "def yolo2_loss(args, anchors, num_classes, label_smoothing=0, elim_grid_sense=False, use_crossentropy_loss=False, use_crossentropy_obj_loss=False, rescore_confidence=False, iou_loss_type=None):\n",
    "    \"\"\"\n",
    "    YOLOv2 loss function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_output : tensor\n",
    "        Final convolutional layer features.\n",
    "\n",
    "    y_true : array\n",
    "        output of preprocess_true_boxes, with shape [conv_height, conv_width, num_anchors, 6]\n",
    "\n",
    "    anchors : tensor\n",
    "        Anchor boxes for model.\n",
    "\n",
    "    num_classes : int\n",
    "        Number of object classes.\n",
    "\n",
    "    rescore_confidence : bool, default=False\n",
    "        If true then set confidence target to IOU of best predicted box with\n",
    "        the closest matching ground truth box.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    total_loss : float\n",
    "        total mean YOLOv2 loss across minibatch\n",
    "    \"\"\"\n",
    "    (yolo_output, y_true) = args\n",
    "    num_anchors = len(anchors)\n",
    "    scale_x_y = 1.05 if elim_grid_sense else None\n",
    "    yolo_output_shape = K.shape(yolo_output)\n",
    "    input_shape = K.cast(yolo_output_shape[1:3] * 32, K.dtype(y_true))\n",
    "    grid_shape = K.cast(yolo_output_shape[1:3], K.dtype(y_true)) # height, width\n",
    "    batch_size_f = K.cast(yolo_output_shape[0], K.dtype(yolo_output)) # batch size, float tensor\n",
    "    object_scale = 5\n",
    "    no_object_scale = 1\n",
    "    class_scale = 1\n",
    "    location_scale = 1\n",
    "\n",
    "    grid, raw_pred, pred_xy, pred_wh = yolo2_decode(\n",
    "        yolo_output, anchors, num_classes, input_shape, scale_x_y=scale_x_y, calc_loss=True)\n",
    "    pred_confidence = K.sigmoid(raw_pred[..., 4:5])\n",
    "    pred_class_prob = K.softmax(raw_pred[..., 5:])\n",
    "\n",
    "    object_mask = y_true[..., 4:5]\n",
    "\n",
    "    # Expand pred x,y,w,h to allow comparison with ground truth.\n",
    "    # batch, conv_height, conv_width, num_anchors, num_true_boxes, box_params\n",
    "    pred_box = K.concatenate([pred_xy, pred_wh])\n",
    "    pred_box = K.expand_dims(pred_box, 4)\n",
    "\n",
    "    raw_true_box = y_true[...,0:4]\n",
    "    raw_true_box = K.expand_dims(raw_true_box, 4)\n",
    "\n",
    "    iou_scores = box_iou(pred_box, raw_true_box, expand_dims=False)\n",
    "    iou_scores = K.squeeze(iou_scores, axis=0)\n",
    "\n",
    "    # Best IOUs for each location.\n",
    "    best_ious = K.max(iou_scores, axis=4)  # Best IOU scores.\n",
    "    best_ious = K.expand_dims(best_ious)\n",
    "\n",
    "    # A detector has found an object if IOU > thresh for some true box.\n",
    "    object_detections = K.cast(best_ious > 0.6, K.dtype(best_ious))\n",
    "\n",
    "    # Determine confidence weights from object and no_object weights.\n",
    "    # NOTE: YOLOv2 does not use binary cross-entropy. Here we try it.\n",
    "    no_object_weights = (no_object_scale * (1 - object_detections) *\n",
    "                         (1 - object_mask))\n",
    "    if use_crossentropy_obj_loss:\n",
    "        no_objects_loss = no_object_weights * K.binary_crossentropy(K.zeros(K.shape(pred_confidence)), pred_confidence, from_logits=False)\n",
    "\n",
    "        if rescore_confidence:\n",
    "            objects_loss = (object_scale * object_mask *\n",
    "                            K.binary_crossentropy(best_ious, pred_confidence, from_logits=False))\n",
    "        else:\n",
    "            objects_loss = (object_scale * object_mask *\n",
    "                            K.binary_crossentropy(K.ones(K.shape(pred_confidence)), pred_confidence, from_logits=False))\n",
    "    else:\n",
    "        no_objects_loss = no_object_weights * K.square(-pred_confidence)\n",
    "\n",
    "        if rescore_confidence:\n",
    "            objects_loss = (object_scale * object_mask *\n",
    "                            K.square(best_ious - pred_confidence))\n",
    "        else:\n",
    "            objects_loss = (object_scale * object_mask *\n",
    "                            K.square(1 - pred_confidence))\n",
    "    confidence_loss = objects_loss + no_objects_loss\n",
    "\n",
    "    # Classification loss for matching detections.\n",
    "    # NOTE: YOLOv2 does not use categorical cross-entropy loss.\n",
    "    #       Here we try it.\n",
    "    matching_classes = K.cast(y_true[..., 5], 'int32')\n",
    "    matching_classes = K.one_hot(matching_classes, num_classes)\n",
    "\n",
    "    if label_smoothing:\n",
    "        matching_classes = smooth_labels(matching_classes, label_smoothing)\n",
    "\n",
    "    if use_crossentropy_loss:\n",
    "        classification_loss = (class_scale * object_mask *\n",
    "                           K.expand_dims(K.categorical_crossentropy(matching_classes, pred_class_prob, from_logits=False), axis=-1))\n",
    "    else:\n",
    "        classification_loss = (class_scale * object_mask *\n",
    "                           K.square(matching_classes - pred_class_prob))\n",
    "\n",
    "    if iou_loss_type:\n",
    "        # Calculate IoU style loss as location loss\n",
    "        iou = box_iou_loss(raw_true_box, pred_box, iou_type=iou_loss_type)\n",
    "        iou = K.squeeze(iou, axis=-1)\n",
    "        iou_loss = location_scale * object_mask * (1 - iou)\n",
    "        location_loss = iou_loss\n",
    "    else:\n",
    "        # YOLOv2 location loss for matching detection boxes.\n",
    "        # Darknet trans box to calculate loss.\n",
    "        trans_true_xy = y_true[..., :2]*grid_shape[::-1] - grid\n",
    "        trans_true_wh = K.log(y_true[..., 2:4] / anchors * input_shape[::-1])\n",
    "        trans_true_wh = K.switch(object_mask, trans_true_wh, K.zeros_like(trans_true_wh)) # avoid log(0)=-inf\n",
    "        trans_true_boxes = K.concatenate([trans_true_xy, trans_true_wh])\n",
    "\n",
    "        # Unadjusted box predictions for loss.\n",
    "        trans_pred_boxes = K.concatenate(\n",
    "            (K.sigmoid(raw_pred[..., 0:2]), raw_pred[..., 2:4]), axis=-1)\n",
    "\n",
    "        location_loss = (location_scale * object_mask *\n",
    "                            K.square(trans_true_boxes - trans_pred_boxes))\n",
    "\n",
    "\n",
    "    confidence_loss_sum = K.sum(confidence_loss) / batch_size_f\n",
    "    location_loss_sum = K.sum(location_loss) / batch_size_f\n",
    "    # only involve class loss for multiple classes\n",
    "    if num_classes == 1:\n",
    "        classification_loss_sum = K.constant(0)\n",
    "    else:\n",
    "        classification_loss_sum = K.sum(classification_loss) / batch_size_f\n",
    "\n",
    "    total_loss = 0.5 * (\n",
    "        confidence_loss_sum + classification_loss_sum + location_loss_sum)\n",
    "\n",
    "    # Fit for tf 2.0.0 loss shape\n",
    "    total_loss = K.expand_dims(total_loss, axis=-1)\n",
    "\n",
    "    return total_loss, location_loss_sum, confidence_loss_sum, classification_loss_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6fa8d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 416, 416, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 416, 416, 32) 864         input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 416, 416, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 416, 416, 32) 0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_416to208 (MaxPooling2D (None, 208, 208, 32) 0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 208, 208, 64) 18432       maxpool1_416to208[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 208, 208, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 208, 208, 64) 0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_208to104 (MaxPooling2D (None, 104, 104, 64) 0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 104, 104, 128 73728       maxpool1_208to104[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 104, 104, 128 512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 104, 104, 128 0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 104, 104, 64) 8192        re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 104, 104, 64) 256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 104, 104, 64) 0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 104, 104, 128 73728       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 104, 104, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 104, 104, 128 0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_104to52 (MaxPooling2D) (None, 52, 52, 128)  0           re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 52, 52, 256)  294912      maxpool1_104to52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 52, 52, 256)  0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 52, 52, 128)  32768       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 52, 52, 128)  512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 52, 52, 128)  0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 52, 52, 256)  294912      re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 52, 52, 256)  0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_52to26 (MaxPooling2D)  (None, 26, 26, 256)  0           re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 26, 26, 512)  1179648     maxpool1_52to26[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)     (None, 26, 26, 512)  2048        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 26, 26, 512)  0           norm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 26, 26, 256)  131072      re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 26, 26, 256)  0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 26, 26, 512)  1179648     re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 26, 26, 512)  0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 26, 26, 256)  131072      re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 26, 26, 256)  0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 26, 26, 512)  1179648     re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 26, 26, 512)  0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_26to13 (MaxPooling2D)  (None, 13, 13, 512)  0           re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 13, 13, 1024) 4718592     maxpool1_26to13[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 13, 13, 1024) 0           norm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 13, 13, 512)  524288      re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 13, 13, 512)  0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 13, 13, 1024) 4718592     re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 13, 13, 1024) 0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 13, 13, 512)  524288      re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 13, 13, 512)  0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 13, 13, 1024) 4718592     re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 13, 13, 1024) 0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 13, 13, 1024) 9437184     re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 26, 26, 64)   32768       re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 13, 13, 1024) 0           norm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 26, 26, 64)   256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 13, 13, 1024) 9437184     re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 26, 26, 64)   0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 13, 13, 256)  0           re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 13, 13, 1024) 0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 13, 13, 1280) 0           lambda[0][0]                     \n",
      "                                                                 re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 13, 13, 1024) 11796480    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 13, 13, 1024) 0           norm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 13, 13, 125)  128125      re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Reshape)          (None, 13, 13, 5, 25 0           conv_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_hack (InputLayer)         [(None, 1, 1, 1, 50, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hack_layer (Lambda)             (None, 13, 13, 5, 25 0           final_output[0][0]               \n",
      "                                                                 input_hack[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 50,676,061\n",
      "Trainable params: 128,125\n",
      "Non-trainable params: 50,547,936\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "new_model = tf.keras.models.load_model('/home/dell/Downloads/keras-YOLOv3-model-set-master/yolo_relu_correct.h5', custom_objects={\"custom_loss\":custom_loss})\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95c75fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_1 [array([[[[-1.97681260e+00,  3.00715894e-01,  2.05217814e+00,\n",
      "           5.65047050e-03,  2.23614860e+00, -8.99692893e-01,\n",
      "          -2.87808204e+00,  1.76136121e-02, -5.05441129e-01,\n",
      "           5.32352507e-01,  2.87888706e-01, -7.91233480e-01,\n",
      "           2.21789815e-02,  4.67349261e-01, -2.53085256e+00,\n",
      "          -7.71328747e-01,  2.36902490e-01, -3.93446493e+00,\n",
      "           4.18320268e-01, -1.64212084e+00,  2.39077568e+00,\n",
      "           8.47958863e-01, -8.83276224e-01, -1.23097956e+00,\n",
      "          -6.17582023e-01,  3.66770387e-01,  9.30302501e-01,\n",
      "          -1.01010628e-01,  1.14673026e-01,  2.76207161e+00,\n",
      "           9.42763507e-01, -9.44271684e-01],\n",
      "         [-1.85534501e+00,  7.09573030e-01,  2.15900135e+00,\n",
      "           5.96114621e-03, -1.27020872e+00, -8.89727175e-01,\n",
      "          -3.10762525e+00,  2.89515764e-01, -5.24937749e-01,\n",
      "           5.79948485e-01,  4.44710940e-01, -5.17910480e-01,\n",
      "           4.50950980e-01, -3.21002483e-01, -2.96101022e+00,\n",
      "           8.80434036e-01, -1.95555866e-01, -5.66872501e+00,\n",
      "           5.80466747e-01, -2.41660786e+00,  3.01359105e+00,\n",
      "           1.14730000e+00,  1.53570855e+00,  3.02375883e-01,\n",
      "          -4.87782657e-01,  7.46452332e-01, -5.25101721e-01,\n",
      "           6.62995338e-01,  3.12425077e-01,  4.75563955e+00,\n",
      "          -3.02541763e-01, -3.10370296e-01],\n",
      "         [-7.42112160e-01, -7.88512468e-01,  1.08544934e+00,\n",
      "           5.60861966e-03, -1.13720727e+00, -5.30655861e-01,\n",
      "          -2.53620172e+00, -1.85087800e-01, -5.45906186e-01,\n",
      "           4.52371478e-01,  5.26907921e-01,  4.09042299e-01,\n",
      "           1.68566406e-01, -2.32526630e-01, -1.54206896e+00,\n",
      "           3.45321685e-01,  4.62028205e-01, -2.40176487e+00,\n",
      "          -8.89770836e-02, -9.20699120e-01,  1.17832386e+00,\n",
      "           8.20894182e-01, -1.49527355e-03,  1.11094391e+00,\n",
      "           7.45913386e-01, -8.22266400e-01,  3.10819000e-01,\n",
      "           3.69575471e-01,  2.55667299e-01,  1.62930429e+00,\n",
      "          -5.77605903e-01,  1.01248956e+00]],\n",
      "\n",
      "        [[ 1.84117556e-01,  5.67618668e-01, -1.70209193e+00,\n",
      "           4.42183157e-03,  2.92584968e+00, -3.10872436e+00,\n",
      "          -2.26651144e+00,  8.77783775e-01,  6.11837626e-01,\n",
      "           2.08051860e-01,  4.24761564e-01,  5.08638859e-01,\n",
      "          -1.30213702e+00,  7.48895586e-01,  7.59553254e-01,\n",
      "          -8.79566729e-01,  3.66445333e-01, -6.54359579e-01,\n",
      "           4.02669239e+00, -3.64376497e+00,  3.07912612e+00,\n",
      "           4.11184311e-01, -1.01990902e+00, -1.61002088e+00,\n",
      "          -1.62184685e-01,  4.03333753e-01,  6.14919960e-01,\n",
      "           8.87623668e-01,  2.07659245e-01, -4.00904799e+00,\n",
      "           1.47749674e+00, -1.07586181e+00],\n",
      "         [ 7.56171823e-01,  8.62566829e-01, -2.04381061e+00,\n",
      "           4.69284458e-03, -1.38522625e+00, -3.61223698e+00,\n",
      "          -2.39524388e+00,  5.17754197e-01,  8.06007624e-01,\n",
      "          -1.39663994e-01,  3.77174318e-01,  5.32257020e-01,\n",
      "          -1.50178993e+00,  8.47471535e-01,  9.79094863e-01,\n",
      "           8.84310186e-01, -3.58017206e-01, -6.10163331e-01,\n",
      "           5.63087034e+00, -4.23320723e+00,  3.90957737e+00,\n",
      "           4.16783571e-01,  5.01352847e-01,  4.72329855e-01,\n",
      "           1.42917763e-02,  8.62694263e-01, -7.03266025e-01,\n",
      "           1.18992019e+00,  1.42383933e-01, -5.60479689e+00,\n",
      "           2.00147688e-01, -2.15183020e-01],\n",
      "         [ 1.84126958e-01, -6.55253887e-01, -9.34048116e-01,\n",
      "           4.41984180e-03, -1.54746354e+00, -1.88883471e+00,\n",
      "          -1.71836436e+00,  1.07410479e+00,  7.78048217e-01,\n",
      "           7.11615905e-02,  3.52276802e-01,  1.32914126e+00,\n",
      "          -3.79538387e-01,  7.49561906e-01,  5.78177989e-01,\n",
      "           2.54937023e-01,  5.13554633e-01, -4.93069977e-01,\n",
      "           2.82577848e+00, -3.01130104e+00,  1.75621367e+00,\n",
      "          -6.36997540e-03,  3.34549665e-01,  1.64409268e+00,\n",
      "           9.34322417e-01, -1.07069457e+00,  8.53896558e-01,\n",
      "           1.38622260e+00,  2.35649392e-01, -2.28141046e+00,\n",
      "          -2.17131987e-01,  1.57064307e+00]],\n",
      "\n",
      "        [[ 1.15802419e+00,  9.17492568e-01, -1.02650428e+00,\n",
      "           5.56028914e-04, -1.05729409e-01, -2.07461381e+00,\n",
      "           2.73874831e+00,  3.61896902e-02, -4.12915081e-01,\n",
      "          -1.23510780e-02, -5.17932093e-03, -5.09592474e-01,\n",
      "          -1.65753931e-01,  4.41876799e-01,  2.46199393e+00,\n",
      "          -3.22095901e-01,  2.36284629e-01,  1.06926668e+00,\n",
      "           4.19700575e+00, -1.31286728e+00,  1.92496324e+00,\n",
      "          -3.52654600e+00, -1.02007127e+00, -2.49499939e-02,\n",
      "          -3.84554237e-01, -1.62261978e-01,  9.77807164e-01,\n",
      "          -7.75255919e-01, -3.02718461e-01,  1.16476667e+00,\n",
      "           8.77388179e-01, -6.29772842e-01],\n",
      "         [ 1.98416734e+00,  1.30637813e+00, -1.01695240e+00,\n",
      "           6.67489134e-04, -4.85773265e-01, -2.59598398e+00,\n",
      "           4.17153805e-01,  1.87052071e-01, -3.97166163e-01,\n",
      "          -4.03728038e-01, -1.35645986e-01, -4.85781014e-01,\n",
      "          -6.45500362e-01,  4.06107992e-01,  3.05237842e+00,\n",
      "           9.23443317e-01, -3.21164906e-01,  1.21272469e+00,\n",
      "           5.67777395e+00, -1.89512873e+00,  2.22711921e+00,\n",
      "          -5.33974266e+00,  5.70508659e-01,  1.81571953e-02,\n",
      "          -3.36931944e-01,  5.24807155e-01, -5.43299839e-02,\n",
      "          -1.14729309e+00, -5.39704502e-01,  1.74902511e+00,\n",
      "          -1.38267875e+00, -3.18283916e-01],\n",
      "         [ 7.59240687e-01, -1.39225408e-01, -5.11537373e-01,\n",
      "           9.87472478e-04,  3.91610771e-01, -1.54508674e+00,\n",
      "          -7.02825606e-01,  6.80673122e-01, -4.00488913e-01,\n",
      "          -4.18990217e-02, -1.60937369e-01,  4.82040673e-01,\n",
      "          -5.21362185e-01,  5.51259518e-01,  1.04358339e+00,\n",
      "          -1.49754435e-01,  4.49111462e-01,  7.27589965e-01,\n",
      "           2.00781155e+00, -5.49509346e-01,  1.20258987e+00,\n",
      "          -2.53992152e+00, -1.10734180e-01, -2.28733808e-01,\n",
      "          -3.34848255e-01, -3.21521312e-01,  9.57997978e-01,\n",
      "          -7.82051623e-01, -3.59983057e-01,  6.63005233e-01,\n",
      "          -1.20387375e+00,  5.75986147e-01]]],\n",
      "\n",
      "\n",
      "       [[[-3.57802868e+00,  2.24262714e-01,  3.22842550e+00,\n",
      "           4.90928674e-03,  2.42263174e+00, -2.05015159e+00,\n",
      "          -1.73726797e+00, -1.47835657e-01,  7.18003988e-01,\n",
      "           3.96392569e-02,  3.22250813e-01,  2.19533071e-01,\n",
      "          -9.12815928e-01,  6.87295973e-01, -3.14793611e+00,\n",
      "          -9.58409309e-01,  2.70817459e-01,  3.31328064e-01,\n",
      "          -3.27882218e+00,  1.99403393e+00,  1.03907192e+00,\n",
      "          -6.57133341e-01, -1.86844230e+00, -1.34031332e+00,\n",
      "           3.62056375e-01,  3.88936758e-01,  4.78616565e-01,\n",
      "           9.19128597e-01,  6.41389117e-02,  3.25798726e+00,\n",
      "           1.45170462e+00, -1.09420764e+00],\n",
      "         [-3.63177228e+00,  6.47924125e-01,  4.16368246e+00,\n",
      "           5.25643164e-03, -1.20491302e+00, -2.57213044e+00,\n",
      "          -1.43725586e+00,  4.54978466e-01,  8.80717754e-01,\n",
      "          -3.86705339e-01,  1.59835488e-01,  6.38410628e-01,\n",
      "          -8.65163743e-01, -4.58375067e-01, -3.74666691e+00,\n",
      "           8.28392923e-01, -4.22020197e-01,  5.65132558e-01,\n",
      "          -4.97441530e+00,  1.99174619e+00,  1.31285715e+00,\n",
      "          -6.07808471e-01, -1.75414848e+00,  1.98953927e-01,\n",
      "           1.00582552e+00,  8.23569298e-01, -4.74432737e-01,\n",
      "           9.50726211e-01, -6.53141588e-02,  4.59465218e+00,\n",
      "           1.91603339e+00, -2.05035374e-01],\n",
      "         [-2.15469170e+00, -8.07116866e-01,  1.66323650e+00,\n",
      "           4.79599275e-03, -1.21637523e+00, -1.05792284e+00,\n",
      "          -6.94574058e-01, -5.31910300e-01,  9.03968930e-01,\n",
      "          -1.85282126e-01,  1.22740977e-01,  1.06737804e+00,\n",
      "          -8.16626847e-02, -4.75561023e-01, -1.78063369e+00,\n",
      "           4.57186818e-01,  4.30354476e-01,  2.23277826e-02,\n",
      "          -1.62410760e+00,  1.43571103e+00,  8.46611261e-01,\n",
      "          -2.26396576e-01, -1.31190085e+00,  1.44460583e+00,\n",
      "           1.82334077e+00, -1.04793334e+00,  8.19699109e-01,\n",
      "           1.12654316e+00,  5.43984994e-02,  2.42009878e+00,\n",
      "           1.83635831e+00,  1.45909178e+00]],\n",
      "\n",
      "        [[ 7.36272812e-01, -1.17447591e+00, -9.14056540e-01,\n",
      "           1.75239542e-03,  3.13336968e+00, -1.30456960e+00,\n",
      "          -3.47767234e+00,  5.76210380e-01, -1.46615136e+00,\n",
      "          -2.92194664e-01, -2.56413519e-01,  2.16452360e+00,\n",
      "          -2.87486506e+00,  7.78174341e-01, -3.86555821e-01,\n",
      "          -1.53278565e+00,  4.49873894e-01,  6.35469151e+00,\n",
      "          -8.81659317e+00,  1.44883668e+00,  4.55165356e-02,\n",
      "           5.92182159e+00, -2.18232942e+00, -1.95405734e+00,\n",
      "           9.07231942e-02,  4.86590296e-01, -1.13823318e+00,\n",
      "          -1.58804691e+00, -6.64004982e-01, -7.55571604e+00,\n",
      "           1.20856154e+00, -1.21651065e+00],\n",
      "         [ 8.29099417e-01, -9.71832156e-01, -9.43769813e-01,\n",
      "           1.76873687e-03, -1.22277689e+00, -1.42202544e+00,\n",
      "          -2.46640229e+00,  5.40733516e-01, -1.53086233e+00,\n",
      "          -8.79898012e-01, -5.66864014e-01,  2.19042587e+00,\n",
      "          -3.45494795e+00,  6.83685660e-01, -3.31610411e-01,\n",
      "           5.96780241e-01, -6.86591804e-01,  8.75297737e+00,\n",
      "          -1.18935652e+01,  1.64961565e+00,  1.40935197e-01,\n",
      "           8.27981853e+00, -2.48173451e+00,  2.18573332e-01,\n",
      "           7.78793156e-01,  9.44907606e-01, -1.75752103e+00,\n",
      "          -2.34908557e+00, -1.01123166e+00, -1.05140114e+01,\n",
      "           1.63337815e+00,  1.35244476e-02],\n",
      "         [ 2.61147052e-01, -1.15085411e+00, -2.48865083e-01,\n",
      "           1.75967836e-03, -1.67418098e+00, -5.40133953e-01,\n",
      "          -1.19315600e+00,  6.70797408e-01, -1.41143024e+00,\n",
      "          -3.95691842e-01, -6.81359291e-01,  1.81883025e+00,\n",
      "          -1.34304798e+00,  4.48767751e-01,  1.73293993e-01,\n",
      "           2.13975802e-01,  4.00005460e-01,  4.16647768e+00,\n",
      "          -5.28244162e+00,  7.03381777e-01,  3.45316380e-01,\n",
      "           4.19910431e+00, -6.79341316e-01,  2.04825807e+00,\n",
      "           1.25643575e+00, -1.39974630e+00,  2.02661023e-01,\n",
      "          -1.71095943e+00, -7.45236337e-01, -4.64923096e+00,\n",
      "           1.43364525e+00,  2.02705979e+00]],\n",
      "\n",
      "        [[ 2.80109096e+00, -1.13739073e+00, -2.73623419e+00,\n",
      "          -1.76517887e-03,  2.18442291e-01,  4.30928677e-01,\n",
      "           8.48084152e-01, -1.83561102e-01,  6.39456749e-01,\n",
      "           6.32823586e-01,  6.00484431e-01,  3.91269833e-01,\n",
      "          -1.77421057e+00,  6.34658754e-01,  3.10670614e+00,\n",
      "          -7.62936175e-01,  3.64532530e-01,  3.08421344e-01,\n",
      "          -2.81598306e+00,  1.06314528e+00, -1.43426347e+00,\n",
      "          -3.29919726e-01, -6.87598407e-01, -1.38022989e-01,\n",
      "          -1.96281493e-01, -2.79887151e-02, -7.18292177e-01,\n",
      "           1.03822172e+00,  2.32223511e-01,  3.53301692e+00,\n",
      "           1.50945628e+00, -8.12402248e-01],\n",
      "         [ 2.94853616e+00, -8.53849232e-01, -3.51626492e+00,\n",
      "          -2.17695604e-03, -3.91630560e-01,  7.04242587e-01,\n",
      "          -2.79103845e-01,  3.18288445e-01,  6.45157754e-01,\n",
      "           3.74928951e-01,  5.40818989e-01,  6.31085515e-01,\n",
      "          -2.18807888e+00,  5.43570817e-01,  3.92303562e+00,\n",
      "           8.96619678e-01, -4.70026970e-01,  3.80542487e-01,\n",
      "          -5.02840900e+00,  1.50673878e+00, -1.79252732e+00,\n",
      "          -5.42764068e-01,  6.94652438e-01, -6.27249777e-02,\n",
      "           2.34513178e-01,  6.51745796e-01, -1.02660251e+00,\n",
      "           6.78659379e-01,  1.03197820e-01,  4.98706341e+00,\n",
      "          -4.27309573e-01, -1.85670957e-01],\n",
      "         [ 1.57235563e+00, -7.88554192e-01, -1.71878254e+00,\n",
      "          -1.21735991e-03,  1.28305301e-01,  3.92337918e-01,\n",
      "          -3.77912551e-01,  3.54858041e-01,  4.69483674e-01,\n",
      "           6.49792492e-01,  1.84124276e-01,  1.31924760e+00,\n",
      "          -1.72320330e+00,  5.29976726e-01,  1.61516511e+00,\n",
      "           4.17490005e-02,  4.72712547e-01,  1.45841762e-01,\n",
      "          -1.11683524e+00,  8.04535747e-01, -7.62672007e-01,\n",
      "          -3.79996896e-01,  8.95428598e-01,  2.38423962e-02,\n",
      "          -2.05477789e-01, -5.20929575e-01,  2.99866080e-01,\n",
      "           5.53709388e-01,  6.23395517e-02,  2.37004423e+00,\n",
      "          -2.42141694e-01,  1.00010288e+00]]],\n",
      "\n",
      "\n",
      "       [[[-1.24851060e+00,  6.43606603e-01,  2.88340330e+00,\n",
      "           3.96968331e-03, -4.32460964e-01,  2.34766078e+00,\n",
      "           2.91964769e+00, -1.60648584e-01, -3.80707115e-01,\n",
      "          -2.77900934e-01,  8.37079063e-02, -1.21371460e+00,\n",
      "          -1.25262871e-01,  3.47026259e-01, -1.47271764e+00,\n",
      "          -5.10356784e-01,  1.01300366e-01,  1.18597031e+00,\n",
      "           3.28367639e+00,  5.25643528e-01, -2.55295348e+00,\n",
      "          -3.18783379e+00, -8.38528693e-01,  4.20546353e-01,\n",
      "          -2.26785727e-02,  1.39388710e-01,  8.59130323e-01,\n",
      "          -7.73220479e-01, -3.36922675e-01,  5.32964170e-01,\n",
      "           1.27734399e+00, -5.64529240e-01],\n",
      "         [-1.94776952e+00,  9.36563909e-01,  3.24404263e+00,\n",
      "           3.86713515e-03, -1.86953470e-01,  2.56609035e+00,\n",
      "           1.23012483e+00,  9.34517264e-01, -4.56443518e-01,\n",
      "          -6.49710655e-01, -8.95072073e-02, -4.16050464e-01,\n",
      "           6.73855692e-02, -7.45613039e-01, -1.58279550e+00,\n",
      "           6.32881224e-01, -2.67332077e-01,  1.29504848e+00,\n",
      "           4.79855537e+00,  3.04648757e-01, -3.16327429e+00,\n",
      "          -4.97400570e+00, -7.88841426e-01, -2.11385071e-01,\n",
      "           4.09307510e-01,  5.17220557e-01,  4.09536004e-01,\n",
      "          -1.13885951e+00, -5.19245386e-01,  6.98498607e-01,\n",
      "           3.09830636e-01, -1.16973467e-01],\n",
      "         [-2.08808228e-01, -7.74033740e-02,  1.31118417e+00,\n",
      "           4.04459052e-03,  4.59386021e-01,  1.42612112e+00,\n",
      "          -7.65247405e-01, -9.15510714e-01, -4.99082685e-01,\n",
      "          -3.79188478e-01, -2.10063234e-01,  5.56378126e-01,\n",
      "           3.78073990e-01, -2.55098909e-01, -7.47391582e-01,\n",
      "           1.14225462e-01,  3.77466023e-01,  8.13096106e-01,\n",
      "           1.44489574e+00,  8.21478516e-02, -1.83104241e+00,\n",
      "          -2.15836120e+00, -7.78715789e-01, -3.72774124e-01,\n",
      "          -2.22775593e-01, -1.76368117e-01,  9.91772830e-01,\n",
      "          -9.95513022e-01, -4.27962363e-01,  2.51592278e-01,\n",
      "           3.17962378e-01,  4.89237696e-01]],\n",
      "\n",
      "        [[ 8.45707536e-01, -1.77249157e+00,  4.96415108e-01,\n",
      "           2.54675600e-04,  1.29208341e-01,  3.59904337e+00,\n",
      "           1.32668924e+00,  3.80900316e-02,  7.07257032e-01,\n",
      "           6.63842440e-01,  5.94553888e-01, -4.26584147e-02,\n",
      "          -1.56126940e+00,  6.27233744e-01, -1.37911177e+00,\n",
      "          -1.14695489e+00,  2.52176255e-01, -1.60664052e-01,\n",
      "           3.01236367e+00,  1.78253269e+00, -3.18493843e+00,\n",
      "           2.76638687e-01, -1.02430356e+00,  5.79171926e-02,\n",
      "          -1.03301093e-01,  1.63536444e-01, -1.73861575e+00,\n",
      "           1.12442601e+00,  2.55927861e-01, -3.07335377e+00,\n",
      "           1.56199992e+00, -9.15355146e-01],\n",
      "         [ 3.21269482e-01, -1.33712363e+00,  8.35378647e-01,\n",
      "          -1.50194974e-04, -2.37943009e-01,  4.66366434e+00,\n",
      "           8.68547916e-01,  8.76607776e-01,  7.63237953e-01,\n",
      "           4.75437641e-01,  5.85052848e-01,  5.75877786e-01,\n",
      "          -1.57451057e+00, -3.87711108e-01, -1.71360648e+00,\n",
      "           5.28816342e-01, -5.11753917e-01, -3.27945977e-01,\n",
      "           4.27021170e+00,  1.62992370e+00, -4.01165581e+00,\n",
      "           3.58885050e-01, -9.70468998e-01, -1.40352324e-01,\n",
      "           4.69006389e-01,  5.72844326e-01, -1.66810250e+00,\n",
      "           9.97445345e-01,  2.26336449e-01, -4.13488483e+00,\n",
      "           5.79606652e-01, -2.28326157e-01],\n",
      "         [ 6.55666739e-02, -9.72970963e-01,  6.92553401e-01,\n",
      "           4.33731213e-04,  6.05216548e-02,  1.98935997e+00,\n",
      "          -5.83984435e-01, -3.24428350e-01,  5.80983818e-01,\n",
      "           7.73272753e-01,  2.88299084e-01,  1.38974881e+00,\n",
      "          -2.02427715e-01, -1.65591657e-01, -6.54769719e-01,\n",
      "           6.89706877e-02,  3.80341351e-01, -3.72491539e-01,\n",
      "           2.12385654e+00,  1.05171180e+00, -2.09546423e+00,\n",
      "          -1.16590839e-02,  1.36345312e-01,  1.84450239e-01,\n",
      "          -5.60264945e-01, -5.01205564e-01, -7.06389368e-01,\n",
      "           7.45799303e-01,  1.50497526e-01, -1.37330830e+00,\n",
      "           4.75025117e-01,  7.61357725e-01]],\n",
      "\n",
      "        [[ 9.83365476e-01, -1.12897146e+00, -2.51054478e+00,\n",
      "          -1.72205642e-03, -1.12283504e+00,  2.75474668e+00,\n",
      "           2.50077367e+00, -4.38631892e-01, -4.20942754e-01,\n",
      "           1.52450562e-01,  3.58454019e-01, -1.03551519e+00,\n",
      "           1.55481920e-01,  3.74152541e-01,  2.33394003e+00,\n",
      "          -6.11936092e-01,  1.70975566e-01, -3.70386267e+00,\n",
      "          -1.95857361e-01,  9.34585154e-01, -1.29069436e+00,\n",
      "           1.33786786e+00, -8.76914635e-02,  1.24187684e+00,\n",
      "           2.74418164e-02, -2.18494833e-01, -1.95858479e+00,\n",
      "           4.33712900e-01,  1.70360237e-01,  2.67895627e+00,\n",
      "           1.37717497e+00, -2.32322633e-01],\n",
      "         [ 8.76954734e-01, -6.15872025e-01, -2.85512328e+00,\n",
      "          -2.11443519e-03,  3.58362108e-01,  3.37708378e+00,\n",
      "           1.62324473e-01,  7.38702297e-01, -3.09656113e-01,\n",
      "           5.97662292e-02,  5.56729853e-01, -4.23602074e-01,\n",
      "           7.90151298e-01, -5.85513234e-01,  2.28948808e+00,\n",
      "           7.22286642e-01, -3.41923803e-01, -5.23319912e+00,\n",
      "          -2.34474495e-01,  8.84412766e-01, -1.70359111e+00,\n",
      "           1.40477395e+00,  1.77070844e+00, -2.96745151e-01,\n",
      "           4.98966664e-01,  4.11702901e-01, -1.50149775e+00,\n",
      "           8.39313567e-01,  3.08332503e-01,  3.27669668e+00,\n",
      "          -1.15178013e+00, -2.85798032e-02],\n",
      "         [ 6.33549243e-02, -2.57032901e-01, -1.67914748e+00,\n",
      "          -9.44516156e-04,  6.94996893e-01,  1.34385085e+00,\n",
      "          -1.35598159e+00, -2.47621700e-01, -4.90059644e-01,\n",
      "           2.22081512e-01,  2.81697959e-01,  9.02041674e-01,\n",
      "           5.60419440e-01, -1.08603336e-01,  1.25890958e+00,\n",
      "          -5.22447415e-02,  3.99612904e-01, -1.93529427e+00,\n",
      "          -3.52459550e-01,  4.31258708e-01, -8.50692511e-01,\n",
      "           9.40146983e-01,  1.49166429e+00, -1.06029272e+00,\n",
      "          -8.81933570e-01,  3.34629044e-02, -1.33522356e+00,\n",
      "           1.42940432e-01,  1.03190884e-01,  1.00611556e+00,\n",
      "          -6.67383790e-01,  1.39808983e-01]]]], dtype=float32)]\n",
      "conv_2 [array([[[[ 2.37069372e-03,  7.89652206e-03,  1.51842728e-03, ...,\n",
      "           4.36895806e-03, -5.18112890e-02,  5.05250122e-04],\n",
      "         [ 2.76693702e-03,  3.79553847e-02, -5.12898825e-02, ...,\n",
      "          -1.11647258e-02,  3.52098681e-02, -4.44589183e-02],\n",
      "         [-2.56539714e-02, -8.42237286e-03,  1.30992634e-02, ...,\n",
      "          -1.74269523e-03, -1.24087937e-01, -2.55958736e-02],\n",
      "         ...,\n",
      "         [-1.09457420e-02,  5.84450411e-03, -5.44912124e-04, ...,\n",
      "          -2.14632675e-02, -7.34193102e-02, -5.03591187e-02],\n",
      "         [-1.64541509e-03,  6.99343458e-02, -1.03204653e-01, ...,\n",
      "           1.11051295e-02,  4.45612259e-02,  5.34989825e-03],\n",
      "         [ 7.47897709e-03, -2.06073765e-02,  2.61040658e-01, ...,\n",
      "           5.24943415e-03,  5.17851487e-03,  1.25211067e-02]],\n",
      "\n",
      "        [[-2.32273713e-03, -5.14770800e-04, -1.50514590e-02, ...,\n",
      "           9.39346850e-03, -6.08954355e-02,  7.35920714e-03],\n",
      "         [ 2.58418312e-03,  3.47387940e-02,  4.29335162e-02, ...,\n",
      "          -1.01577640e-02,  1.29268002e-02, -5.91109544e-02],\n",
      "         [-5.81302829e-02, -6.63676838e-05, -1.30437762e-02, ...,\n",
      "          -2.66137645e-02, -2.06426293e-01,  3.43914814e-02],\n",
      "         ...,\n",
      "         [-4.20865752e-02,  5.62513620e-03, -5.03419479e-03, ...,\n",
      "           8.58664792e-03, -1.08718984e-01, -3.92629206e-02],\n",
      "         [-4.30301018e-03,  1.19377702e-01, -2.75265966e-02, ...,\n",
      "           1.06194234e-02,  8.29759687e-02,  1.45058772e-02],\n",
      "         [ 1.88428897e-03, -6.91078091e-03,  1.17148362e-01, ...,\n",
      "          -1.71016646e-03, -7.42920628e-03,  5.85557241e-03]],\n",
      "\n",
      "        [[-9.25954524e-03, -3.66059667e-03, -3.98910269e-02, ...,\n",
      "          -5.85414283e-03, -7.64801204e-02,  4.60916311e-02],\n",
      "         [ 9.86889703e-04,  2.85833795e-03,  9.09086615e-02, ...,\n",
      "           7.00630667e-03, -2.11228002e-02, -1.54304234e-02],\n",
      "         [-2.33884715e-02, -1.42825628e-02,  7.61127705e-03, ...,\n",
      "           4.30854373e-02, -1.42277643e-01, -6.78981934e-03],\n",
      "         ...,\n",
      "         [-4.45470139e-02, -4.47909348e-02,  5.77590568e-03, ...,\n",
      "           1.64259709e-02, -1.10176146e-01, -4.15909067e-02],\n",
      "         [-3.68706882e-03,  1.07235603e-01,  4.75461632e-02, ...,\n",
      "          -2.80042266e-04,  9.89075974e-02,  1.34633938e-02],\n",
      "         [ 3.56436823e-03, -2.54525077e-02, -1.67524204e-01, ...,\n",
      "           2.03228279e-04, -3.58483344e-02, -1.13261938e-02]]],\n",
      "\n",
      "\n",
      "       [[[-7.66811369e-04, -3.42001654e-02, -8.46064016e-02, ...,\n",
      "          -5.81101403e-02, -6.53730752e-03, -2.19767243e-02],\n",
      "         [ 3.64135555e-03,  2.08511204e-02, -3.68087441e-02, ...,\n",
      "          -2.56373305e-02,  7.93601852e-03, -5.44083528e-02],\n",
      "         [-3.27464230e-02, -3.04505453e-02, -3.27508003e-02, ...,\n",
      "          -6.09407239e-02,  7.81637728e-02, -3.50290053e-02],\n",
      "         ...,\n",
      "         [-3.85301895e-02, -1.63126625e-02, -4.33055460e-02, ...,\n",
      "           1.14144161e-01,  5.42214215e-02, -2.08730623e-02],\n",
      "         [-1.48063048e-03,  5.29315770e-02, -1.54040188e-01, ...,\n",
      "           4.08741646e-03, -2.98106801e-02,  2.86506722e-03],\n",
      "         [-5.68540127e-04, -1.93927474e-02,  3.69858176e-01, ...,\n",
      "           6.06753537e-03, -6.54526846e-03,  3.42034968e-03]],\n",
      "\n",
      "        [[-6.69330172e-03, -9.98736266e-03, -6.30158186e-02, ...,\n",
      "           6.53794501e-04,  2.57218182e-02, -1.47861391e-02],\n",
      "         [ 5.91969676e-03,  2.80730538e-02,  9.20835659e-02, ...,\n",
      "           6.37830887e-03,  6.23639068e-03, -7.46341869e-02],\n",
      "         [-6.00810349e-02, -1.04746001e-03, -2.66797338e-02, ...,\n",
      "           1.07768059e-01,  6.81513026e-02,  1.78397112e-02],\n",
      "         ...,\n",
      "         [-6.25381097e-02, -9.61735751e-03,  6.83123320e-02, ...,\n",
      "           6.38073981e-02,  3.16240117e-02, -5.01894914e-02],\n",
      "         [-4.88230679e-03,  1.17427923e-01, -1.50380265e-02, ...,\n",
      "           2.27903556e-02, -5.94121292e-02,  1.50112351e-02],\n",
      "         [-5.53007098e-03, -4.67299577e-03, -6.49238518e-03, ...,\n",
      "           2.70261196e-03, -1.51121151e-03,  7.13674119e-03]],\n",
      "\n",
      "        [[-9.33787227e-03, -3.06511880e-04, -5.88420443e-02, ...,\n",
      "          -1.59253310e-02, -5.59293432e-03,  1.90209430e-02],\n",
      "         [ 3.24672507e-03, -3.38906189e-03,  1.49611309e-01, ...,\n",
      "           9.56193171e-03,  2.17319913e-02, -4.70345654e-02],\n",
      "         [-3.13671045e-02,  1.87574495e-02, -2.09812261e-02, ...,\n",
      "           1.99608523e-02, -5.52534349e-02,  2.41940818e-03],\n",
      "         ...,\n",
      "         [-4.70061116e-02, -2.00043749e-02,  2.00442728e-02, ...,\n",
      "           8.13390613e-02, -1.20281859e-03, -2.85317805e-02],\n",
      "         [-5.51552512e-03,  1.12240441e-01,  3.42899635e-02, ...,\n",
      "          -1.63756590e-02, -4.86782491e-02,  1.43286735e-02],\n",
      "         [-3.37374373e-03, -2.33774967e-02, -4.12039697e-01, ...,\n",
      "          -4.58813878e-03, -1.62586514e-02, -4.05331887e-03]]],\n",
      "\n",
      "\n",
      "       [[[-7.83995353e-03, -1.96921770e-02, -3.04345638e-02, ...,\n",
      "          -5.63075691e-02,  4.00715711e-04, -1.49458740e-02],\n",
      "         [-1.68130398e-04, -3.34491162e-03,  1.29626291e-02, ...,\n",
      "          -2.45978832e-02,  1.92419835e-03, -1.43400421e-02],\n",
      "         [-1.97444856e-03,  1.14453332e-02, -3.57122608e-02, ...,\n",
      "          -3.73212956e-02,  1.99299194e-02, -4.10908014e-02],\n",
      "         ...,\n",
      "         [-3.31817754e-02,  1.60136092e-02,  1.11979917e-02, ...,\n",
      "           9.67969894e-02,  6.38577864e-02,  8.93648341e-03],\n",
      "         [-3.82961822e-03,  5.21302558e-02, -7.09531680e-02, ...,\n",
      "           2.63961777e-03, -1.38310306e-02, -2.38672737e-02],\n",
      "         [-5.00192260e-03, -4.54177037e-02,  1.77986309e-01, ...,\n",
      "           3.02135129e-03,  1.51101463e-02, -1.04161827e-02]],\n",
      "\n",
      "        [[-4.94736293e-03, -2.18334515e-02, -4.04424146e-02, ...,\n",
      "           8.08995124e-03,  1.63762663e-02, -3.20279561e-02],\n",
      "         [ 2.16646888e-03, -4.39750683e-03,  1.32288978e-01, ...,\n",
      "          -4.93034022e-03, -2.16411930e-02, -4.16001901e-02],\n",
      "         [-4.79787588e-02, -1.08035677e-03,  2.30716616e-02, ...,\n",
      "           9.47302505e-02,  2.61591282e-02, -4.57013724e-03],\n",
      "         ...,\n",
      "         [-3.98849994e-02, -2.32140087e-02,  2.09936053e-02, ...,\n",
      "           1.25490338e-01,  7.53770629e-03, -2.43949927e-02],\n",
      "         [-8.96552671e-03,  6.09082021e-02,  5.34963124e-02, ...,\n",
      "           1.75531451e-02, -1.08316289e-02,  2.87640351e-03],\n",
      "         [-9.68487468e-03, -4.00207415e-02, -2.93891251e-01, ...,\n",
      "           2.55451247e-04,  2.68911514e-02, -9.74246673e-03]],\n",
      "\n",
      "        [[ 9.78632248e-04, -1.38650015e-02,  2.21323334e-02, ...,\n",
      "          -3.10531761e-02,  2.36108694e-02,  2.39372142e-02],\n",
      "         [-6.88229411e-05, -1.23515576e-02,  6.72197491e-02, ...,\n",
      "           9.39260237e-03,  4.71138768e-03, -2.04412229e-02],\n",
      "         [-1.81783661e-02,  8.89291056e-03, -2.24474724e-03, ...,\n",
      "           8.22334588e-02,  7.42900139e-03,  2.97778454e-02],\n",
      "         ...,\n",
      "         [-1.11075193e-02,  1.92783102e-02,  5.14180958e-02, ...,\n",
      "           5.48331775e-02,  1.59328301e-02, -1.82722528e-02],\n",
      "         [-8.37363210e-03,  6.66288659e-02,  4.68164459e-02, ...,\n",
      "          -1.51421418e-02, -1.58793703e-02,  2.10825983e-03],\n",
      "         [-5.50602097e-03, -4.74959649e-02, -4.18068796e-01, ...,\n",
      "          -5.42931492e-03,  2.44847927e-02, -9.66573041e-03]]]],\n",
      "      dtype=float32)]\n",
      "conv_3 [array([[[[ 1.12040658e-02,  2.31441520e-02,  2.70016976e-02, ...,\n",
      "          -2.51874961e-02,  3.86967212e-02,  9.04722605e-03],\n",
      "         [ 8.13000929e-03,  1.43186201e-03,  2.21933071e-02, ...,\n",
      "          -2.13965634e-03, -3.82354809e-03,  5.89703768e-03],\n",
      "         [-5.42880185e-02,  7.88594782e-03,  4.55086231e-02, ...,\n",
      "           6.04046918e-02,  9.95770656e-03, -1.57629643e-02],\n",
      "         ...,\n",
      "         [-1.11217648e-02, -3.46392719e-03,  1.89348646e-02, ...,\n",
      "           2.47771125e-02, -5.91752157e-02, -2.40886956e-02],\n",
      "         [ 1.91537326e-03,  2.11329665e-02, -4.47335914e-02, ...,\n",
      "           2.34902454e-05,  1.92664377e-02, -4.22256663e-02],\n",
      "         [ 2.52217073e-02, -5.02757840e-02,  1.86731236e-03, ...,\n",
      "           3.66628207e-02, -1.70211345e-02,  1.70509405e-02]],\n",
      "\n",
      "        [[-2.13852501e-04,  4.60458733e-02,  6.37384653e-02, ...,\n",
      "          -1.35729127e-02,  9.44046006e-02,  5.33941993e-03],\n",
      "         [-1.78100439e-04, -4.49403236e-03,  1.96689051e-02, ...,\n",
      "          -2.70899525e-03, -2.02894974e-02, -4.22664743e-04],\n",
      "         [-3.16013657e-02, -3.07201911e-02,  3.46309468e-02, ...,\n",
      "          -3.51642892e-02, -7.05946609e-02,  6.15323428e-03],\n",
      "         ...,\n",
      "         [ 7.99911190e-03, -3.12043130e-02, -4.42335531e-02, ...,\n",
      "           2.32172608e-02, -2.05352202e-01, -2.43992582e-02],\n",
      "         [-5.61954174e-03,  4.59682988e-03, -1.20677967e-02, ...,\n",
      "           1.71854999e-02,  2.63561681e-02, -3.75953652e-02],\n",
      "         [-2.00991966e-02, -4.63957302e-02,  1.68743525e-02, ...,\n",
      "          -1.72004439e-02, -2.56789438e-02,  2.74667460e-02]],\n",
      "\n",
      "        [[ 1.27724716e-02,  5.25705852e-02,  2.79409774e-02, ...,\n",
      "          -1.44910272e-02,  5.81986271e-02,  3.62925865e-02],\n",
      "         [-3.48616717e-03,  1.08208582e-02,  3.18553345e-03, ...,\n",
      "          -8.44295428e-04, -6.80980273e-03,  5.14702592e-03],\n",
      "         [-5.62776141e-02, -7.09512783e-03,  9.05002933e-03, ...,\n",
      "           1.78077184e-02, -7.05846027e-03, -1.68668889e-02],\n",
      "         ...,\n",
      "         [-1.67068150e-02, -1.12629402e-02,  2.04251539e-02, ...,\n",
      "          -5.32205869e-03, -6.04888685e-02, -4.09511663e-02],\n",
      "         [ 1.55597162e-02,  1.40785826e-02,  2.81147193e-02, ...,\n",
      "           8.22347682e-03,  2.25124806e-02,  1.41521264e-03],\n",
      "         [-4.31350395e-02,  1.57673925e-03, -4.37156186e-02, ...,\n",
      "          -2.70065404e-02,  2.59999968e-02,  1.27472095e-02]]],\n",
      "\n",
      "\n",
      "       [[[-1.29814027e-02,  1.14586707e-02,  4.84302528e-02, ...,\n",
      "          -4.02351879e-02,  2.68164463e-03, -2.11201026e-04],\n",
      "         [ 4.55261469e-02,  8.36705044e-03,  1.99368764e-02, ...,\n",
      "          -4.27100919e-02, -1.37626501e-02, -5.29617956e-03],\n",
      "         [ 3.38769667e-02, -1.88661758e-02,  1.49708139e-02, ...,\n",
      "          -6.60549402e-02,  1.98514108e-02, -6.69712108e-03],\n",
      "         ...,\n",
      "         [ 5.71870664e-03, -2.90873311e-02,  1.87146699e-03, ...,\n",
      "           2.73403786e-02,  2.95360480e-03, -4.93394397e-03],\n",
      "         [-4.73166294e-02, -5.29165231e-02, -4.70363796e-02, ...,\n",
      "          -1.12444274e-02,  5.39116329e-03, -2.72005778e-02],\n",
      "         [ 5.63464575e-02,  9.97709483e-03,  1.08127398e-02, ...,\n",
      "           8.84860232e-02, -4.38625067e-02,  2.76721967e-03]],\n",
      "\n",
      "        [[-2.10096687e-02,  3.29514705e-02,  9.86238718e-02, ...,\n",
      "           7.78790610e-03,  4.54811603e-02, -4.93500866e-02],\n",
      "         [ 1.07617853e-02,  1.74524486e-02,  3.44367027e-02, ...,\n",
      "          -2.43526977e-02, -2.80388333e-02, -1.00921374e-03],\n",
      "         [-1.84103504e-01, -1.11651476e-02,  1.40131917e-02, ...,\n",
      "           9.35804844e-02, -5.11323586e-02,  5.37196249e-02],\n",
      "         ...,\n",
      "         [ 3.67762558e-02,  1.56357642e-02, -6.22734204e-02, ...,\n",
      "           1.16383042e-02, -7.22537264e-02, -2.68426514e-03],\n",
      "         [-1.65005550e-02, -1.21101066e-01, -3.48812453e-02, ...,\n",
      "           3.70079763e-02, -1.44769950e-02,  3.13699506e-02],\n",
      "         [ 2.14748434e-04,  2.85552498e-02,  6.55340031e-02, ...,\n",
      "          -5.73759479e-03, -8.56497139e-02, -1.36021860e-02]],\n",
      "\n",
      "        [[ 1.28557822e-02,  5.28021529e-02,  6.16125092e-02, ...,\n",
      "           5.36911236e-03,  2.71372143e-02,  3.63731645e-02],\n",
      "         [-2.36888137e-02,  1.04871737e-02,  1.61948334e-02, ...,\n",
      "           3.78741813e-03, -6.54725963e-03, -6.03908487e-03],\n",
      "         [ 5.80676310e-02, -7.30534131e-03,  1.92084350e-02, ...,\n",
      "          -2.13520825e-02, -3.24183926e-02,  5.49841672e-03],\n",
      "         ...,\n",
      "         [-3.51271816e-02, -6.32722350e-03, -1.93908475e-02, ...,\n",
      "           1.77708883e-02,  8.55015405e-03, -5.48258647e-02],\n",
      "         [ 7.55889341e-04, -3.22247259e-02,  1.58115868e-02, ...,\n",
      "           3.46609876e-02,  3.07674706e-02, -1.98628288e-02],\n",
      "         [-4.31424789e-02,  4.96110320e-03, -5.67394169e-03, ...,\n",
      "          -4.93610166e-02,  5.29694669e-02, -5.59288170e-03]]],\n",
      "\n",
      "\n",
      "       [[[-3.23819113e-03,  8.00961070e-03,  1.62007064e-02, ...,\n",
      "          -4.35863473e-02, -6.00689687e-02,  4.64704074e-02],\n",
      "         [ 3.05964611e-02,  1.42679224e-02,  3.15576680e-02, ...,\n",
      "          -2.95448843e-02, -7.56792026e-03, -4.82318364e-03],\n",
      "         [-6.93828017e-02, -7.02171121e-03,  1.92414655e-03, ...,\n",
      "           1.81602854e-02,  2.00566016e-02, -1.03743691e-02],\n",
      "         ...,\n",
      "         [ 1.90818333e-03,  1.47415055e-02,  3.27355764e-03, ...,\n",
      "           1.68770943e-02,  5.29798716e-02, -3.31168473e-02],\n",
      "         [ 1.19694239e-02,  9.76836160e-02, -6.50962591e-02, ...,\n",
      "           5.16569838e-02, -5.68596460e-03, -1.35343929e-03],\n",
      "         [ 4.36738990e-02,  5.69987930e-02, -2.04608422e-02, ...,\n",
      "           5.99620156e-02,  1.83897279e-02,  2.33461745e-02]],\n",
      "\n",
      "        [[-7.70873157e-03,  2.03885417e-02,  2.67390516e-02, ...,\n",
      "          -2.21740678e-02, -7.41384476e-02,  2.92951874e-02],\n",
      "         [-2.68078502e-03,  7.06811808e-03,  2.95130070e-02, ...,\n",
      "          -2.19838191e-02, -5.22506889e-03,  2.09642531e-04],\n",
      "         [-6.62829652e-02,  1.56638976e-02,  3.49140237e-03, ...,\n",
      "          -1.90102719e-02, -2.43512746e-02, -9.22994316e-03],\n",
      "         ...,\n",
      "         [-1.35682635e-02,  4.85135429e-02, -3.44051160e-02, ...,\n",
      "           1.72178168e-02,  3.09070498e-02, -3.63994278e-02],\n",
      "         [-4.49101906e-03,  8.73676986e-02,  4.32944074e-02, ...,\n",
      "           5.15039377e-02, -1.24297421e-02,  1.29950615e-02],\n",
      "         [ 8.61684512e-03,  5.77288270e-02, -4.09775935e-02, ...,\n",
      "          -2.90318988e-02,  6.89933682e-03,  3.70033048e-02]],\n",
      "\n",
      "        [[ 8.08791607e-04,  3.64496820e-02, -6.35832641e-03, ...,\n",
      "          -2.01523304e-02, -3.48473899e-02,  5.93160652e-02],\n",
      "         [-1.89785864e-02,  2.20184699e-02,  2.50970367e-02, ...,\n",
      "          -6.31435262e-03, -6.97454484e-03, -3.90180503e-03],\n",
      "         [ 1.57168210e-02,  1.17304139e-02,  1.89720243e-02, ...,\n",
      "           1.77045427e-02,  1.22417221e-02, -2.56468542e-02],\n",
      "         ...,\n",
      "         [-2.33537350e-02,  4.12771739e-02, -1.63923688e-02, ...,\n",
      "           1.30240079e-02,  2.04299577e-02, -4.92177531e-02],\n",
      "         [ 2.27505271e-03,  2.15592887e-03,  4.70676981e-02, ...,\n",
      "           1.39980940e-02,  1.05897337e-02, -3.87810767e-02],\n",
      "         [-3.56691331e-02,  4.19779904e-02, -8.14246759e-02, ...,\n",
      "          -7.14360848e-02,  5.29160127e-02,  2.29175463e-02]]]],\n",
      "      dtype=float32)]\n",
      "conv_4 [array([[[[-0.02415568,  0.11693741, -0.10076126, ...,  0.08629055,\n",
      "          -0.06828997,  0.15808363],\n",
      "         [-0.00133811,  0.01882177, -0.3791423 , ..., -0.10907529,\n",
      "           0.0920382 , -0.15022995],\n",
      "         [-0.03359664, -0.08269531, -0.2823649 , ...,  0.03222595,\n",
      "           0.01718387,  0.12466422],\n",
      "         ...,\n",
      "         [-0.05625835, -0.02462655,  0.11722703, ...,  0.08888837,\n",
      "          -0.08986495,  0.00519492],\n",
      "         [ 0.04851319, -0.21191134,  0.41400692, ...,  0.18980233,\n",
      "          -0.03840475, -0.25786597],\n",
      "         [ 0.11869529, -0.09514218, -0.13748646, ...,  0.37004653,\n",
      "          -0.19104193, -0.22665292]]]], dtype=float32)]\n",
      "conv_5 [array([[[[ 2.39748042e-02,  1.18284458e-02,  2.33302286e-04, ...,\n",
      "          -2.04714596e-01,  4.98364829e-02,  1.40339765e-03],\n",
      "         [-4.75532450e-02, -4.15128656e-02, -5.19634923e-03, ...,\n",
      "          -5.21056280e-02, -1.47598768e-02,  2.59227003e-03],\n",
      "         [ 9.37869474e-02,  1.62321106e-02,  9.41030011e-02, ...,\n",
      "           5.87187614e-03, -1.10371456e-01,  2.03480069e-02],\n",
      "         ...,\n",
      "         [ 2.17491128e-02,  1.89433782e-03, -4.37508225e-02, ...,\n",
      "          -5.34557998e-02,  2.33411929e-03,  1.31028835e-02],\n",
      "         [ 1.85801275e-02, -2.09617466e-02, -3.14002065e-03, ...,\n",
      "           1.65022369e-02, -1.61048770e-02,  4.70383838e-02],\n",
      "         [-3.77388671e-02,  3.35534588e-02, -3.84351872e-02, ...,\n",
      "           3.11439950e-02,  1.10422932e-02,  2.60722842e-02]],\n",
      "\n",
      "        [[ 7.53803700e-02, -2.01212261e-02,  4.96470742e-02, ...,\n",
      "          -1.86377391e-01,  3.14076385e-03,  6.53497782e-03],\n",
      "         [-8.93159583e-02,  4.83200001e-03, -2.97609926e-03, ...,\n",
      "           2.68868469e-02, -2.09349976e-03,  5.42002544e-03],\n",
      "         [-1.57079883e-02, -2.48500798e-02,  4.50616814e-02, ...,\n",
      "           9.15492419e-03, -5.74075170e-02,  2.13758405e-02],\n",
      "         ...,\n",
      "         [ 6.45620152e-02, -1.78103149e-02, -3.12873274e-02, ...,\n",
      "          -4.49042134e-02,  1.30529273e-02,  2.86362134e-02],\n",
      "         [-4.66837175e-02, -3.85377817e-02, -2.33646668e-02, ...,\n",
      "           3.95028964e-02,  3.16512957e-02,  5.88166155e-02],\n",
      "         [-7.75750875e-02, -1.06485728e-02, -6.03235662e-02, ...,\n",
      "           3.57130952e-02,  3.97922322e-02,  4.23754305e-02]],\n",
      "\n",
      "        [[-2.67010890e-02,  1.26555152e-02,  1.01992711e-02, ...,\n",
      "          -1.22093253e-01, -3.49090621e-02, -3.44652892e-03],\n",
      "         [ 3.38876364e-03,  2.09581871e-02, -1.89257674e-02, ...,\n",
      "           2.46773716e-02,  8.28331802e-03,  9.82011668e-03],\n",
      "         [-1.55393541e-01, -2.17707101e-02,  1.80912893e-02, ...,\n",
      "          -1.79375447e-02, -7.95632228e-02, -2.01626870e-04],\n",
      "         ...,\n",
      "         [ 6.61255196e-02,  3.11254198e-03, -9.61735193e-03, ...,\n",
      "          -1.37035409e-02,  1.65766217e-02,  2.30227243e-02],\n",
      "         [-6.36523739e-02,  8.09077248e-02, -6.67955428e-02, ...,\n",
      "           8.34406062e-04, -2.28023417e-02,  3.82580049e-02],\n",
      "         [-8.95112678e-02, -3.83781791e-02, -1.30013488e-02, ...,\n",
      "           1.46607496e-02,  1.59606356e-02,  1.50595801e-02]]],\n",
      "\n",
      "\n",
      "       [[[-3.92433107e-02,  1.44072901e-03, -8.94143730e-02, ...,\n",
      "           1.03858389e-01, -4.73547541e-02,  6.38421904e-03],\n",
      "         [-6.98718578e-02, -2.32526753e-02,  5.40082576e-03, ...,\n",
      "          -9.53387376e-03, -3.27136542e-04, -4.04608920e-02],\n",
      "         [-8.63843188e-02, -4.45276918e-03, -2.59109004e-03, ...,\n",
      "           3.47579047e-02,  2.23314110e-02, -2.20429767e-02],\n",
      "         ...,\n",
      "         [ 8.87354021e-04,  3.51781957e-03,  2.20625438e-02, ...,\n",
      "           1.12270489e-02,  1.30154425e-02, -1.08675053e-02],\n",
      "         [ 6.86610043e-02, -5.62916584e-02, -6.10344969e-02, ...,\n",
      "           2.31641028e-02, -2.97345668e-02, -1.16151184e-01],\n",
      "         [ 1.99400589e-01,  2.30355114e-02,  1.20954640e-01, ...,\n",
      "           4.23398055e-03,  1.49863213e-01, -2.57153362e-02]],\n",
      "\n",
      "        [[ 2.67610997e-02, -1.42459162e-02, -2.31323056e-02, ...,\n",
      "           1.27118617e-01, -2.66539510e-02,  8.19083489e-03],\n",
      "         [-1.20609879e-01,  2.21573319e-02,  5.27480580e-02, ...,\n",
      "           9.53561440e-03,  6.91493079e-02, -2.17888243e-02],\n",
      "         [-9.08339918e-02,  4.36725914e-02,  6.02726499e-03, ...,\n",
      "           8.50757863e-03,  1.01411730e-01,  4.17065993e-02],\n",
      "         ...,\n",
      "         [ 3.45148845e-03, -1.13544241e-02,  2.80856173e-02, ...,\n",
      "           2.49874480e-02,  8.18572845e-03,  1.32291475e-02],\n",
      "         [ 9.28657502e-02,  4.84497510e-02, -1.10163838e-02, ...,\n",
      "           2.97215134e-02, -6.70024380e-02, -1.71628222e-01],\n",
      "         [ 2.76898861e-01, -3.21551301e-02,  5.70750907e-02, ...,\n",
      "          -8.51491233e-04,  2.59698629e-02, -2.50850990e-02]],\n",
      "\n",
      "        [[-8.32427144e-02,  1.19172474e-02,  8.22477695e-03, ...,\n",
      "           7.87603185e-02, -1.44062126e-02, -1.15574608e-02],\n",
      "         [ 9.29742353e-04, -2.24762913e-02,  1.82058737e-02, ...,\n",
      "          -1.29095558e-03, -4.69132140e-02, -6.99352613e-03],\n",
      "         [-1.19472653e-01,  6.83663040e-03,  9.45816562e-02, ...,\n",
      "          -8.44334438e-03,  9.24091190e-02,  1.19265346e-02],\n",
      "         ...,\n",
      "         [-1.91991858e-04,  4.40011779e-03, -7.81484600e-03, ...,\n",
      "           1.75156537e-02,  5.46881929e-03,  7.74495886e-04],\n",
      "         [ 5.87903634e-02,  1.81494989e-02,  1.18932668e-02, ...,\n",
      "           1.55060515e-02, -1.10542728e-02, -1.10662073e-01],\n",
      "         [-2.54621476e-01, -3.77222560e-02, -7.17941299e-02, ...,\n",
      "          -2.24977192e-02, -1.01314567e-01, -6.49474263e-02]]],\n",
      "\n",
      "\n",
      "       [[[-8.83080289e-02, -3.80091704e-02, -2.42200661e-02, ...,\n",
      "           6.96867928e-02, -6.49381289e-03, -8.74156971e-03],\n",
      "         [-5.73150218e-02,  1.10433241e-02, -4.78802323e-02, ...,\n",
      "          -1.44581292e-02,  2.81322971e-02, -1.99164152e-02],\n",
      "         [-6.82141557e-02,  2.50922833e-02, -1.00727618e-01, ...,\n",
      "          -2.02775151e-02,  2.12237015e-02, -3.34038958e-02],\n",
      "         ...,\n",
      "         [ 2.47790031e-02, -2.20467225e-02,  5.77794313e-02, ...,\n",
      "           3.01629817e-03,  1.51080806e-02, -4.52474691e-03],\n",
      "         [ 9.78066474e-02,  4.42672670e-02,  1.63470075e-01, ...,\n",
      "          -8.02045036e-03,  3.46794687e-02,  4.87229861e-02],\n",
      "         [ 1.05698086e-01, -5.01670502e-03, -8.33427981e-02, ...,\n",
      "          -1.26721794e-02, -8.52128193e-02,  2.75056018e-03]],\n",
      "\n",
      "        [[ 6.14399742e-03,  6.88596582e-03, -1.33132527e-03, ...,\n",
      "           6.01189137e-02, -5.32763153e-02, -5.36439102e-03],\n",
      "         [-6.85055256e-02, -2.58279219e-02, -6.45915046e-02, ...,\n",
      "           9.40395147e-03, -6.83854818e-02,  3.38333426e-03],\n",
      "         [ 1.26847267e-01, -1.75981149e-02, -1.71461269e-01, ...,\n",
      "          -1.70189887e-02,  1.13747865e-01, -7.53904320e-03],\n",
      "         ...,\n",
      "         [-1.19941644e-02, -6.08781585e-04,  1.91979613e-02, ...,\n",
      "          -1.78988592e-03,  3.94563340e-02, -6.34326134e-03],\n",
      "         [-2.27269866e-02,  1.30974557e-02,  1.71085279e-02, ...,\n",
      "           3.02363979e-03,  1.19897975e-02,  5.40645607e-02],\n",
      "         [ 1.44621879e-01, -1.53457755e-02,  1.08933868e-02, ...,\n",
      "          -8.32739472e-03, -9.55508575e-02,  3.25492099e-02]],\n",
      "\n",
      "        [[-1.62625778e-02, -7.96076935e-03, -1.98975969e-02, ...,\n",
      "           3.69818956e-02,  2.59296894e-02,  1.79149199e-03],\n",
      "         [-4.58254293e-02,  2.44674142e-02, -3.57215293e-02, ...,\n",
      "           7.07854657e-03, -4.63445410e-02, -3.09818443e-02],\n",
      "         [ 1.13422886e-01, -3.65430117e-02, -7.67291337e-02, ...,\n",
      "          -2.94199307e-02, -2.31760181e-02, -2.08332837e-02],\n",
      "         ...,\n",
      "         [-4.40576039e-02, -3.95209342e-03, -1.49866110e-02, ...,\n",
      "           1.63706876e-02,  3.19706984e-02, -2.44894018e-03],\n",
      "         [-1.78629979e-02, -8.51211022e-04, -4.93719578e-02, ...,\n",
      "          -1.70766935e-02, -6.22620760e-03,  2.83690803e-02],\n",
      "         [-1.60476327e-01,  1.04291355e-02,  1.45429954e-01, ...,\n",
      "          -1.25848884e-02,  3.24482694e-02, -2.32575294e-02]]]],\n",
      "      dtype=float32)]\n",
      "conv_6 [array([[[[-1.52332494e-02,  9.75654181e-03, -8.51572305e-03, ...,\n",
      "          -8.49341415e-03,  1.31648723e-02,  6.41342904e-03],\n",
      "         [-4.49627750e-02,  1.74672913e-03, -2.59627718e-02, ...,\n",
      "           5.03694313e-03,  3.83755052e-03,  9.26439068e-04],\n",
      "         [-1.72154233e-02,  1.45993242e-02, -1.03882633e-01, ...,\n",
      "          -5.15825581e-03, -3.99751216e-02,  8.61077383e-03],\n",
      "         ...,\n",
      "         [-9.35241953e-03, -3.53428884e-03,  5.48161846e-03, ...,\n",
      "           8.08692072e-03, -1.26834158e-04, -1.18756993e-02],\n",
      "         [ 4.17808257e-02, -1.69892181e-02,  1.04778605e-02, ...,\n",
      "           9.91800986e-03,  2.55897790e-02,  3.56848096e-03],\n",
      "         [-1.28491921e-03, -3.12765944e-03,  5.06226299e-03, ...,\n",
      "           2.25468795e-03, -1.64686963e-02, -4.55759838e-03]],\n",
      "\n",
      "        [[ 1.28811726e-03, -8.80765170e-03,  3.28610837e-02, ...,\n",
      "          -6.88205520e-03, -1.88748948e-02,  1.30052693e-04],\n",
      "         [-4.65715826e-02, -4.78586089e-03, -1.39815323e-02, ...,\n",
      "           3.34559684e-03, -3.53989867e-03,  6.86862180e-03],\n",
      "         [ 3.39766443e-02, -4.15949966e-04, -3.48068327e-02, ...,\n",
      "           9.41575447e-04, -4.51179966e-02,  1.12893870e-02],\n",
      "         ...,\n",
      "         [ 5.34351217e-03, -3.13894195e-03,  8.89863353e-03, ...,\n",
      "           8.69042892e-03,  5.18000871e-03, -2.42995918e-02],\n",
      "         [ 6.90970868e-02, -1.59113817e-02,  1.28980353e-02, ...,\n",
      "           1.13076456e-02,  4.60480303e-02, -2.51567876e-03],\n",
      "         [ 7.40617514e-03, -1.85248945e-02,  2.80753560e-02, ...,\n",
      "           1.03392722e-02,  3.09685012e-03, -1.24277826e-02]],\n",
      "\n",
      "        [[-2.84654517e-02,  1.04515599e-02,  2.17963867e-02, ...,\n",
      "           1.09599326e-02, -1.18076266e-03, -1.42060232e-03],\n",
      "         [-3.00154518e-02, -1.39723038e-02, -2.72312872e-02, ...,\n",
      "           6.68555615e-04,  1.16834231e-02,  4.64091194e-04],\n",
      "         [ 5.37373908e-02, -4.25318535e-03, -9.29650292e-03, ...,\n",
      "           1.03809303e-02, -1.79265591e-03,  1.83516629e-02],\n",
      "         ...,\n",
      "         [ 3.52397282e-03, -3.33305495e-03, -4.05258266e-03, ...,\n",
      "           6.89963484e-03, -1.39326544e-03, -2.05985140e-02],\n",
      "         [ 3.61818038e-02, -7.90115818e-03, -1.05049768e-02, ...,\n",
      "           6.95131905e-03,  1.55782532e-02, -3.24291969e-03],\n",
      "         [ 9.74821113e-03, -2.67674378e-03, -3.59766977e-03, ...,\n",
      "           3.25897126e-03, -1.09241833e-03, -1.25586260e-02]]],\n",
      "\n",
      "\n",
      "       [[[-1.95765006e-03,  1.21327955e-02,  1.26952082e-02, ...,\n",
      "          -3.02756252e-03, -7.16850068e-03,  6.97577046e-03],\n",
      "         [-3.99463810e-02,  1.57925561e-02,  1.97972031e-03, ...,\n",
      "           2.28727539e-03,  5.41311176e-03, -2.08827667e-03],\n",
      "         [-1.17239663e-02,  4.03023977e-03, -3.46570723e-02, ...,\n",
      "           4.62319050e-03, -1.25765037e-02, -5.50308265e-04],\n",
      "         ...,\n",
      "         [-2.58742692e-03, -3.16710584e-03, -2.47026589e-02, ...,\n",
      "           1.72338577e-03,  8.36536195e-03, -3.21874544e-02],\n",
      "         [ 2.08151769e-02, -8.29148106e-03, -3.91351618e-02, ...,\n",
      "           1.06886374e-02,  1.86262187e-02,  4.63302759e-03],\n",
      "         [ 1.78869404e-02, -1.94130447e-02, -1.33280759e-03, ...,\n",
      "           1.29143214e-02,  1.32023096e-02, -8.65086098e-04]],\n",
      "\n",
      "        [[ 6.10212386e-02,  5.53932274e-03,  2.17215091e-01, ...,\n",
      "          -4.08911059e-04, -6.18737144e-03,  4.43163153e-04],\n",
      "         [-6.96622208e-02, -1.83058884e-02,  4.95994743e-03, ...,\n",
      "          -1.75653547e-02,  1.01689072e-02, -1.63339230e-03],\n",
      "         [-3.66663896e-02,  1.22397793e-02, -1.74927767e-02, ...,\n",
      "          -4.72600339e-03, -8.54741558e-02,  1.30688015e-03],\n",
      "         ...,\n",
      "         [ 1.56202437e-02, -1.20579889e-02, -1.05783790e-02, ...,\n",
      "          -6.05282803e-05,  8.48110067e-04, -4.72669043e-02],\n",
      "         [-1.19168416e-03, -4.35862243e-02, -2.94100679e-02, ...,\n",
      "           1.53958909e-02,  2.23616492e-02,  8.82235821e-03],\n",
      "         [ 3.37506086e-02, -8.17485675e-02,  1.84572265e-02, ...,\n",
      "           4.74543683e-03,  6.44940091e-03, -7.11109722e-03]],\n",
      "\n",
      "        [[ 4.26529814e-03,  4.23423806e-03,  7.34151527e-02, ...,\n",
      "          -3.09893017e-04, -8.12094077e-04,  6.77664997e-03],\n",
      "         [-4.11185957e-02, -2.24367678e-02,  7.31516927e-02, ...,\n",
      "          -6.68042852e-03,  6.38884492e-03, -1.62221107e-03],\n",
      "         [-1.41583923e-02, -2.66165957e-02, -1.57719608e-02, ...,\n",
      "           1.29653083e-03, -4.11820300e-02,  5.85754775e-03],\n",
      "         ...,\n",
      "         [-3.80142918e-03, -3.38241388e-03,  2.25167293e-02, ...,\n",
      "           3.98150273e-03,  9.19810124e-03, -3.76592577e-02],\n",
      "         [ 2.99749654e-02, -3.87248630e-03, -2.82016415e-02, ...,\n",
      "           1.60050057e-02, -1.44276684e-02,  2.26764265e-03],\n",
      "         [ 2.58283354e-02, -3.08121685e-02,  1.99480578e-02, ...,\n",
      "           5.83150052e-03,  3.47510055e-02,  1.07177370e-03]]],\n",
      "\n",
      "\n",
      "       [[[-1.85471475e-02,  1.08479466e-02, -5.22123137e-03, ...,\n",
      "          -1.38409808e-02,  1.62179936e-02,  1.91977399e-03],\n",
      "         [-4.15513702e-02, -2.35341419e-03,  1.18641471e-02, ...,\n",
      "          -1.12880720e-03,  6.86278800e-04, -1.33400364e-02],\n",
      "         [ 8.95151403e-03,  4.47318563e-03,  4.16364409e-02, ...,\n",
      "           6.31380593e-03,  1.12402616e-02,  8.05694424e-03],\n",
      "         ...,\n",
      "         [ 1.19742006e-02, -3.15145007e-04, -1.60393789e-02, ...,\n",
      "           9.47736017e-03, -6.52430672e-03, -2.73692794e-02],\n",
      "         [ 1.06056929e-02, -3.36112478e-03,  5.40179154e-03, ...,\n",
      "           1.53998323e-02, -1.08219059e-02, -8.40503722e-04],\n",
      "         [-1.14912558e-02, -1.28902290e-02, -4.80896560e-03, ...,\n",
      "           5.21999737e-03,  1.29859401e-02, -1.79810962e-03]],\n",
      "\n",
      "        [[ 8.08087084e-03, -4.89965687e-03,  6.51554316e-02, ...,\n",
      "          -9.20176972e-03,  3.67547036e-03,  1.36806387e-02],\n",
      "         [-3.59594449e-02,  2.62565818e-03, -2.87362281e-02, ...,\n",
      "          -2.20789085e-03, -1.64067652e-02, -9.50124394e-03],\n",
      "         [ 6.36529597e-03,  1.81691218e-02,  1.40596004e-02, ...,\n",
      "           1.28692640e-02, -2.40555964e-02,  6.28781784e-03],\n",
      "         ...,\n",
      "         [-8.79222061e-03, -2.14244910e-02,  1.23410886e-02, ...,\n",
      "           3.60029889e-03,  2.16585137e-02, -3.76348346e-02],\n",
      "         [ 2.56999936e-02,  1.95706240e-03, -3.82156111e-02, ...,\n",
      "           2.03567580e-03,  2.50962880e-02,  1.17411080e-03],\n",
      "         [ 2.24826075e-02, -2.94200014e-02,  6.12977445e-02, ...,\n",
      "           1.04160560e-02,  3.54335713e-03, -5.59523143e-03]],\n",
      "\n",
      "        [[-6.33439515e-03,  1.24370484e-02,  1.82173327e-02, ...,\n",
      "          -1.37231676e-02,  2.92201173e-02, -2.56623584e-03],\n",
      "         [-3.94611359e-02,  1.66968245e-03,  1.46276643e-02, ...,\n",
      "          -1.25276670e-03, -1.47461668e-02, -8.44680052e-03],\n",
      "         [ 1.21746259e-02,  4.72727418e-03, -4.01064008e-02, ...,\n",
      "           9.74979624e-03, -1.15302363e-02, -2.29907827e-03],\n",
      "         ...,\n",
      "         [-6.50721975e-03, -7.77029898e-03,  9.88559425e-03, ...,\n",
      "           4.36316477e-03,  6.33189781e-03, -3.19277756e-02],\n",
      "         [ 1.37135824e-02, -8.84843338e-03, -3.09581421e-02, ...,\n",
      "          -7.89882895e-03,  8.18630680e-03,  9.28430725e-03],\n",
      "         [-1.03906495e-02, -1.70916039e-02,  3.78931686e-02, ...,\n",
      "           5.09797782e-03,  1.42350327e-02,  2.03844090e-03]]]],\n",
      "      dtype=float32)]\n",
      "conv_7 [array([[[[-0.11800609, -0.06180272,  0.09531447, ..., -0.06041104,\n",
      "          -0.20998913, -0.11437263],\n",
      "         [ 0.12802649,  0.06129074, -0.19148555, ...,  0.01755231,\n",
      "          -0.23192102,  0.07097082],\n",
      "         [ 0.21287528,  0.06892725, -0.02180706, ...,  0.03722533,\n",
      "           0.05055586,  0.0956927 ],\n",
      "         ...,\n",
      "         [ 0.04137745, -0.12758178, -0.3733853 , ..., -0.01420925,\n",
      "           0.16997884,  0.02405235],\n",
      "         [-0.05708291, -0.06816874,  0.20941152, ...,  0.01144307,\n",
      "          -0.08141409, -0.04180998],\n",
      "         [-0.08387841, -0.01380313, -0.03938982, ..., -0.04844283,\n",
      "          -0.13191311, -0.24131289]]]], dtype=float32)]\n",
      "conv_8 [array([[[[-0.00858286, -0.02971694, -0.00290415, ..., -0.00355356,\n",
      "          -0.01521339, -0.00035237],\n",
      "         [ 0.00202893, -0.00613171,  0.00306613, ...,  0.01228228,\n",
      "           0.0003048 ,  0.03476648],\n",
      "         [ 0.00736792, -0.00011174, -0.01814922, ...,  0.00085021,\n",
      "          -0.00295891, -0.01614909],\n",
      "         ...,\n",
      "         [ 0.01945902, -0.02086893, -0.01999105, ..., -0.01699878,\n",
      "          -0.00603373,  0.02391584],\n",
      "         [ 0.0164361 ,  0.02777951,  0.00259559, ..., -0.0246609 ,\n",
      "          -0.00325694,  0.01787344],\n",
      "         [ 0.01453412, -0.02267127, -0.01032784, ...,  0.0275145 ,\n",
      "           0.01443679,  0.0088458 ]],\n",
      "\n",
      "        [[-0.0075066 , -0.0371886 , -0.01385566, ..., -0.02961019,\n",
      "           0.03781151,  0.00012567],\n",
      "         [-0.04768711, -0.01131608,  0.01583959, ...,  0.00734516,\n",
      "          -0.00315285,  0.02093415],\n",
      "         [-0.01552158,  0.00897625, -0.01495226, ...,  0.02884482,\n",
      "          -0.03014452, -0.04099866],\n",
      "         ...,\n",
      "         [ 0.03555429,  0.00512485, -0.00194914, ...,  0.02595375,\n",
      "           0.05613749,  0.02579713],\n",
      "         [ 0.01889464,  0.02354194,  0.00958483, ..., -0.02598743,\n",
      "          -0.01340589,  0.00156932],\n",
      "         [ 0.01714182, -0.0236889 , -0.00119426, ...,  0.0040777 ,\n",
      "           0.0130989 ,  0.00766363]],\n",
      "\n",
      "        [[-0.0011337 , -0.02721677, -0.01754102, ..., -0.00394745,\n",
      "           0.00948348, -0.02504386],\n",
      "         [-0.01660815, -0.01640755,  0.01119608, ...,  0.00065454,\n",
      "          -0.00981907,  0.00132845],\n",
      "         [ 0.01923636, -0.00110239, -0.0078008 , ..., -0.01185868,\n",
      "          -0.00978531,  0.01021975],\n",
      "         ...,\n",
      "         [ 0.01589707, -0.00421496, -0.01141716, ..., -0.01926018,\n",
      "           0.04091194, -0.03013213],\n",
      "         [ 0.00190763,  0.00853411, -0.00161325, ..., -0.02309175,\n",
      "          -0.00876966,  0.0045174 ],\n",
      "         [ 0.04389202, -0.01703472,  0.00236288, ...,  0.00506099,\n",
      "           0.02279014, -0.00272428]]],\n",
      "\n",
      "\n",
      "       [[[ 0.01028525, -0.02499826,  0.00865968, ..., -0.0289802 ,\n",
      "          -0.01966143, -0.02413468],\n",
      "         [ 0.04256686, -0.0106698 , -0.02238113, ...,  0.01805846,\n",
      "          -0.02064571,  0.01587988],\n",
      "         [ 0.02024991,  0.01135011, -0.01050688, ..., -0.00880828,\n",
      "           0.00418993,  0.03332638],\n",
      "         ...,\n",
      "         [-0.07044495, -0.01754364, -0.02215604, ..., -0.01240689,\n",
      "          -0.10599685,  0.00231011],\n",
      "         [ 0.01525226,  0.05419227,  0.00348223, ...,  0.0214001 ,\n",
      "          -0.00583294, -0.00782625],\n",
      "         [-0.00704939, -0.01890074, -0.01902279, ...,  0.02190823,\n",
      "           0.00355079,  0.01023641]],\n",
      "\n",
      "        [[ 0.06781395, -0.02342331, -0.00072434, ..., -0.03141559,\n",
      "           0.0817728 , -0.00878153],\n",
      "         [-0.07474975, -0.0290722 , -0.03768962, ..., -0.00245846,\n",
      "          -0.08736142,  0.01349698],\n",
      "         [ 0.01027968,  0.0256088 , -0.02161344, ...,  0.05252817,\n",
      "          -0.003766  , -0.03977257],\n",
      "         ...,\n",
      "         [ 0.04272661, -0.00610697, -0.00442545, ...,  0.03370912,\n",
      "           0.0618969 ,  0.02298499],\n",
      "         [ 0.03438523,  0.03936111,  0.00578441, ...,  0.0181885 ,\n",
      "          -0.04798942, -0.03048009],\n",
      "         [-0.00985823, -0.03167205, -0.0163945 , ..., -0.00913464,\n",
      "          -0.05521966,  0.0044062 ]],\n",
      "\n",
      "        [[ 0.01769085, -0.03408278, -0.00841589, ..., -0.02690808,\n",
      "           0.00179017,  0.00018213],\n",
      "         [ 0.03374957, -0.00403827,  0.00503177, ...,  0.00346887,\n",
      "          -0.00406482,  0.00201579],\n",
      "         [ 0.02293203,  0.00913395, -0.00451069, ...,  0.03470194,\n",
      "           0.0121671 ,  0.02534802],\n",
      "         ...,\n",
      "         [-0.04321128, -0.01905651, -0.02581958, ...,  0.00283338,\n",
      "           0.00978932, -0.05370189],\n",
      "         [-0.00903758,  0.03429114, -0.00201271, ..., -0.02412416,\n",
      "          -0.01309507, -0.01550985],\n",
      "         [ 0.03213478, -0.01109973,  0.01675731, ..., -0.01764052,\n",
      "           0.00449919, -0.00174418]]],\n",
      "\n",
      "\n",
      "       [[[ 0.0085378 , -0.02699834,  0.01096613, ..., -0.00180088,\n",
      "           0.00346337, -0.02958025],\n",
      "         [-0.03238331, -0.01843012,  0.00626575, ...,  0.03811894,\n",
      "          -0.02093682, -0.00722447],\n",
      "         [ 0.01297915,  0.0162837 , -0.01341598, ..., -0.05016403,\n",
      "           0.00410458,  0.02326324],\n",
      "         ...,\n",
      "         [-0.01259663, -0.01520975, -0.0007795 , ..., -0.04876121,\n",
      "          -0.05468236, -0.01879304],\n",
      "         [-0.01079763,  0.05971308,  0.00784737, ..., -0.01680288,\n",
      "           0.00317694, -0.01294862],\n",
      "         [ 0.01478486, -0.00673888, -0.00110766, ...,  0.02070797,\n",
      "           0.008876  ,  0.03438055]],\n",
      "\n",
      "        [[-0.02286823, -0.03133046,  0.00150509, ..., -0.03591323,\n",
      "           0.01651159, -0.03093969],\n",
      "         [-0.02711838, -0.01210354,  0.01550926, ...,  0.00808388,\n",
      "          -0.04761204, -0.01570245],\n",
      "         [-0.00719007,  0.01919334,  0.00038896, ...,  0.00090894,\n",
      "          -0.01847297,  0.02384023],\n",
      "         ...,\n",
      "         [ 0.00979822, -0.00564162,  0.00584612, ...,  0.05794657,\n",
      "           0.04150591,  0.01566685],\n",
      "         [-0.0054711 ,  0.03462357,  0.02660591, ...,  0.00330039,\n",
      "          -0.02889535, -0.04193718],\n",
      "         [ 0.01307422, -0.01794222, -0.02204184, ...,  0.02782809,\n",
      "          -0.00897364,  0.0266194 ]],\n",
      "\n",
      "        [[-0.01754873, -0.00174492, -0.00933463, ...,  0.0033398 ,\n",
      "           0.00348664, -0.02517889],\n",
      "         [-0.02580293,  0.01059178, -0.00612977, ...,  0.02986539,\n",
      "          -0.00419293,  0.00526414],\n",
      "         [ 0.01211616, -0.00352252, -0.00772564, ...,  0.02336721,\n",
      "           0.01962093,  0.02818851],\n",
      "         ...,\n",
      "         [-0.00484681, -0.0129916 ,  0.00523237, ...,  0.05550091,\n",
      "           0.00503179, -0.0302256 ],\n",
      "         [-0.01451508,  0.02280128,  0.00876827, ..., -0.01128693,\n",
      "           0.01377686, -0.00377965],\n",
      "         [ 0.01283942, -0.0088586 , -0.00149085, ..., -0.01162547,\n",
      "          -0.03536097,  0.01996155]]]], dtype=float32)]\n",
      "conv_9 [array([[[[-2.80397590e-02,  1.77783472e-03,  7.90394749e-03, ...,\n",
      "          -1.61809300e-03,  8.32320540e-04,  2.39328816e-04],\n",
      "         [-1.41580338e-02,  9.01385117e-03,  3.72870057e-03, ...,\n",
      "           2.25186907e-02, -8.33460316e-03,  1.29468823e-02],\n",
      "         [ 1.58117767e-02, -5.85706497e-04, -5.78168221e-03, ...,\n",
      "           1.86250117e-02, -2.12654900e-02, -6.88713510e-03],\n",
      "         ...,\n",
      "         [ 3.41657596e-03,  4.81510675e-03,  1.16301153e-03, ...,\n",
      "          -3.01304995e-03, -8.10266647e-04, -9.23815387e-05],\n",
      "         [-1.45639759e-03, -6.01603324e-03, -2.83993129e-03, ...,\n",
      "          -2.61715818e-02, -1.52862845e-02, -8.62916838e-03],\n",
      "         [-8.34645797e-03, -1.19997179e-02,  3.53510783e-04, ...,\n",
      "          -7.32011022e-03,  3.67375975e-03,  6.42416906e-03]],\n",
      "\n",
      "        [[-1.66377611e-02,  1.06597459e-03,  1.96254137e-03, ...,\n",
      "           1.66926347e-02,  1.51984207e-02,  6.09630661e-04],\n",
      "         [-5.65006910e-03, -1.81030051e-03,  6.18126011e-03, ...,\n",
      "           1.40695297e-03,  1.18455529e-04,  5.27271349e-03],\n",
      "         [ 3.07471640e-02, -1.31814450e-04, -5.39734354e-03, ...,\n",
      "          -1.67285651e-02, -3.80378962e-02,  4.73242924e-02],\n",
      "         ...,\n",
      "         [-2.21296749e-03, -2.14530472e-02,  9.42178420e-04, ...,\n",
      "           4.54727153e-04, -7.55565194e-03, -2.22923625e-02],\n",
      "         [-6.79371879e-03,  9.47092427e-04, -9.09978896e-03, ...,\n",
      "           1.14380196e-02, -1.14218639e-02,  7.30146887e-03],\n",
      "         [-1.32003729e-03, -1.76086545e-03,  8.51237623e-04, ...,\n",
      "           1.33393668e-02,  9.77057312e-03, -3.53219137e-02]],\n",
      "\n",
      "        [[-1.73053946e-02, -1.77801168e-03,  2.29267846e-03, ...,\n",
      "          -8.14519939e-04, -5.28908521e-03,  3.90252136e-02],\n",
      "         [ 5.95992757e-03,  1.14129502e-02,  1.12598585e-02, ...,\n",
      "          -2.79086903e-02, -7.67394342e-03, -1.35563621e-02],\n",
      "         [ 2.78900936e-02, -6.60034316e-03, -4.84742632e-05, ...,\n",
      "          -5.41829458e-03, -2.88924668e-02,  7.06585422e-02],\n",
      "         ...,\n",
      "         [ 2.84921713e-02,  1.25347741e-03, -1.72135495e-02, ...,\n",
      "           3.02567817e-02,  9.51725617e-03,  7.43579119e-03],\n",
      "         [-1.17403120e-02, -1.63890002e-03, -9.54667199e-03, ...,\n",
      "          -8.65821354e-03, -2.15520933e-02,  2.10567582e-02],\n",
      "         [-1.72015894e-02, -1.72201078e-03, -7.30353128e-03, ...,\n",
      "          -4.23197215e-03,  1.53360823e-02, -4.29325961e-02]]],\n",
      "\n",
      "\n",
      "       [[[-6.21910254e-03, -1.97625905e-03,  1.41134183e-03, ...,\n",
      "          -4.60600946e-03, -1.38074430e-02, -1.08559541e-02],\n",
      "         [-2.64301505e-02,  9.21889208e-03,  1.77214143e-03, ...,\n",
      "           1.24425162e-03, -4.37017530e-03,  1.13004530e-02],\n",
      "         [ 1.46518899e-02, -2.27004336e-03, -1.59267429e-03, ...,\n",
      "           2.08184831e-02,  4.27918974e-03, -2.98852213e-02],\n",
      "         ...,\n",
      "         [-7.61264004e-03, -1.95017690e-03, -2.59762839e-03, ...,\n",
      "           4.48639132e-03,  4.02720273e-03,  6.34375401e-03],\n",
      "         [-1.28442177e-03, -5.24217123e-03,  6.93631684e-03, ...,\n",
      "          -5.67990681e-03, -7.29292491e-03,  3.25429533e-03],\n",
      "         [ 1.40102138e-03, -1.38072483e-02, -2.80698063e-03, ...,\n",
      "           2.54083779e-02,  9.24250577e-03,  2.92115826e-02]],\n",
      "\n",
      "        [[ 6.88847806e-03, -2.19774945e-03, -1.30309898e-03, ...,\n",
      "           1.38290636e-02,  1.93421021e-02,  1.18391868e-02],\n",
      "         [-1.44794928e-02, -7.33975880e-03,  4.82915249e-03, ...,\n",
      "          -5.96059114e-03,  4.37588990e-03,  1.13526639e-02],\n",
      "         [ 2.38947663e-02,  3.37010529e-03,  2.02690018e-03, ...,\n",
      "          -2.92666676e-03, -1.44551657e-02, -4.15914459e-03],\n",
      "         ...,\n",
      "         [-1.19052446e-02, -2.50569847e-03,  1.36531210e-02, ...,\n",
      "           8.88289511e-03, -4.65507060e-03,  1.99430492e-02],\n",
      "         [-1.20963505e-03, -2.33460590e-03, -5.34143473e-04, ...,\n",
      "           3.10699381e-02, -3.79406614e-03,  2.08325647e-02],\n",
      "         [-9.83663555e-03, -1.04505690e-02,  1.21895084e-03, ...,\n",
      "          -6.14869827e-03, -5.74765867e-03,  1.66733805e-02]],\n",
      "\n",
      "        [[-6.68256171e-03, -7.53795356e-03,  1.10671281e-04, ...,\n",
      "           7.26897037e-03, -6.66947570e-03,  3.51428092e-02],\n",
      "         [-5.59060788e-03, -4.90920339e-03,  7.44805904e-03, ...,\n",
      "          -2.12766975e-02, -3.06428829e-03, -2.42387168e-02],\n",
      "         [ 1.72392242e-02, -8.98947287e-03,  2.73803785e-03, ...,\n",
      "           8.54467507e-03, -1.46620534e-02,  9.69501492e-03],\n",
      "         ...,\n",
      "         [-6.40110765e-03, -5.88186085e-03,  5.43692522e-03, ...,\n",
      "          -3.30944592e-03,  1.21697523e-02,  6.64646458e-03],\n",
      "         [-4.30006348e-03, -1.73056815e-02,  1.29492953e-03, ...,\n",
      "           7.03610945e-03, -3.12359980e-03,  1.55438213e-02],\n",
      "         [ 7.34734640e-04, -2.15250556e-03, -6.10910729e-03, ...,\n",
      "           1.83031335e-02, -1.33982301e-02, -1.38521707e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 9.32043418e-03,  1.01409713e-03,  1.09989187e-02, ...,\n",
      "          -8.65576882e-03, -2.91298120e-03,  1.19533017e-02],\n",
      "         [-1.17101101e-02,  8.05960689e-03,  8.69250484e-03, ...,\n",
      "           5.05775388e-04, -8.85495264e-03, -9.53164417e-03],\n",
      "         [ 1.35318646e-02, -4.37975815e-03, -6.31181989e-03, ...,\n",
      "           1.41627043e-02,  1.29971374e-02, -1.96185745e-02],\n",
      "         ...,\n",
      "         [-5.03231259e-03, -3.31275677e-03, -6.94951508e-03, ...,\n",
      "          -1.11982517e-03,  1.74893029e-02, -5.41279875e-02],\n",
      "         [ 2.00375300e-02, -3.71146452e-05,  7.95388408e-03, ...,\n",
      "          -1.56477075e-02,  9.71359666e-03,  5.99853694e-03],\n",
      "         [-1.53032532e-02, -3.49579728e-03,  3.32171144e-03, ...,\n",
      "           8.62690341e-03, -4.06914260e-05,  5.71335852e-03]],\n",
      "\n",
      "        [[ 4.49273066e-04, -1.90629740e-03, -5.26483310e-03, ...,\n",
      "          -8.56959634e-03, -5.15316520e-03,  2.86318511e-02],\n",
      "         [-1.79798121e-03,  1.32647983e-03,  1.19702648e-02, ...,\n",
      "          -3.04201944e-03, -7.03626964e-03, -1.57745015e-02],\n",
      "         [-5.05206920e-03, -9.18918382e-03, -1.27391110e-03, ...,\n",
      "           2.70262212e-02,  2.88854241e-02, -3.73909771e-02],\n",
      "         ...,\n",
      "         [-1.70880165e-02, -3.71145247e-03,  9.01439041e-03, ...,\n",
      "          -2.25231685e-02, -9.04251006e-04, -3.35147642e-02],\n",
      "         [-9.80766118e-03,  7.20980763e-03, -6.21258165e-04, ...,\n",
      "          -3.91466357e-03,  3.67162167e-04, -1.50809167e-02],\n",
      "         [-3.02771050e-02,  5.53356810e-03,  1.31994616e-02, ...,\n",
      "          -1.75053235e-02, -5.02696866e-03, -5.33312559e-03]],\n",
      "\n",
      "        [[-3.64144798e-03, -7.58751435e-03, -5.66701964e-03, ...,\n",
      "           1.23241078e-02,  8.81494675e-03,  1.40289832e-02],\n",
      "         [ 2.14210642e-03, -5.59229916e-03,  1.25940349e-02, ...,\n",
      "          -1.39605934e-02, -1.20957419e-02, -2.15000175e-02],\n",
      "         [ 5.60849498e-04, -1.84559878e-02,  6.28693635e-03, ...,\n",
      "           1.41038410e-02, -2.22457829e-03, -2.05856580e-02],\n",
      "         ...,\n",
      "         [-1.63170099e-02, -3.10230791e-03,  1.15442146e-02, ...,\n",
      "           4.64979792e-03,  9.70179681e-03, -2.86078881e-02],\n",
      "         [-9.70906205e-03, -8.74348637e-03,  2.73519685e-03, ...,\n",
      "          -5.23976702e-03,  9.18412860e-03, -2.79113036e-02],\n",
      "         [-1.16761902e-03,  2.69610970e-03,  1.00480728e-02, ...,\n",
      "          -1.51909301e-02, -1.34719750e-02, -1.30443238e-02]]]],\n",
      "      dtype=float32)]\n",
      "conv_10 [array([[[[-8.18202943e-02, -1.53695270e-01, -2.33815219e-02, ...,\n",
      "          -1.74237013e-01, -6.27734959e-02,  3.35697457e-02],\n",
      "         [-9.60902721e-02,  4.58022170e-02, -3.29638235e-02, ...,\n",
      "          -7.69755840e-02,  1.60333375e-03,  2.12406106e-02],\n",
      "         [-8.29639882e-02,  1.83220550e-01, -1.37555093e-01, ...,\n",
      "          -4.50612754e-02,  2.28895005e-02, -1.38946757e-01],\n",
      "         ...,\n",
      "         [-1.13471799e-01,  8.49355310e-02,  2.06959531e-01, ...,\n",
      "           8.16757604e-03, -6.35328377e-03,  6.95559308e-02],\n",
      "         [ 2.54744083e-01, -3.89564666e-03, -1.71576012e-02, ...,\n",
      "           7.37226903e-02, -1.84605196e-02,  7.94842392e-02],\n",
      "         [ 2.53063291e-02,  3.41428677e-05, -1.13283284e-01, ...,\n",
      "          -4.19614799e-02,  1.01927519e-01,  5.71901910e-03]]]],\n",
      "      dtype=float32)]\n",
      "conv_11 [array([[[[ 2.69067078e-03,  1.51758865e-02,  1.23783667e-03, ...,\n",
      "          -6.45089243e-03, -1.00169964e-02,  7.78537756e-03],\n",
      "         [-3.39059765e-03, -9.46912076e-03, -1.70852542e-02, ...,\n",
      "           3.08111794e-02,  3.18688750e-02, -2.28455532e-02],\n",
      "         [-3.36003886e-03,  1.96326394e-02,  1.32340277e-02, ...,\n",
      "           3.17491381e-03,  7.86094088e-03,  1.00278249e-02],\n",
      "         ...,\n",
      "         [-3.45825357e-03,  1.40067069e-02, -3.97507362e-02, ...,\n",
      "          -1.09562939e-02, -5.46594942e-03,  7.60206021e-03],\n",
      "         [ 3.29621113e-03, -1.76977310e-02,  1.26961935e-02, ...,\n",
      "           1.42395478e-02, -1.50993504e-02,  1.69464815e-02],\n",
      "         [-7.89750088e-03, -5.89518389e-03,  1.16426237e-02, ...,\n",
      "           1.93761364e-02,  2.21145414e-02,  1.24982493e-02]],\n",
      "\n",
      "        [[ 3.12466966e-03,  9.54559166e-03,  4.00159322e-03, ...,\n",
      "           4.68129152e-03, -1.04576033e-02,  4.75400351e-02],\n",
      "         [-9.32428148e-03, -7.61062326e-03, -1.04520181e-02, ...,\n",
      "           1.31311705e-02,  3.06711607e-02, -1.27878832e-02],\n",
      "         [ 6.06512232e-03,  2.28930009e-03, -8.17786250e-03, ...,\n",
      "          -4.46047401e-03,  5.14605362e-03,  1.93704441e-02],\n",
      "         ...,\n",
      "         [ 9.15693585e-03,  4.80218278e-03,  1.42918099e-02, ...,\n",
      "           5.16752712e-04, -1.81336254e-02,  5.90493553e-04],\n",
      "         [ 1.47093330e-02,  3.20285233e-03,  2.37553250e-02, ...,\n",
      "           1.22364890e-03, -4.20336379e-03,  8.98344629e-03],\n",
      "         [ 8.02644528e-04, -6.90713944e-03, -1.15324347e-03, ...,\n",
      "           3.76370065e-02, -5.41313644e-03,  5.11080772e-03]],\n",
      "\n",
      "        [[ 3.95356026e-03,  1.07318563e-02,  1.23779299e-02, ...,\n",
      "           3.60014290e-02, -2.23109988e-03,  1.51026901e-02],\n",
      "         [-2.47102068e-03,  9.61032510e-03,  2.09347419e-02, ...,\n",
      "           1.38300182e-02, -1.63956999e-03, -1.28025338e-02],\n",
      "         [-8.21306556e-03,  2.13029068e-02,  1.54929599e-02, ...,\n",
      "           6.02616789e-03,  5.52861951e-03, -4.45704674e-03],\n",
      "         ...,\n",
      "         [-8.37425515e-03,  2.10401863e-02, -4.49005105e-02, ...,\n",
      "          -2.33078673e-02, -1.25880763e-02, -1.29134748e-02],\n",
      "         [ 6.29409263e-03, -4.90528159e-03,  2.10750513e-02, ...,\n",
      "           9.12136305e-03,  1.69142298e-02,  5.31763444e-03],\n",
      "         [-5.59896289e-04,  1.27833830e-02, -9.24862921e-03, ...,\n",
      "           1.74779668e-02, -3.09166070e-02, -3.18664243e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 8.93536862e-03, -6.99577155e-03,  7.48652825e-03, ...,\n",
      "          -1.96640175e-02,  2.47045839e-03,  4.44969088e-02],\n",
      "         [-1.78543627e-02, -1.28740193e-02, -1.77006703e-02, ...,\n",
      "           2.07745880e-02,  1.47783849e-02, -2.95513049e-02],\n",
      "         [-3.75217618e-03, -1.09188138e-02,  8.74891039e-03, ...,\n",
      "           1.17520932e-02,  5.83702419e-03, -1.10039450e-02],\n",
      "         ...,\n",
      "         [-3.70869390e-03, -6.89961202e-03, -3.05731185e-02, ...,\n",
      "           1.48623940e-02, -1.32113267e-02,  1.71567276e-02],\n",
      "         [ 3.22045595e-03,  2.26368178e-02,  1.72768719e-02, ...,\n",
      "          -5.37178805e-03,  7.39395386e-03,  2.36357804e-02],\n",
      "         [-1.05240084e-02, -1.40862372e-02,  2.66788621e-02, ...,\n",
      "          -7.85031414e-04,  3.39224450e-02,  1.96961146e-02]],\n",
      "\n",
      "        [[ 4.78441417e-02, -1.22043141e-03,  1.52986497e-02, ...,\n",
      "          -1.26739293e-02,  4.88050329e-03,  2.00235948e-01],\n",
      "         [-1.89966857e-02, -7.55737768e-03, -1.02265840e-02, ...,\n",
      "           6.02307077e-03, -5.43020712e-03, -1.30362865e-02],\n",
      "         [ 1.61180031e-02, -1.03063891e-02, -4.50972049e-03, ...,\n",
      "          -8.93490575e-03, -2.50277594e-02,  3.08116917e-02],\n",
      "         ...,\n",
      "         [ 1.58472229e-02, -4.01851197e-04,  3.96529473e-02, ...,\n",
      "          -3.89116583e-03, -4.25684415e-02, -4.59421705e-03],\n",
      "         [ 9.65160038e-03,  2.59228908e-02,  2.39073262e-02, ...,\n",
      "           4.15490614e-03, -1.59212351e-02,  5.09017855e-02],\n",
      "         [ 8.16395134e-03,  1.55458949e-03, -6.17093500e-03, ...,\n",
      "           2.46253889e-02,  1.05266711e-02, -5.72923198e-03]],\n",
      "\n",
      "        [[ 1.77814602e-03,  1.51069723e-02,  1.98202133e-02, ...,\n",
      "           8.29801057e-03,  1.47066973e-02,  4.07929644e-02],\n",
      "         [ 6.16789889e-03,  1.60316881e-02,  1.91261750e-02, ...,\n",
      "           1.12284450e-02, -2.23302543e-02, -4.86962544e-03],\n",
      "         [-6.46706531e-03, -4.73586377e-03,  8.53529759e-03, ...,\n",
      "          -6.12843642e-03, -1.46228645e-04, -3.11238021e-02],\n",
      "         ...,\n",
      "         [-8.37962329e-03,  5.83333336e-03, -3.08181290e-02, ...,\n",
      "          -1.44106923e-02, -6.33170735e-03, -5.51438658e-03],\n",
      "         [ 1.19668664e-03,  8.37098435e-03,  2.51633413e-02, ...,\n",
      "          -2.93861888e-03,  1.30816782e-02,  2.53855996e-02],\n",
      "         [ 1.74441189e-02,  1.54682649e-02,  7.29787338e-04, ...,\n",
      "           1.74349193e-02, -8.26769788e-03, -1.34063568e-02]]],\n",
      "\n",
      "\n",
      "       [[[-8.49204231e-03,  1.65531784e-02,  5.92521112e-03, ...,\n",
      "          -2.04069316e-02,  4.51507932e-03,  7.94138853e-03],\n",
      "         [ 2.25490425e-03, -2.44487892e-03,  3.80901457e-03, ...,\n",
      "           2.41805166e-02, -1.22284684e-02, -2.05634404e-02],\n",
      "         [-9.31038428e-03,  2.53901072e-03,  1.07467435e-02, ...,\n",
      "           1.53453723e-02, -9.42344777e-03, -1.20342420e-02],\n",
      "         ...,\n",
      "         [-7.43426895e-03,  2.35298313e-02, -3.54799032e-02, ...,\n",
      "           1.40608214e-02,  2.79616239e-03,  2.10309848e-02],\n",
      "         [-2.27799127e-03,  2.70014675e-03,  1.80489607e-02, ...,\n",
      "           3.36034433e-03,  2.49736593e-03,  1.33063775e-02],\n",
      "         [-1.25642195e-02, -1.78022031e-02,  1.42380791e-02, ...,\n",
      "           1.44986308e-03,  3.13709676e-02,  3.09462659e-03]],\n",
      "\n",
      "        [[ 6.51333528e-03,  5.04269358e-03,  2.06586644e-02, ...,\n",
      "          -1.19360955e-02,  4.04813047e-03,  3.31632756e-02],\n",
      "         [ 1.03254300e-02, -3.21590970e-03,  7.68052414e-03, ...,\n",
      "          -1.45407775e-02, -2.52601057e-02,  5.96379256e-03],\n",
      "         [-5.96979400e-03, -9.66929086e-03, -3.06191458e-03, ...,\n",
      "          -4.79393359e-03, -6.81912573e-03, -3.07885204e-02],\n",
      "         ...,\n",
      "         [ 4.81289206e-03,  1.90636925e-02,  2.73308009e-02, ...,\n",
      "           7.07040820e-03, -6.32083509e-03,  1.42692300e-02],\n",
      "         [-4.68519470e-03,  1.87474340e-02,  3.34946923e-02, ...,\n",
      "           5.98262483e-03, -2.12666579e-02,  4.43012752e-02],\n",
      "         [-6.34772284e-03, -2.51371553e-03,  3.11473641e-03, ...,\n",
      "           1.01580576e-03,  3.68232280e-02, -2.09770352e-02]],\n",
      "\n",
      "        [[-1.97809027e-03,  8.79020337e-03,  1.86603311e-02, ...,\n",
      "          -6.20269263e-03,  1.40065234e-02,  3.90419620e-03],\n",
      "         [ 9.04855132e-03,  9.25610680e-03,  7.71077536e-03, ...,\n",
      "          -7.96388462e-03, -2.71932781e-02,  1.24507667e-02],\n",
      "         [-1.16699198e-02, -5.42678405e-03,  1.89876347e-03, ...,\n",
      "          -2.41672043e-02, -7.92745326e-04, -2.34527979e-02],\n",
      "         ...,\n",
      "         [-1.52216833e-02,  2.65958868e-02, -2.50422508e-02, ...,\n",
      "          -9.30315908e-03,  5.14107337e-03,  9.14964732e-03],\n",
      "         [ 5.42189809e-04, -2.12057941e-02,  1.10072177e-02, ...,\n",
      "          -8.69887322e-03,  1.12226888e-04,  2.57228371e-02],\n",
      "         [ 2.68656574e-03,  9.04649869e-03,  4.51403437e-03, ...,\n",
      "           2.12567765e-02,  3.30092874e-03, -1.03273792e-02]]]],\n",
      "      dtype=float32)]\n",
      "conv_12 [array([[[[ 0.00949955, -0.23996429,  0.02582577, ..., -0.02326609,\n",
      "          -0.13041878, -0.08824904],\n",
      "         [-0.13167913, -0.05818203, -0.02279084, ..., -0.00171288,\n",
      "          -0.07421007,  0.05833216],\n",
      "         [-0.02992593, -0.01697055,  0.00096144, ..., -0.08989975,\n",
      "           0.10725688,  0.00933981],\n",
      "         ...,\n",
      "         [ 0.00617118,  0.0808064 , -0.02920728, ..., -0.01137618,\n",
      "          -0.02864682, -0.1187812 ],\n",
      "         [-0.14204076, -0.00084747, -0.01824573, ..., -0.03354491,\n",
      "           0.0777481 ,  0.01619646],\n",
      "         [ 0.19603401, -0.01793286, -0.08652591, ..., -0.0205334 ,\n",
      "           0.14542697, -0.02023548]]]], dtype=float32)]\n",
      "conv_13 [array([[[[-0.00159304, -0.0064578 , -0.01231109, ..., -0.00186857,\n",
      "          -0.01605642,  0.01710332],\n",
      "         [-0.00729066, -0.00169792,  0.00874512, ..., -0.0345098 ,\n",
      "          -0.03415347, -0.01752651],\n",
      "         [-0.00828961,  0.02187245, -0.0154186 , ..., -0.00423101,\n",
      "          -0.03295492, -0.00206016],\n",
      "         ...,\n",
      "         [ 0.00328804, -0.01623837,  0.00407743, ...,  0.03106141,\n",
      "          -0.0009135 , -0.01537282],\n",
      "         [ 0.00235703,  0.02637211, -0.0022828 , ...,  0.01410314,\n",
      "          -0.00854996, -0.01709237],\n",
      "         [-0.02110225,  0.02808492, -0.00442518, ..., -0.01345371,\n",
      "          -0.00523004,  0.01529127]],\n",
      "\n",
      "        [[ 0.00087076,  0.00905363,  0.00305032, ..., -0.01847352,\n",
      "          -0.01058467,  0.00112187],\n",
      "         [-0.0156092 ,  0.03567931,  0.00271095, ..., -0.03254913,\n",
      "          -0.02360423, -0.00345314],\n",
      "         [-0.02024355,  0.05329141, -0.02397571, ..., -0.01534146,\n",
      "          -0.02129993,  0.01818563],\n",
      "         ...,\n",
      "         [ 0.01358156, -0.01897552,  0.02827656, ...,  0.00303334,\n",
      "          -0.01293229, -0.00253815],\n",
      "         [ 0.00357445,  0.01066527,  0.00334156, ...,  0.01667123,\n",
      "          -0.01436181, -0.02579226],\n",
      "         [-0.01283205,  0.01813626,  0.01358267, ...,  0.00831573,\n",
      "          -0.05325786,  0.03489845]],\n",
      "\n",
      "        [[-0.01114983,  0.00034436, -0.01246372, ..., -0.03317266,\n",
      "          -0.02006347, -0.00768594],\n",
      "         [-0.01589214,  0.01577555,  0.01624861, ..., -0.0076207 ,\n",
      "          -0.01753558, -0.0115874 ],\n",
      "         [-0.00928051, -0.01891861, -0.01122414, ..., -0.00399633,\n",
      "           0.00314403, -0.00754632],\n",
      "         ...,\n",
      "         [ 0.00612532, -0.04868062,  0.00462015, ...,  0.00532966,\n",
      "           0.00221087, -0.01291594],\n",
      "         [ 0.00573038, -0.02596688, -0.02331921, ...,  0.0107055 ,\n",
      "          -0.01069627, -0.02455129],\n",
      "         [ 0.02083127, -0.01838739, -0.02794406, ...,  0.02462708,\n",
      "          -0.0145788 ,  0.00693306]]],\n",
      "\n",
      "\n",
      "       [[[-0.0058025 , -0.01791027, -0.02051721, ..., -0.01150989,\n",
      "          -0.02450956,  0.01499854],\n",
      "         [ 0.01118463, -0.0300288 , -0.0185552 , ..., -0.00547329,\n",
      "          -0.01502396,  0.00649037],\n",
      "         [-0.02078796,  0.03289298, -0.00714563, ..., -0.01267136,\n",
      "          -0.00917494, -0.0279663 ],\n",
      "         ...,\n",
      "         [-0.00460337,  0.00914844, -0.02699848, ...,  0.02196243,\n",
      "          -0.00327319,  0.00095354],\n",
      "         [-0.00878943,  0.0144253 , -0.00559657, ..., -0.02564806,\n",
      "          -0.0262788 , -0.00566226],\n",
      "         [ 0.00684664,  0.00247721, -0.0294536 , ...,  0.01974311,\n",
      "          -0.01695546,  0.02241231]],\n",
      "\n",
      "        [[-0.01169641,  0.00368968, -0.01427541, ..., -0.00633364,\n",
      "          -0.05063333,  0.00552089],\n",
      "         [ 0.000786  , -0.00684488,  0.00085795, ..., -0.03172087,\n",
      "           0.00737287,  0.00244749],\n",
      "         [-0.03012566,  0.07074283, -0.05420903, ..., -0.01382046,\n",
      "          -0.01878975, -0.01788554],\n",
      "         ...,\n",
      "         [ 0.00083083, -0.01102382,  0.00483514, ..., -0.00437035,\n",
      "           0.0510439 , -0.01826863],\n",
      "         [-0.00690293,  0.01911813,  0.01017545, ...,  0.01587658,\n",
      "          -0.02805857, -0.00785732],\n",
      "         [-0.01773502, -0.01121203,  0.04941676, ...,  0.06325366,\n",
      "           0.0244989 ,  0.03135187]],\n",
      "\n",
      "        [[-0.00598586,  0.02761046, -0.02558145, ..., -0.02949719,\n",
      "          -0.0137064 , -0.02403823],\n",
      "         [ 0.01144408,  0.00975935, -0.03136482, ..., -0.00883733,\n",
      "          -0.00666068, -0.01005735],\n",
      "         [-0.01165323, -0.00858001, -0.02136198, ..., -0.00384441,\n",
      "          -0.00680586, -0.00472767],\n",
      "         ...,\n",
      "         [ 0.01524681, -0.04832524, -0.02355055, ...,  0.00349075,\n",
      "           0.00151431, -0.02352815],\n",
      "         [ 0.0001007 , -0.00840508, -0.00262447, ...,  0.05118714,\n",
      "          -0.02776064, -0.01776761],\n",
      "         [-0.00586197, -0.03708808,  0.00614003, ...,  0.02073547,\n",
      "           0.06128304, -0.01030526]]],\n",
      "\n",
      "\n",
      "       [[[-0.01980704, -0.00242737,  0.0061301 , ..., -0.02308729,\n",
      "          -0.03226959, -0.01273683],\n",
      "         [ 0.00045141, -0.03148951, -0.019452  , ...,  0.00997264,\n",
      "           0.01128323, -0.00117689],\n",
      "         [-0.0195499 , -0.01288179, -0.02874041, ...,  0.00613363,\n",
      "          -0.03186717, -0.01877662],\n",
      "         ...,\n",
      "         [-0.00192278, -0.02209764, -0.00714537, ...,  0.0344824 ,\n",
      "          -0.02032251, -0.00102835],\n",
      "         [-0.0095994 , -0.00139179,  0.00902921, ..., -0.00874722,\n",
      "          -0.01070859, -0.00987618],\n",
      "         [ 0.01128636, -0.04009337, -0.06095735, ...,  0.01467788,\n",
      "          -0.04268137, -0.00041429]],\n",
      "\n",
      "        [[-0.01026167, -0.00159156,  0.02836555, ..., -0.01833776,\n",
      "          -0.040796  , -0.00664743],\n",
      "         [ 0.02590186, -0.0220113 , -0.0179537 , ..., -0.0356125 ,\n",
      "           0.01491585, -0.01818733],\n",
      "         [-0.04190594,  0.03065524, -0.07216649, ..., -0.02224663,\n",
      "          -0.03208397, -0.00516452],\n",
      "         ...,\n",
      "         [-0.01237095,  0.00032423, -0.01312345, ...,  0.00034516,\n",
      "          -0.0169221 , -0.00637437],\n",
      "         [-0.02498146,  0.0032453 ,  0.00754438, ...,  0.01739726,\n",
      "          -0.00576008,  0.0036149 ],\n",
      "         [ 0.00459641, -0.05975   ,  0.01706984, ...,  0.04364995,\n",
      "          -0.00492023,  0.01740227]],\n",
      "\n",
      "        [[ 0.00033162,  0.01611052,  0.03036699, ...,  0.00012875,\n",
      "          -0.01279958,  0.0047067 ],\n",
      "         [ 0.03486946, -0.01858968, -0.02460478, ..., -0.01421549,\n",
      "          -0.01961148, -0.00923778],\n",
      "         [-0.01794339, -0.00021053, -0.04797752, ..., -0.00965698,\n",
      "          -0.04975275,  0.00382303],\n",
      "         ...,\n",
      "         [ 0.02274517,  0.01354212, -0.01936226, ..., -0.02265413,\n",
      "          -0.00881009, -0.00576904],\n",
      "         [-0.00072902, -0.02006206,  0.02356694, ...,  0.05431454,\n",
      "          -0.01201177, -0.01779092],\n",
      "         [ 0.00196409, -0.04766871,  0.08332834, ...,  0.04098659,\n",
      "           0.04497423, -0.00666941]]]], dtype=float32)]\n",
      "conv_14 [array([[[[ 1.12591300e-03, -1.79999992e-02,  1.27829323e-02, ...,\n",
      "          -7.50622293e-03, -5.41970460e-03,  8.07153899e-03],\n",
      "         [-9.72110312e-03, -1.19444290e-02, -4.29706415e-04, ...,\n",
      "          -1.53473178e-02,  1.41416034e-02, -3.46134827e-02],\n",
      "         [ 5.57626772e-04,  3.64406896e-03,  1.19679160e-02, ...,\n",
      "           5.71570126e-04, -5.15579758e-03, -7.25105498e-03],\n",
      "         ...,\n",
      "         [-2.73799337e-03, -9.78784263e-03, -4.24187677e-03, ...,\n",
      "          -3.70915094e-03,  1.05530061e-02, -3.18503077e-03],\n",
      "         [ 2.58677360e-02, -3.22438916e-03,  1.29457489e-02, ...,\n",
      "           1.78917181e-02, -2.79817660e-03,  4.50995471e-03],\n",
      "         [-1.76348947e-02, -6.16007997e-03,  1.78789459e-02, ...,\n",
      "          -6.69740140e-03,  4.92157706e-04, -1.24855302e-02]],\n",
      "\n",
      "        [[-1.19626836e-03,  6.05674926e-03,  2.61512045e-02, ...,\n",
      "          -1.64434165e-02,  3.12922266e-03,  2.26472109e-03],\n",
      "         [-1.34886699e-02,  1.23234103e-02,  2.97859055e-03, ...,\n",
      "          -1.23745212e-02,  3.27012269e-03, -1.21217836e-02],\n",
      "         [-8.84837098e-03, -4.77706664e-04, -6.63455669e-03, ...,\n",
      "          -2.84679234e-04, -1.07793082e-02, -1.74628850e-02],\n",
      "         ...,\n",
      "         [ 9.15991608e-03, -1.30401859e-02,  9.05941706e-03, ...,\n",
      "          -1.30019179e-02, -1.12397759e-03, -8.44462030e-03],\n",
      "         [-8.46111868e-03,  1.16086677e-02, -1.86108463e-02, ...,\n",
      "           5.64887142e-03,  4.06632246e-03, -1.67834386e-03],\n",
      "         [-3.22768800e-02, -1.43186189e-02,  1.73295289e-02, ...,\n",
      "          -1.64179839e-02,  1.31363124e-02, -3.53281526e-03]],\n",
      "\n",
      "        [[ 2.14438667e-04,  3.27991741e-03, -3.06469598e-03, ...,\n",
      "          -1.60901248e-02,  5.86315244e-03, -5.83797460e-04],\n",
      "         [ 4.00433177e-03,  3.98167782e-03,  2.08259095e-02, ...,\n",
      "           3.46760149e-03,  6.64665829e-03, -4.71997960e-03],\n",
      "         [ 1.83772133e-03, -2.25288216e-02,  1.52387598e-03, ...,\n",
      "          -2.14203284e-03, -9.94224916e-04, -8.68551992e-03],\n",
      "         ...,\n",
      "         [-3.54511407e-03, -1.64117431e-03, -1.66828427e-02, ...,\n",
      "          -1.08782910e-02,  4.34106728e-03, -7.93532003e-04],\n",
      "         [ 1.31409022e-03,  5.21282107e-03,  6.46234676e-03, ...,\n",
      "           5.94984461e-03, -7.82896392e-03, -1.03350841e-02],\n",
      "         [-1.26326019e-02,  7.32006831e-03,  1.37140313e-02, ...,\n",
      "          -1.13822259e-02,  4.87447949e-03, -4.23018960e-03]]],\n",
      "\n",
      "\n",
      "       [[[-1.68119017e-02,  4.82867192e-03,  7.14838784e-03, ...,\n",
      "           8.43767915e-03, -4.11228323e-03,  5.59629779e-03],\n",
      "         [-1.48145985e-02,  2.01124046e-02, -8.20328854e-03, ...,\n",
      "          -1.56991147e-02,  2.38292548e-03, -2.74074618e-02],\n",
      "         [ 1.58549044e-02, -3.94415954e-04,  1.32677406e-02, ...,\n",
      "          -3.28213000e-03, -2.60201574e-04,  2.01469846e-03],\n",
      "         ...,\n",
      "         [ 5.66282123e-03, -8.48133117e-04, -1.75939947e-02, ...,\n",
      "          -9.27448459e-03,  3.93362250e-03, -9.98237357e-03],\n",
      "         [ 3.26103605e-02, -3.01552983e-03, -4.35148366e-03, ...,\n",
      "           9.03687160e-03, -8.60305876e-03, -5.61184541e-04],\n",
      "         [ 6.66348403e-03, -4.29997686e-03, -1.92594975e-02, ...,\n",
      "           1.95751805e-03,  1.38988288e-03, -2.82972562e-03]],\n",
      "\n",
      "        [[-3.16902325e-02,  1.90245323e-02, -3.40609648e-03, ...,\n",
      "           4.24683513e-03, -6.50904560e-03,  5.32365497e-03],\n",
      "         [-5.01930295e-03, -1.05903745e-02, -1.72273852e-02, ...,\n",
      "          -1.30672269e-02, -1.09831104e-03,  8.93026649e-04],\n",
      "         [ 2.23492775e-02, -3.24836709e-02,  2.10052840e-02, ...,\n",
      "           2.63051642e-03, -2.18060520e-02, -2.06625629e-02],\n",
      "         ...,\n",
      "         [ 1.24290166e-02, -1.87043063e-02,  7.85882305e-03, ...,\n",
      "          -4.15339554e-03, -2.80867284e-03, -5.38844708e-03],\n",
      "         [ 6.81837723e-02,  1.08587602e-02, -2.75225937e-02, ...,\n",
      "          -1.16173681e-02, -6.84531685e-03,  6.78869756e-03],\n",
      "         [-1.59634613e-02, -2.18334496e-02, -2.71280129e-02, ...,\n",
      "           1.20243570e-02,  8.66625458e-03, -2.63950191e-02]],\n",
      "\n",
      "        [[-1.27519192e-02, -9.42542218e-03,  7.15621747e-03, ...,\n",
      "          -3.99787124e-04, -8.04597512e-03, -8.47156625e-03],\n",
      "         [-1.64233358e-03,  1.23401973e-02,  5.74254803e-03, ...,\n",
      "          -1.65041536e-03,  8.49855307e-04, -3.34717683e-03],\n",
      "         [ 3.52539359e-07, -3.83481868e-02,  1.86423101e-02, ...,\n",
      "          -1.29931523e-02, -9.49859433e-03,  1.64394435e-02],\n",
      "         ...,\n",
      "         [-1.50668686e-02,  1.56767201e-02, -2.29204819e-02, ...,\n",
      "           3.20199109e-03, -3.45182628e-03, -9.03070686e-05],\n",
      "         [ 3.43608856e-02,  6.17004093e-03, -5.03497198e-03, ...,\n",
      "          -1.20848343e-02, -1.03287911e-02, -2.57213861e-02],\n",
      "         [-5.67731913e-03, -1.89026687e-02, -1.11322990e-02, ...,\n",
      "           6.02836255e-03,  7.16164196e-03, -2.97893453e-02]]],\n",
      "\n",
      "\n",
      "       [[[-4.55990992e-03, -1.32933928e-04, -1.82359591e-02, ...,\n",
      "           2.41330382e-03,  1.76916263e-04,  1.37831569e-02],\n",
      "         [-1.45559981e-02,  8.72862898e-03, -8.63699708e-03, ...,\n",
      "           4.79649846e-03,  7.34406814e-04, -3.03061970e-04],\n",
      "         [ 7.35488441e-03, -1.47739751e-02, -3.94924282e-04, ...,\n",
      "           9.66627849e-05,  4.01427783e-03, -1.03609508e-03],\n",
      "         ...,\n",
      "         [ 1.49562983e-02, -4.76816949e-03, -6.32780651e-03, ...,\n",
      "          -1.18379528e-02,  4.53828106e-04, -2.14693905e-03],\n",
      "         [ 3.46911214e-02, -2.00682338e-02, -9.99944564e-03, ...,\n",
      "          -5.64367324e-03, -2.46210815e-03,  1.81414206e-02],\n",
      "         [ 2.07569692e-02, -1.29756716e-03, -2.30607800e-02, ...,\n",
      "           3.83463060e-03,  4.09918325e-03,  5.54455910e-03]],\n",
      "\n",
      "        [[-3.03766914e-02, -5.98690333e-03, -2.90000681e-02, ...,\n",
      "           9.49614402e-03,  2.21412838e-03,  8.23372696e-03],\n",
      "         [-8.62403028e-03, -1.31136626e-02, -1.48339691e-02, ...,\n",
      "           5.91754541e-03,  2.26666220e-03,  3.64283845e-02],\n",
      "         [-2.21142522e-03, -2.65787058e-02, -1.77260023e-02, ...,\n",
      "          -8.07438861e-04,  4.24929010e-03, -4.01491597e-02],\n",
      "         ...,\n",
      "         [ 6.52470486e-03, -8.22718255e-03, -7.49937724e-03, ...,\n",
      "          -2.33799056e-03,  9.67889093e-04, -4.54596151e-03],\n",
      "         [ 2.08232738e-02, -7.73104839e-03, -4.26019588e-03, ...,\n",
      "          -2.10064389e-02,  3.74769443e-03, -1.23397373e-02],\n",
      "         [ 1.76550541e-02, -1.33409742e-02, -1.71654951e-02, ...,\n",
      "           1.09775299e-02,  2.82093626e-03, -8.35690368e-03]],\n",
      "\n",
      "        [[-1.62751209e-02, -1.73658244e-02, -1.47417495e-02, ...,\n",
      "           1.71703275e-03, -6.23400975e-03,  2.32759342e-02],\n",
      "         [-7.40390783e-03, -1.80688798e-02, -1.22758225e-02, ...,\n",
      "           1.22819841e-02,  3.15713766e-03, -5.59447752e-03],\n",
      "         [ 6.42367452e-03, -2.33184416e-02,  1.12118700e-03, ...,\n",
      "          -1.88444369e-02, -1.32450862e-02, -1.25556323e-03],\n",
      "         ...,\n",
      "         [-2.06267252e-03,  1.21090328e-02, -1.17281312e-02, ...,\n",
      "           8.46471358e-03,  7.75764289e-04, -3.27088796e-02],\n",
      "         [ 4.00513895e-02,  7.96445925e-03,  3.71957052e-04, ...,\n",
      "          -1.48891825e-02, -5.25080366e-03, -1.66947814e-03],\n",
      "         [ 1.50169209e-02, -1.99183729e-02, -1.45365410e-02, ...,\n",
      "           4.33141086e-03, -9.79891326e-03, -1.64578240e-02]]]],\n",
      "      dtype=float32)]\n",
      "conv_15 [array([[[[ 0.19143392, -0.10611773,  0.00673514, ..., -0.10258852,\n",
      "          -0.06796212, -0.04196317],\n",
      "         [-0.07546722, -0.15258959, -0.08751062, ...,  0.0022453 ,\n",
      "          -0.05892092,  0.00160973],\n",
      "         [-0.09198509, -0.21203329, -0.006884  , ...,  0.14845249,\n",
      "           0.07655799, -0.09857908],\n",
      "         ...,\n",
      "         [-0.07098643, -0.05528874, -0.02155441, ..., -0.16966398,\n",
      "          -0.12334815, -0.15745103],\n",
      "         [-0.00872305,  0.09654544, -0.21770634, ...,  0.05514843,\n",
      "           0.00149807, -0.03144943],\n",
      "         [ 0.09918083, -0.05789131,  0.07469989, ...,  0.03301247,\n",
      "           0.05976806, -0.07284516]]]], dtype=float32)]\n",
      "conv_16 [array([[[[ 0.00807551, -0.0280848 ,  0.02514889, ...,  0.02560309,\n",
      "           0.0290932 ,  0.00974225],\n",
      "         [-0.00683639,  0.02941405, -0.01125208, ..., -0.02907435,\n",
      "           0.03312953,  0.00067798],\n",
      "         [-0.01459053,  0.02684379,  0.00803532, ...,  0.00493364,\n",
      "          -0.02418713,  0.02660733],\n",
      "         ...,\n",
      "         [-0.02246485,  0.01522462,  0.00114509, ..., -0.04105796,\n",
      "           0.07398587, -0.02236065],\n",
      "         [-0.00436118,  0.03903906, -0.0193542 , ...,  0.11309237,\n",
      "          -0.04236867, -0.01161152],\n",
      "         [ 0.00696175, -0.02306864, -0.02490051, ..., -0.03229899,\n",
      "           0.00599569,  0.00123445]],\n",
      "\n",
      "        [[-0.00416054, -0.02909603, -0.01357645, ...,  0.00166894,\n",
      "          -0.00896087,  0.02173852],\n",
      "         [-0.0092683 ,  0.0247183 ,  0.0079284 , ..., -0.03979396,\n",
      "          -0.02389563, -0.00217564],\n",
      "         [-0.0155221 ,  0.02750147, -0.00095249, ..., -0.00244952,\n",
      "          -0.02495   ,  0.0248208 ],\n",
      "         ...,\n",
      "         [-0.01302369, -0.00233094, -0.00457013, ...,  0.05060707,\n",
      "           0.00958633, -0.02105434],\n",
      "         [-0.00414294,  0.03345078, -0.02949607, ...,  0.01423266,\n",
      "          -0.01485063, -0.01240852],\n",
      "         [ 0.00385106, -0.06241884, -0.02626906, ..., -0.00607296,\n",
      "           0.04985061,  0.00154553]],\n",
      "\n",
      "        [[ 0.00271253,  0.00175204,  0.02636515, ..., -0.00374474,\n",
      "          -0.00490709,  0.00563013],\n",
      "         [ 0.00425079,  0.03361332,  0.00170313, ..., -0.02749137,\n",
      "           0.04120351, -0.00218923],\n",
      "         [-0.0237345 ,  0.03513157, -0.00056156, ..., -0.00082112,\n",
      "          -0.02443564,  0.02247646],\n",
      "         ...,\n",
      "         [-0.01171957,  0.00205858,  0.00090915, ..., -0.03776979,\n",
      "           0.02628576, -0.02193657],\n",
      "         [-0.00218027,  0.0616204 , -0.03628235, ...,  0.11795855,\n",
      "          -0.01297978, -0.01299278],\n",
      "         [ 0.00399823, -0.02136733, -0.02953202, ..., -0.02852449,\n",
      "           0.00090117,  0.00637015]]],\n",
      "\n",
      "\n",
      "       [[[ 0.0100615 , -0.02716755,  0.02713634, ...,  0.01375163,\n",
      "           0.03011419, -0.00212129],\n",
      "         [-0.01051267,  0.00398604, -0.00965931, ..., -0.04236378,\n",
      "          -0.00143789, -0.00948266],\n",
      "         [-0.01652966,  0.04106248, -0.00482584, ...,  0.01813813,\n",
      "          -0.02086913,  0.01297379],\n",
      "         ...,\n",
      "         [-0.02551518,  0.0151977 , -0.01331306, ..., -0.03436693,\n",
      "           0.08118038,  0.00445918],\n",
      "         [-0.00699496, -0.0088654 , -0.01053438, ..., -0.01519209,\n",
      "          -0.0110715 ,  0.00431487],\n",
      "         [ 0.00574039, -0.00981347, -0.03145062, ..., -0.02053142,\n",
      "           0.01338743, -0.00766355]],\n",
      "\n",
      "        [[ 0.00712789, -0.01652055,  0.01326242, ...,  0.01288752,\n",
      "           0.02107524,  0.00501952],\n",
      "         [-0.01971392,  0.04051911,  0.01900775, ..., -0.06249498,\n",
      "          -0.00535235, -0.00735623],\n",
      "         [-0.01971405,  0.04630493,  0.00460932, ...,  0.03916782,\n",
      "          -0.00367502,  0.01142235],\n",
      "         ...,\n",
      "         [-0.01147411, -0.000903  , -0.04092908, ...,  0.02350448,\n",
      "           0.0451349 ,  0.0111101 ],\n",
      "         [-0.00530583, -0.00950133, -0.02108527, ..., -0.01343086,\n",
      "           0.00529905, -0.00404198],\n",
      "         [ 0.01596909, -0.04980528, -0.02521791, ...,  0.03179904,\n",
      "           0.05517367, -0.0113239 ]],\n",
      "\n",
      "        [[-0.00102407, -0.00358658,  0.03402798, ...,  0.01828126,\n",
      "           0.04438353,  0.00255319],\n",
      "         [-0.01064485,  0.00446275, -0.02023282, ..., -0.04979699,\n",
      "           0.01076289, -0.00993916],\n",
      "         [-0.02636816,  0.0277578 ,  0.00222952, ...,  0.00886944,\n",
      "          -0.01155428,  0.01546444],\n",
      "         ...,\n",
      "         [-0.01415529, -0.02009202, -0.01835708, ..., -0.01010602,\n",
      "           0.02942321, -0.00251793],\n",
      "         [-0.00046026, -0.00669961, -0.01459728, ...,  0.00609902,\n",
      "           0.00349483,  0.00391195],\n",
      "         [ 0.00466854, -0.02088905, -0.02356935, ..., -0.01490805,\n",
      "          -0.02813542, -0.00453508]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00652502, -0.00789148,  0.01403969, ...,  0.02137228,\n",
      "          -0.03038702,  0.00498167],\n",
      "         [-0.01067377, -0.0031419 ,  0.01996704, ..., -0.01321372,\n",
      "           0.04847521, -0.01267745],\n",
      "         [-0.00858278, -0.0054934 , -0.00774009, ...,  0.02373945,\n",
      "          -0.01708017,  0.01235169],\n",
      "         ...,\n",
      "         [-0.042569  ,  0.01275223, -0.01761656, ..., -0.0155173 ,\n",
      "           0.0053802 , -0.00507124],\n",
      "         [-0.01851099, -0.03786767, -0.01171542, ..., -0.04373822,\n",
      "           0.01306682, -0.00857655],\n",
      "         [ 0.00082131,  0.0399637 , -0.01291217, ..., -0.02401759,\n",
      "          -0.01855625, -0.00934628]],\n",
      "\n",
      "        [[ 0.00164138, -0.03982268,  0.00600348, ...,  0.03541964,\n",
      "          -0.04856402,  0.01073604],\n",
      "         [-0.03079744, -0.01829121,  0.0262824 , ..., -0.02417801,\n",
      "           0.13678794, -0.00927385],\n",
      "         [-0.01557285, -0.00649225, -0.00341193, ...,  0.0557548 ,\n",
      "          -0.00824546,  0.01104953],\n",
      "         ...,\n",
      "         [-0.04345808,  0.01429223, -0.0275664 , ..., -0.01796266,\n",
      "           0.00168374,  0.00197627],\n",
      "         [-0.02027325, -0.01360189, -0.00208189, ..., -0.06164948,\n",
      "           0.00532529, -0.0127253 ],\n",
      "         [ 0.00607647,  0.02213329, -0.0087815 , ...,  0.00891482,\n",
      "          -0.01657999, -0.00846038]],\n",
      "\n",
      "        [[ 0.00014805, -0.02152634,  0.0108926 , ...,  0.04745111,\n",
      "          -0.0371378 ,  0.01925945],\n",
      "         [-0.02515622, -0.03101097, -0.00761384, ..., -0.00804302,\n",
      "           0.03756405, -0.0068904 ],\n",
      "         [-0.01498624, -0.01063643, -0.00426275, ...,  0.01815758,\n",
      "          -0.00220229,  0.01832077],\n",
      "         ...,\n",
      "         [-0.03279109,  0.00043514, -0.00769316, ...,  0.00200333,\n",
      "          -0.02775396, -0.00509368],\n",
      "         [-0.01892563, -0.03421161,  0.00663021, ..., -0.04695   ,\n",
      "          -0.01178987, -0.00561398],\n",
      "         [-0.00738182,  0.02787498, -0.01952254, ..., -0.02472586,\n",
      "          -0.04002197, -0.00870581]]]], dtype=float32)]\n",
      "conv_17 [array([[[[-0.04650331,  0.09513813, -0.17600243, ..., -0.06143475,\n",
      "          -0.1336893 , -0.04462598],\n",
      "         [-0.06505483,  0.01315632, -0.13070233, ..., -0.00768883,\n",
      "          -0.2616414 , -0.03359379],\n",
      "         [ 0.01441627,  0.03158605, -0.01086078, ...,  0.0075598 ,\n",
      "           0.03878124,  0.03126227],\n",
      "         ...,\n",
      "         [ 0.2517993 ,  0.00915247,  0.14952888, ...,  0.2149883 ,\n",
      "           0.06762971,  0.17266251],\n",
      "         [ 0.06169932, -0.03469652,  0.05355908, ...,  0.08346896,\n",
      "          -0.07906832, -0.06192382],\n",
      "         [-0.18920396,  0.05865443,  0.15176196, ...,  0.01684226,\n",
      "          -0.16561113, -0.1128467 ]]]], dtype=float32)]\n",
      "conv_18 [array([[[[-1.73671711e-02, -1.43428728e-01, -2.60362402e-02, ...,\n",
      "          -5.27646430e-02,  2.52916403e-02,  9.56527144e-03],\n",
      "         [-1.62056804e-01, -2.25335971e-01,  3.93319353e-02, ...,\n",
      "          -2.35547442e-02, -5.01406118e-02,  8.09914619e-02],\n",
      "         [ 1.11415856e-01, -1.08089387e-01,  6.39774352e-02, ...,\n",
      "           3.55659127e-01, -1.15602314e-01, -6.98718578e-02],\n",
      "         ...,\n",
      "         [ 2.88957115e-02,  3.44208702e-02, -1.50633648e-01, ...,\n",
      "           8.51601213e-02,  3.09762359e-01,  9.98387933e-02],\n",
      "         [-8.11441168e-02,  4.68127578e-02,  3.58455218e-02, ...,\n",
      "          -5.24434447e-02, -1.74813941e-01, -1.67469289e-02],\n",
      "         [ 1.71611384e-01, -2.36358382e-02, -2.01585710e-01, ...,\n",
      "           6.61983415e-02, -1.29392510e-02, -3.16528417e-02]],\n",
      "\n",
      "        [[-9.68163684e-02, -1.06453784e-01, -1.08470365e-01, ...,\n",
      "           4.25590016e-02,  6.39383569e-02,  1.11593995e-02],\n",
      "         [-2.26598367e-01, -2.19837084e-01,  2.20790803e-02, ...,\n",
      "          -2.16450810e-01,  3.36570516e-02,  3.70024773e-03],\n",
      "         [ 1.27588809e-01, -7.25013241e-02,  1.02162495e-01, ...,\n",
      "           2.95986086e-01, -2.39196364e-02, -9.59034339e-02],\n",
      "         ...,\n",
      "         [ 6.72011869e-03,  4.98158410e-02, -1.54265836e-01, ...,\n",
      "           5.85028306e-02,  3.71745646e-01, -3.04323770e-02],\n",
      "         [-1.12000346e-01,  3.73338931e-03,  1.98301785e-02, ...,\n",
      "          -4.11323234e-02, -1.30568340e-01, -1.34148849e-02],\n",
      "         [ 8.12277570e-02, -8.29163790e-02, -1.38778999e-01, ...,\n",
      "          -2.40574796e-02,  9.96484142e-03, -9.63188335e-02]],\n",
      "\n",
      "        [[-6.15454577e-02, -1.35788675e-02, -7.49019608e-02, ...,\n",
      "           3.67240794e-02,  1.00208379e-01,  8.18248168e-02],\n",
      "         [-1.63949043e-01, -4.64646332e-02,  5.19635491e-02, ...,\n",
      "          -4.45792377e-02,  7.24514201e-02,  1.43701538e-01],\n",
      "         [ 1.68981761e-01, -8.29420015e-02,  1.24742113e-01, ...,\n",
      "           2.63811558e-01, -4.27257456e-02, -8.55934396e-02],\n",
      "         ...,\n",
      "         [-6.30937070e-02,  2.64265090e-02, -6.06371909e-02, ...,\n",
      "           1.66045129e-02,  3.30723584e-01, -7.30279312e-02],\n",
      "         [-1.18920982e-01,  1.85449850e-02,  7.75697678e-02, ...,\n",
      "          -3.18410769e-02, -1.21897876e-01,  8.14733654e-02],\n",
      "         [ 1.38339326e-01, -1.15081526e-01, -1.09684683e-01, ...,\n",
      "           8.67491439e-02, -7.53798336e-02, -7.58926868e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 3.95330936e-02, -3.62139717e-02, -2.68865433e-02, ...,\n",
      "           5.33621982e-02,  9.84628499e-02, -3.74175869e-02],\n",
      "         [-1.24129370e-01, -1.83333188e-01,  5.18546328e-02, ...,\n",
      "          -8.98154154e-02, -3.80736850e-02,  9.67853367e-02],\n",
      "         [ 6.95583299e-02, -2.37800498e-02,  3.17082852e-02, ...,\n",
      "           1.38046205e-01, -6.04021214e-02, -5.63745871e-02],\n",
      "         ...,\n",
      "         [ 1.13764897e-01,  4.68033105e-02, -1.07503816e-01, ...,\n",
      "          -4.46362570e-02,  2.71724701e-01,  5.79653680e-02],\n",
      "         [-6.24131002e-02,  4.92462562e-03,  7.50096813e-02, ...,\n",
      "          -1.52748227e-01, -1.41228601e-01,  4.39829193e-02],\n",
      "         [ 1.11775681e-01,  1.52729359e-03, -1.22623004e-01, ...,\n",
      "          -4.33625095e-02,  4.05628933e-03, -7.12005794e-02]],\n",
      "\n",
      "        [[-8.50182474e-02, -5.90272769e-02,  1.01621188e-02, ...,\n",
      "           1.66758627e-01,  1.67942405e-01,  1.48814097e-01],\n",
      "         [-1.67607009e-01, -1.81660146e-01, -1.00210637e-01, ...,\n",
      "          -2.35146567e-01,  3.05840615e-02, -6.08532317e-02],\n",
      "         [ 1.30705014e-01,  1.01701908e-01,  2.11151689e-02, ...,\n",
      "           8.36434737e-02,  3.96523951e-03,  1.41065372e-02],\n",
      "         ...,\n",
      "         [ 1.48045029e-02, -1.44260892e-04, -8.42646137e-02, ...,\n",
      "           4.80768383e-02,  2.89868265e-01, -6.60496950e-02],\n",
      "         [-1.22084254e-02, -1.86952595e-02, -1.51386522e-02, ...,\n",
      "          -1.35690361e-01, -1.30292147e-01, -4.12370488e-02],\n",
      "         [-6.92144185e-02, -8.50129426e-02, -7.16350153e-02, ...,\n",
      "          -1.32382303e-01, -2.25690138e-02, -4.06127386e-02]],\n",
      "\n",
      "        [[-8.68531913e-02, -2.19535641e-02, -1.40962690e-01, ...,\n",
      "           9.73507538e-02,  9.31768268e-02,  8.55632871e-02],\n",
      "         [-1.63726732e-01, -1.16296217e-01,  7.08191842e-02, ...,\n",
      "          -7.59126991e-02,  7.70990625e-02,  1.23584434e-01],\n",
      "         [ 1.94371089e-01,  4.58231494e-02,  1.06660470e-01, ...,\n",
      "           1.66423291e-01, -6.75569847e-02, -2.40913462e-02],\n",
      "         ...,\n",
      "         [-1.08180568e-01,  2.48300228e-02, -3.02722491e-03, ...,\n",
      "           1.92566961e-02,  2.50413924e-01, -1.13093205e-01],\n",
      "         [-6.03086129e-02, -3.26720183e-04,  6.21538721e-02, ...,\n",
      "          -1.16780877e-01, -1.48844540e-01, -7.12956162e-03],\n",
      "         [ 1.97872203e-02, -1.13550596e-01, -6.69781640e-02, ...,\n",
      "          -1.72777940e-02, -6.76333234e-02,  6.91699283e-03]]],\n",
      "\n",
      "\n",
      "       [[[-6.90744892e-02,  7.51688983e-03, -3.53965573e-02, ...,\n",
      "           4.38605100e-02,  1.87889233e-01, -1.54651642e-01],\n",
      "         [-9.64057148e-02, -4.46065255e-02, -1.87240504e-02, ...,\n",
      "           5.60179949e-02,  1.02081656e-01,  1.60878837e-01],\n",
      "         [-2.15382259e-02,  3.87112930e-04,  6.14608340e-02, ...,\n",
      "           1.44010514e-01, -3.62260304e-02,  3.27434787e-03],\n",
      "         ...,\n",
      "         [-5.69683407e-03,  1.38009146e-01, -1.21017635e-01, ...,\n",
      "          -1.15871271e-02,  2.47639567e-01,  6.28361255e-02],\n",
      "         [-3.83732840e-02,  4.72634025e-02,  8.75482559e-02, ...,\n",
      "          -1.51622057e-01, -6.05589561e-02,  1.14772148e-01],\n",
      "         [ 1.34333238e-01,  3.21049280e-02, -8.46676752e-02, ...,\n",
      "          -5.55759780e-02, -3.04886792e-02, -4.67887260e-02]],\n",
      "\n",
      "        [[-1.04968295e-01, -2.34767869e-02, -9.79174674e-02, ...,\n",
      "           1.40533522e-01,  1.16754524e-01, -1.41601386e-02],\n",
      "         [-1.45426705e-01, -5.87796383e-02, -1.37002259e-01, ...,\n",
      "          -6.19242676e-02,  1.61388934e-01,  3.18229645e-02],\n",
      "         [ 1.04703223e-02, -7.75752240e-04,  9.97345224e-02, ...,\n",
      "           7.70769492e-02, -8.04423243e-02,  7.19600869e-03],\n",
      "         ...,\n",
      "         [-1.39189567e-02,  1.10228024e-01, -4.74670604e-02, ...,\n",
      "           7.66429529e-02,  2.63350487e-01, -2.54192334e-02],\n",
      "         [ 1.48642911e-02,  3.55224907e-02,  7.90804550e-02, ...,\n",
      "          -1.71022385e-01, -5.80916815e-02,  8.64491165e-02],\n",
      "         [ 3.89659368e-02, -6.42150491e-02, -1.35567904e-01, ...,\n",
      "          -6.47691190e-02, -3.80460136e-02, -2.53260117e-02]],\n",
      "\n",
      "        [[-9.21281055e-02,  2.18113046e-02, -1.14461802e-01, ...,\n",
      "           7.89928958e-02, -2.07461677e-02, -1.30465403e-01],\n",
      "         [-1.54593825e-01, -7.92922080e-02, -6.73345849e-02, ...,\n",
      "          -1.68831274e-02,  1.26411378e-01,  1.15482725e-01],\n",
      "         [ 6.69004098e-02, -2.36774725e-03,  1.81164101e-01, ...,\n",
      "           2.55561650e-01, -6.19823374e-02,  1.20907659e-02],\n",
      "         ...,\n",
      "         [-1.28175735e-01,  1.08198389e-01, -9.13419202e-02, ...,\n",
      "           3.43363769e-02,  2.33508751e-01, -9.88225862e-02],\n",
      "         [-7.18882605e-02,  4.88530695e-02,  1.42737806e-01, ...,\n",
      "          -1.75578550e-01, -1.38542339e-01,  5.01521863e-02],\n",
      "         [ 6.25840053e-02,  4.05422924e-03, -8.02868530e-02, ...,\n",
      "           8.77780188e-03, -1.00482084e-01, -9.16107092e-03]]]],\n",
      "      dtype=float32)]\n",
      "conv_19 [array([[[[-6.35290126e-05, -1.41910871e-03,  1.46546517e-03, ...,\n",
      "          -2.94743426e-04,  2.67445552e-03,  9.77252610e-04],\n",
      "         [-2.02234765e-03,  1.56860333e-03,  6.99661497e-04, ...,\n",
      "           3.11860815e-04, -2.29014643e-03, -4.64923185e-04],\n",
      "         [-1.89583702e-03, -2.00612805e-04,  5.19007503e-04, ...,\n",
      "           1.39067299e-04, -3.56014149e-04, -6.77249511e-04],\n",
      "         ...,\n",
      "         [ 2.10021622e-03,  1.08199916e-03,  1.53546908e-03, ...,\n",
      "           5.41479501e-04, -1.24635443e-03, -7.84004631e-04],\n",
      "         [-2.21397704e-03, -3.72596005e-05,  9.76762502e-04, ...,\n",
      "          -8.94292549e-04, -8.10154015e-04, -1.34131755e-03],\n",
      "         [-1.48838176e-03, -1.63143023e-03, -1.56457187e-03, ...,\n",
      "          -1.04944641e-03,  5.36699314e-04,  1.02894788e-03]],\n",
      "\n",
      "        [[ 2.51664408e-03, -1.36429712e-03, -5.28620440e-04, ...,\n",
      "           7.68081227e-04, -1.09139760e-03, -4.58765950e-04],\n",
      "         [-2.73891928e-04, -1.16531923e-03, -1.45656103e-03, ...,\n",
      "          -2.08670259e-04,  3.92514485e-04, -8.73642100e-04],\n",
      "         [ 2.10902328e-03,  1.25589478e-03,  2.52873427e-03, ...,\n",
      "           2.49093882e-05, -3.33072385e-03,  8.12278071e-04],\n",
      "         ...,\n",
      "         [-3.64815845e-04,  1.49925321e-03, -2.43015448e-03, ...,\n",
      "          -1.11117377e-03,  8.89226154e-04,  4.97434405e-04],\n",
      "         [ 1.88825815e-03,  3.70502647e-04,  1.80549908e-03, ...,\n",
      "           6.42584404e-04,  2.40664463e-03, -2.56698782e-04],\n",
      "         [ 8.03247560e-04, -1.57570036e-03,  2.95345002e-04, ...,\n",
      "          -2.12894476e-04,  3.31030018e-03,  3.58820515e-04]],\n",
      "\n",
      "        [[-3.54296388e-03, -1.04820111e-03,  3.78249242e-04, ...,\n",
      "          -3.57858546e-04,  9.36680241e-04,  7.47451908e-04],\n",
      "         [-8.99234961e-04,  9.84507729e-04,  2.75774975e-03, ...,\n",
      "           4.31306762e-05,  2.77427054e-04,  7.16463313e-04],\n",
      "         [-2.46912707e-03, -1.14012812e-03,  2.25010281e-03, ...,\n",
      "           5.05080039e-04,  2.08797792e-04,  4.64900018e-04],\n",
      "         ...,\n",
      "         [-9.69632412e-04, -5.19264257e-04, -9.01897904e-04, ...,\n",
      "          -1.14840094e-03,  3.37758963e-03,  4.53678558e-06],\n",
      "         [ 2.95632146e-03, -8.55688355e-04, -1.03257829e-03, ...,\n",
      "          -6.70412614e-04, -4.86876350e-03,  4.53886169e-04],\n",
      "         [-1.48105784e-03,  1.12426584e-03,  1.96575536e-03, ...,\n",
      "          -3.28842783e-04,  3.88649665e-03,  6.17235608e-04]]],\n",
      "\n",
      "\n",
      "       [[[-2.25777947e-03,  2.40972673e-04, -1.26748241e-03, ...,\n",
      "          -7.85676180e-04, -1.51937106e-03, -1.40690317e-04],\n",
      "         [ 3.79032834e-04, -1.21598376e-03,  1.07639167e-03, ...,\n",
      "           6.93558948e-04,  2.85920617e-03,  5.34496503e-04],\n",
      "         [-2.79020605e-04, -6.02617220e-04,  1.21555175e-03, ...,\n",
      "           7.30672153e-04,  1.66787149e-03, -7.00733042e-04],\n",
      "         ...,\n",
      "         [-2.59247236e-03, -1.14113512e-03, -1.10828062e-03, ...,\n",
      "          -5.75975690e-04, -2.48577702e-03, -5.06244251e-04],\n",
      "         [-3.50472343e-04, -1.01082458e-03,  2.68674572e-03, ...,\n",
      "          -8.26333940e-04, -1.18112068e-04, -6.50658272e-04],\n",
      "         [ 2.33668648e-03, -3.64407606e-04, -1.07239978e-03, ...,\n",
      "           1.04375335e-03,  1.13827118e-03,  1.04725000e-03]],\n",
      "\n",
      "        [[ 1.75473595e-03, -7.73120497e-04, -1.92022102e-03, ...,\n",
      "           8.14416708e-05,  3.27490014e-03,  8.23684095e-04],\n",
      "         [ 5.36932203e-04,  7.74277665e-04, -1.28438894e-03, ...,\n",
      "          -7.99312198e-04,  7.83661962e-04,  1.02682563e-03],\n",
      "         [ 6.85326639e-04, -1.00270892e-03, -2.46289623e-04, ...,\n",
      "           2.90300115e-04, -2.37011463e-05, -5.01623726e-04],\n",
      "         ...,\n",
      "         [-2.91676633e-03,  1.00710965e-03, -1.81990239e-04, ...,\n",
      "          -7.06121209e-04, -2.91818683e-03, -6.80597790e-04],\n",
      "         [-8.72244360e-04, -2.91055912e-04, -1.83318031e-03, ...,\n",
      "          -1.16822252e-03, -3.82496836e-03,  4.54228226e-04],\n",
      "         [-4.74790839e-04,  1.28239440e-03, -2.26270175e-03, ...,\n",
      "           7.79422408e-04,  2.57022330e-03,  5.46145311e-04]],\n",
      "\n",
      "        [[-8.86924739e-04, -3.50692397e-04, -1.03811012e-03, ...,\n",
      "          -1.29278356e-04,  1.81578612e-03, -3.14024393e-04],\n",
      "         [-1.12828054e-03, -1.60901039e-03, -2.29585939e-03, ...,\n",
      "          -1.21136650e-03, -4.91983490e-03, -4.77047724e-05],\n",
      "         [-3.50538571e-03, -6.68223132e-04, -1.28022235e-04, ...,\n",
      "          -1.03371660e-03,  1.48007728e-03,  2.17460620e-04],\n",
      "         ...,\n",
      "         [ 2.00883602e-04,  2.75708997e-04,  1.59014051e-03, ...,\n",
      "          -1.09868275e-03,  1.19992706e-03,  1.20513188e-03],\n",
      "         [ 2.66380794e-03,  1.57837686e-03,  6.78723736e-04, ...,\n",
      "          -2.87714036e-04, -1.44255871e-03,  8.24316405e-04],\n",
      "         [ 2.49255472e-03, -8.98182625e-04,  2.38179695e-03, ...,\n",
      "           4.03892154e-05, -1.09758264e-04, -4.26666316e-04]]],\n",
      "\n",
      "\n",
      "       [[[-4.73912136e-04, -2.11633043e-04,  2.11438118e-03, ...,\n",
      "           7.66509096e-04,  2.84196623e-03, -6.86733518e-04],\n",
      "         [-4.43684166e-06,  1.25053257e-03, -1.77296367e-03, ...,\n",
      "           1.07223843e-03,  2.76248390e-03, -1.08358229e-03],\n",
      "         [ 1.59270829e-03,  1.07961404e-03, -2.69944221e-03, ...,\n",
      "           8.27381038e-04, -3.04185948e-03,  1.05175260e-03],\n",
      "         ...,\n",
      "         [-2.72951531e-03, -2.72923760e-04, -3.75926931e-04, ...,\n",
      "          -6.11090392e-04,  2.17198022e-03, -5.76138496e-04],\n",
      "         [-6.36246230e-04,  1.18822325e-03, -9.29165835e-05, ...,\n",
      "           1.04695151e-03,  2.01462326e-03,  1.02606509e-03],\n",
      "         [-2.70787789e-03, -8.24367453e-04, -1.66433107e-03, ...,\n",
      "          -6.38198748e-04,  3.84569587e-03,  4.38356772e-04]],\n",
      "\n",
      "        [[-3.36756371e-03, -1.59477012e-03,  1.07444008e-03, ...,\n",
      "          -9.60277917e-04,  1.98665005e-03,  2.38062319e-04],\n",
      "         [ 6.48572459e-04, -1.00554887e-03, -2.56723864e-03, ...,\n",
      "           9.71219095e-04,  2.61011370e-03,  3.69182198e-05],\n",
      "         [-4.24795365e-03, -3.03196663e-04,  2.15334375e-03, ...,\n",
      "           8.23507900e-04,  6.14016433e-04,  2.87655246e-04],\n",
      "         ...,\n",
      "         [-1.58369192e-03, -4.24622995e-04, -1.96629367e-03, ...,\n",
      "           1.71155960e-04,  2.15227483e-03, -1.22307811e-03],\n",
      "         [-1.57566660e-03, -1.42410060e-03,  1.71855930e-03, ...,\n",
      "           1.33057154e-04, -1.24842313e-03, -6.28381909e-04],\n",
      "         [ 1.70825759e-03, -3.54527583e-05, -1.57027843e-03, ...,\n",
      "          -4.44608537e-04, -1.74950587e-03, -6.93970709e-04]],\n",
      "\n",
      "        [[-1.06810301e-03,  3.41023551e-04, -2.91061867e-03, ...,\n",
      "           1.08496705e-03, -2.58352165e-03, -6.51403330e-04],\n",
      "         [-1.53952732e-03, -5.09137230e-04, -1.88511983e-03, ...,\n",
      "          -1.30069835e-04, -2.02951068e-03,  9.68634195e-05],\n",
      "         [ 9.74730297e-04,  1.22592400e-03,  1.46512338e-03, ...,\n",
      "          -7.86093296e-04,  2.70833354e-03, -1.04295090e-03],\n",
      "         ...,\n",
      "         [ 1.37259194e-03,  1.19456067e-03,  2.30840291e-03, ...,\n",
      "          -3.69802816e-04,  1.80296903e-03,  6.39172329e-04],\n",
      "         [-1.51108264e-03,  1.45059545e-03, -5.57505700e-04, ...,\n",
      "           9.07569600e-04, -4.29582549e-03, -3.75165575e-04],\n",
      "         [-2.25799653e-04,  2.29499637e-04, -1.23582478e-03, ...,\n",
      "          -1.39861339e-04,  1.35678902e-05,  1.07217662e-03]]]],\n",
      "      dtype=float32)]\n",
      "conv_21 [array([[[[ 6.15683794e-02, -4.63326722e-02, -9.60482433e-02, ...,\n",
      "          -1.06820188e-01, -2.63553672e-02, -7.42662027e-02],\n",
      "         [-4.36167009e-02,  5.32831922e-02, -2.95708794e-03, ...,\n",
      "          -2.44918920e-04,  1.24102766e-02,  2.07600705e-02],\n",
      "         [-4.60635275e-02,  4.00808118e-02, -1.19542815e-01, ...,\n",
      "          -5.31875156e-02, -1.23035405e-02,  1.41766062e-02],\n",
      "         ...,\n",
      "         [ 4.33324873e-02,  2.27843188e-02,  1.11393362e-01, ...,\n",
      "           4.49512973e-02,  2.55199634e-02, -4.93774749e-02],\n",
      "         [ 1.54463083e-01, -2.23151166e-02,  2.56781846e-01, ...,\n",
      "          -2.72233523e-02, -5.13861305e-04,  1.43446669e-01],\n",
      "         [-1.45242721e-01, -3.74224968e-02,  1.37500754e-02, ...,\n",
      "          -8.79353434e-02, -1.24335932e-02,  8.59208629e-02]]]],\n",
      "      dtype=float32)]\n",
      "conv_20 [array([[[[-8.33222829e-03, -6.51815534e-03,  5.32550178e-03, ...,\n",
      "           6.46402710e-04, -7.43719703e-03,  6.41611172e-03],\n",
      "         [ 1.17098941e-02, -1.63102020e-02,  3.75623093e-03, ...,\n",
      "          -3.93868424e-03, -9.55076597e-04, -2.56359801e-02],\n",
      "         [-5.97003382e-03,  1.09670162e-02, -7.76717905e-03, ...,\n",
      "          -3.55885783e-03,  6.04631286e-03, -1.46303475e-02],\n",
      "         ...,\n",
      "         [ 3.68898432e-03, -6.33932604e-03,  6.51257159e-03, ...,\n",
      "          -3.14622931e-03, -4.09936858e-03,  8.81820638e-03],\n",
      "         [-9.49368719e-03, -4.49390290e-03,  4.36989730e-03, ...,\n",
      "           2.12914217e-03, -8.93441308e-03, -9.23108216e-03],\n",
      "         [-1.34403436e-02,  2.44110096e-02, -7.43881287e-03, ...,\n",
      "          -3.91903799e-03, -9.20669176e-03, -2.40943078e-02]],\n",
      "\n",
      "        [[-8.44077324e-04, -3.99927748e-03,  7.35760247e-03, ...,\n",
      "          -3.47992405e-03, -1.03712606e-03,  3.10020838e-02],\n",
      "         [ 1.25679197e-02,  1.74650690e-03, -7.48083973e-03, ...,\n",
      "          -2.23980984e-03,  6.36827620e-03,  1.55010046e-02],\n",
      "         [-8.54918920e-03,  8.91929958e-03,  2.49770959e-03, ...,\n",
      "           3.57517996e-03,  4.44164686e-03,  2.35270597e-02],\n",
      "         ...,\n",
      "         [ 9.60565172e-03,  1.45181920e-02,  8.26747157e-03, ...,\n",
      "          -2.36161356e-03,  7.15125632e-03,  1.20537467e-02],\n",
      "         [-1.18687553e-02,  5.76821901e-03,  4.86891484e-03, ...,\n",
      "           2.03189440e-03, -5.63120563e-03, -3.08758281e-02],\n",
      "         [ 5.04059996e-03,  1.29679553e-02, -2.35437253e-03, ...,\n",
      "          -1.16417720e-03,  6.86085643e-03, -1.78167336e-02]],\n",
      "\n",
      "        [[-3.68457823e-03,  1.28924567e-02, -1.59433810e-03, ...,\n",
      "           1.66150485e-03,  2.34742137e-03,  8.11783876e-03],\n",
      "         [ 1.59285814e-02,  7.22918240e-03,  4.69514728e-03, ...,\n",
      "           3.86963342e-03,  8.50599352e-03, -1.10799735e-02],\n",
      "         [-2.14678282e-03,  4.39093774e-03,  5.03837771e-04, ...,\n",
      "           1.75684865e-03,  4.04797215e-03,  1.11685379e-03],\n",
      "         ...,\n",
      "         [-2.78872298e-03,  5.80697227e-03, -5.52638900e-03, ...,\n",
      "          -1.51153677e-03,  5.28285978e-03,  1.08460737e-02],\n",
      "         [ 4.76129167e-03, -1.03851352e-02, -6.49980828e-03, ...,\n",
      "           2.84149218e-03, -4.47590137e-03,  1.44164292e-02],\n",
      "         [ 9.83920414e-03,  1.27407897e-03,  6.00629160e-03, ...,\n",
      "           7.99231464e-04,  8.54726695e-03, -2.57887132e-02]]],\n",
      "\n",
      "\n",
      "       [[[-7.15583190e-03, -1.75497923e-02, -1.09835085e-03, ...,\n",
      "           2.22752523e-03,  3.60432547e-03, -1.83259360e-02],\n",
      "         [-6.62249746e-03,  5.74598648e-03,  2.13140011e-05, ...,\n",
      "          -4.08684742e-03, -7.30937114e-03, -4.02182620e-03],\n",
      "         [ 5.15665277e-04,  2.53722519e-02,  1.75261102e-03, ...,\n",
      "           6.68891706e-04,  7.26844557e-03, -2.81993691e-02],\n",
      "         ...,\n",
      "         [ 3.85039253e-03,  4.06581163e-03, -1.74313097e-03, ...,\n",
      "          -1.07509659e-04, -3.25490721e-03,  1.27505418e-02],\n",
      "         [ 5.46645653e-03,  1.80916749e-02,  5.67752984e-04, ...,\n",
      "           3.12305987e-03, -1.78278401e-03, -1.70591418e-02],\n",
      "         [-8.06589983e-03, -2.01602168e-02,  7.46665429e-03, ...,\n",
      "           2.77225277e-03,  4.05946421e-03,  2.48025730e-02]],\n",
      "\n",
      "        [[ 1.72296632e-02, -1.82254892e-02,  7.18723098e-03, ...,\n",
      "           1.31155411e-03,  7.64103187e-03,  2.98004225e-03],\n",
      "         [-1.87289827e-02, -8.88568629e-03,  8.05871654e-03, ...,\n",
      "          -3.77191231e-03,  7.44163431e-03, -1.34500470e-02],\n",
      "         [-1.41274901e-02,  1.21773249e-02, -2.44635041e-04, ...,\n",
      "          -1.03297469e-03,  2.81207287e-03,  2.60621626e-02],\n",
      "         ...,\n",
      "         [-6.89669047e-03,  2.10937746e-02, -5.31924074e-04, ...,\n",
      "          -9.15928176e-05, -7.17775663e-03, -1.29051609e-02],\n",
      "         [-1.28722927e-02, -2.90478840e-02, -7.71944318e-03, ...,\n",
      "           4.11479082e-03, -7.89946597e-03,  2.01583244e-02],\n",
      "         [-3.86671186e-03,  1.30075729e-02, -1.26127701e-03, ...,\n",
      "          -2.72324961e-03,  7.24769779e-04,  1.90511290e-02]],\n",
      "\n",
      "        [[-8.80871806e-03,  3.18324775e-03, -4.96894633e-03, ...,\n",
      "          -2.25746492e-03, -4.76451963e-03,  1.82476342e-02],\n",
      "         [-6.44216834e-06,  2.04844140e-02, -3.75952851e-03, ...,\n",
      "           1.34256680e-03,  3.30111315e-03,  3.24892462e-03],\n",
      "         [ 2.04106234e-02, -1.29929092e-02, -3.65814264e-03, ...,\n",
      "           3.44244018e-03,  1.48996722e-03, -2.43634055e-03],\n",
      "         ...,\n",
      "         [ 6.23931037e-03,  6.62161177e-03, -1.04423314e-04, ...,\n",
      "           1.59183820e-03,  4.54056729e-03, -2.04437245e-02],\n",
      "         [-1.69272423e-02, -3.05401217e-02, -9.62777995e-03, ...,\n",
      "           1.73756038e-03, -3.59534868e-03, -6.03099773e-03],\n",
      "         [ 1.88665539e-02, -1.21313324e-02, -8.48372560e-03, ...,\n",
      "           2.47626158e-04, -3.67913931e-03,  9.10534803e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 1.94581449e-02, -7.93400127e-03,  1.54759455e-03, ...,\n",
      "           2.97501287e-03,  1.59691833e-03,  2.07373966e-02],\n",
      "         [ 9.29824263e-03, -1.85522269e-02,  1.07607117e-03, ...,\n",
      "           7.33367575e-04,  3.06216977e-03,  8.00325163e-03],\n",
      "         [-1.51533317e-02, -2.10870872e-03,  2.40320278e-05, ...,\n",
      "           2.59280740e-03,  5.58957504e-03,  8.62355344e-03],\n",
      "         ...,\n",
      "         [-1.07331937e-02, -1.67205103e-03,  5.57878381e-03, ...,\n",
      "          -2.84765568e-03, -7.07074115e-03,  5.15670981e-04],\n",
      "         [ 9.40878037e-03,  1.93718355e-02,  2.79189087e-03, ...,\n",
      "          -3.37987021e-03, -2.36687623e-03,  7.70744681e-03],\n",
      "         [ 2.73902813e-04, -6.39450457e-03, -2.49257963e-03, ...,\n",
      "           1.56171387e-03,  1.88772078e-03, -5.47073036e-03]],\n",
      "\n",
      "        [[ 2.35016402e-02, -2.72996426e-02, -6.35687076e-03, ...,\n",
      "           1.86504365e-03,  4.35132906e-03, -2.61427779e-02],\n",
      "         [ 1.98340025e-02, -5.41236764e-03,  3.51486239e-03, ...,\n",
      "           9.37567238e-05, -9.11246752e-04,  2.34468039e-02],\n",
      "         [-1.37170637e-02, -9.75416414e-03,  2.35741097e-03, ...,\n",
      "          -1.66389893e-03, -7.08977180e-03, -2.06043534e-02],\n",
      "         ...,\n",
      "         [ 2.57420982e-03, -1.43512674e-02,  3.35225137e-03, ...,\n",
      "          -2.10713242e-05, -8.03466234e-03, -1.49382548e-02],\n",
      "         [-3.25406971e-03, -2.14483775e-02,  8.24596360e-03, ...,\n",
      "           2.77306279e-03,  8.07968993e-03, -2.72044502e-02],\n",
      "         [-1.66235082e-02,  3.86286271e-03,  7.52748083e-03, ...,\n",
      "           3.78323160e-03, -7.44986301e-03,  2.64044181e-02]],\n",
      "\n",
      "        [[-1.17568374e-02, -1.18047399e-02,  4.10557678e-03, ...,\n",
      "           2.31156009e-03,  5.07383328e-03,  1.63049772e-02],\n",
      "         [-1.47000104e-02,  1.45970949e-03, -1.27666665e-03, ...,\n",
      "          -2.08135229e-03,  2.51199771e-03, -6.62851846e-03],\n",
      "         [-4.64614155e-03, -1.99261513e-02, -4.63292934e-03, ...,\n",
      "          -6.08590548e-04, -4.94299177e-03, -2.58146953e-02],\n",
      "         ...,\n",
      "         [ 5.98387187e-03, -5.66159189e-03, -4.55611106e-03, ...,\n",
      "           3.74641526e-03, -5.26827993e-03, -7.32135633e-03],\n",
      "         [-9.14700888e-03, -5.18961635e-04,  4.94518958e-04, ...,\n",
      "           3.95787926e-03,  6.22053538e-03, -2.40697134e-02],\n",
      "         [-2.31497991e-03, -2.72326841e-04,  4.51084320e-03, ...,\n",
      "          -2.46942400e-05,  1.87927170e-03, -2.83242390e-02]]]],\n",
      "      dtype=float32)]\n",
      "conv_22 [array([[[[ 1.18581993e-04,  2.48279830e-04, -1.86559919e-03, ...,\n",
      "           2.59334594e-03,  3.16396705e-03,  7.28049036e-03],\n",
      "         [ 7.36311078e-03,  2.66817544e-04, -1.43340870e-03, ...,\n",
      "           1.07974699e-03, -7.09927315e-03,  3.97759723e-03],\n",
      "         [ 7.07593979e-04, -2.27387573e-04, -1.03089660e-02, ...,\n",
      "           3.87784885e-03,  8.05787463e-03, -6.13195635e-03],\n",
      "         ...,\n",
      "         [-2.03591888e-03, -6.62303864e-05, -1.55126620e-02, ...,\n",
      "           2.40077497e-03,  1.68620758e-02, -1.46154547e-02],\n",
      "         [ 7.80685712e-03, -1.07719796e-04, -8.86100624e-03, ...,\n",
      "           3.48054874e-03,  1.17712682e-02,  1.16520980e-02],\n",
      "         [-4.41617798e-03,  8.88234281e-05, -1.14219580e-02, ...,\n",
      "          -8.29833443e-04, -1.60523341e-03,  9.66203492e-03]],\n",
      "\n",
      "        [[-1.54900388e-03,  3.34518081e-05,  1.81080010e-02, ...,\n",
      "           1.92388345e-03, -3.92573001e-03, -1.10568227e-02],\n",
      "         [ 1.87070982e-03, -2.58582761e-04, -3.94849456e-04, ...,\n",
      "          -3.41671938e-03,  5.71859302e-04, -1.13805840e-02],\n",
      "         [ 1.02782669e-03,  1.37567098e-04,  8.65479838e-03, ...,\n",
      "           2.94697849e-04, -1.74272805e-03,  1.19862929e-02],\n",
      "         ...,\n",
      "         [ 4.56449529e-03,  6.45158361e-05,  2.37380169e-04, ...,\n",
      "          -3.55792465e-03,  2.72310979e-04,  1.67192926e-03],\n",
      "         [ 4.95763496e-03, -2.85520655e-04,  1.33703044e-02, ...,\n",
      "          -5.80826774e-04, -3.40195536e-03,  1.85759517e-03],\n",
      "         [ 1.90062122e-03, -2.41057875e-04,  1.68392658e-02, ...,\n",
      "          -1.05993764e-03, -2.39924621e-03, -6.57606451e-03]],\n",
      "\n",
      "        [[ 8.82512052e-03, -8.13430177e-07,  8.36843159e-03, ...,\n",
      "           1.94282795e-03,  1.01329917e-02,  5.08717028e-03],\n",
      "         [ 1.81005406e-03, -1.85635930e-04, -9.96936299e-03, ...,\n",
      "          -1.57548027e-04,  7.86434021e-03, -1.33555429e-03],\n",
      "         [-9.71333124e-03, -8.73180907e-05,  3.43780126e-03, ...,\n",
      "          -2.08497094e-03,  1.41872931e-02, -5.27398475e-03],\n",
      "         ...,\n",
      "         [-3.87702207e-03, -9.18133665e-05,  1.76963452e-02, ...,\n",
      "           4.06855391e-03, -1.66952703e-02, -2.37050839e-03],\n",
      "         [-9.95578151e-03, -6.17532278e-05, -1.07429754e-02, ...,\n",
      "          -3.72743281e-03, -1.37128327e-02, -1.03020743e-02],\n",
      "         [ 8.95293429e-03,  2.18444067e-04, -1.28030619e-02, ...,\n",
      "           4.02297080e-03,  1.29775063e-03, -4.85693989e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 3.26212705e-03, -6.96222633e-05,  1.12193599e-02, ...,\n",
      "           1.70812593e-03,  9.97332670e-03, -2.12442726e-02],\n",
      "         [-8.65436252e-03,  1.94202934e-04,  1.69499777e-02, ...,\n",
      "          -3.99611099e-03,  1.26310969e-02, -1.61563959e-02],\n",
      "         [-5.43539040e-03, -2.78228050e-04,  4.82750451e-03, ...,\n",
      "          -2.03772169e-03,  1.64242964e-02,  4.25700657e-03],\n",
      "         ...,\n",
      "         [-4.52500721e-03, -2.25810727e-04, -1.66247021e-02, ...,\n",
      "          -5.92449855e-04,  6.79299422e-03, -4.43693763e-03],\n",
      "         [-6.33242133e-04, -1.82970671e-05,  1.47824716e-02, ...,\n",
      "          -4.43021487e-03,  8.46155547e-03, -8.89572222e-03],\n",
      "         [ 6.29670452e-03,  4.48597784e-05, -1.45957312e-02, ...,\n",
      "          -2.52355216e-03, -5.35643566e-03,  1.47686945e-03]],\n",
      "\n",
      "        [[-6.95596822e-03, -5.16276705e-05, -1.44792609e-02, ...,\n",
      "          -3.26095847e-03, -1.04014501e-02,  5.73464297e-03],\n",
      "         [-8.35372880e-03,  2.80951732e-04,  1.40663553e-02, ...,\n",
      "           1.44515862e-03, -1.26584549e-03, -1.33604491e-02],\n",
      "         [-5.61830029e-03,  8.72778546e-05, -8.66893493e-03, ...,\n",
      "           3.00615467e-03,  1.67447720e-02,  3.29600694e-03],\n",
      "         ...,\n",
      "         [ 8.93606711e-03, -2.25737691e-04, -1.04331896e-02, ...,\n",
      "           3.31783970e-03, -9.00409743e-03,  1.53356069e-03],\n",
      "         [ 6.91589946e-03,  8.45141476e-05,  5.71198715e-03, ...,\n",
      "           4.23256168e-03,  8.69992282e-03,  2.63661583e-04],\n",
      "         [-4.09054523e-03,  1.09605346e-04,  2.57986528e-03, ...,\n",
      "          -1.51695486e-03,  2.00467817e-02,  9.53484967e-04]],\n",
      "\n",
      "        [[ 8.70699249e-03,  1.28693966e-04, -6.95115596e-04, ...,\n",
      "          -1.75612047e-03, -5.64728165e-03,  9.42204241e-03],\n",
      "         [ 1.36143074e-03, -2.39515299e-04,  1.77596696e-02, ...,\n",
      "          -1.13052875e-03,  1.57201495e-02, -1.42651377e-02],\n",
      "         [ 3.36074480e-03, -2.20472648e-04, -8.18714593e-03, ...,\n",
      "           3.34749836e-03, -9.40494426e-03,  1.51630938e-02],\n",
      "         ...,\n",
      "         [ 7.74247712e-03, -3.27923626e-05, -6.32194895e-03, ...,\n",
      "          -1.29670976e-03,  5.58928913e-03,  1.32408575e-03],\n",
      "         [-3.04019614e-03,  4.45023543e-05,  1.69713739e-02, ...,\n",
      "          -3.21962143e-04, -1.45881614e-02,  1.49847874e-02],\n",
      "         [-6.58340659e-03, -5.87514987e-05, -1.72241442e-02, ...,\n",
      "           1.91782147e-03,  6.16982405e-04, -3.69801046e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 1.47590355e-03,  1.96934730e-06, -1.39740054e-02, ...,\n",
      "           2.60289852e-03,  2.08581239e-03,  1.29707763e-02],\n",
      "         [-8.56023096e-03,  1.72638698e-04, -1.12887798e-02, ...,\n",
      "          -3.33722169e-03, -6.85968110e-03, -7.73816649e-03],\n",
      "         [-2.95717386e-03,  2.57939333e-04,  1.36067206e-02, ...,\n",
      "          -2.36370275e-03, -5.63718518e-03, -5.61792264e-03],\n",
      "         ...,\n",
      "         [-1.53670949e-03, -2.33234623e-05, -8.63989722e-03, ...,\n",
      "          -2.58138520e-03,  1.16008418e-02,  1.24219281e-03],\n",
      "         [-1.95960863e-03,  9.77632444e-05,  7.88886659e-03, ...,\n",
      "          -1.22716732e-03,  5.99193666e-03,  3.15939367e-04],\n",
      "         [ 4.80748154e-03,  2.90497585e-04,  4.83706594e-03, ...,\n",
      "          -1.21264509e-03, -7.34373787e-03,  1.75064709e-03]],\n",
      "\n",
      "        [[-6.77746627e-03, -2.12097671e-04,  9.50391497e-03, ...,\n",
      "          -3.14070866e-03, -1.74745154e-02, -1.22727163e-03],\n",
      "         [-7.68756145e-04,  1.64022655e-04, -2.42404130e-05, ...,\n",
      "           3.93916480e-03,  1.48549732e-02,  4.22349753e-04],\n",
      "         [-4.86888981e-04, -7.29995809e-05,  2.05513630e-02, ...,\n",
      "          -7.55547535e-06,  1.66130904e-02,  1.75328273e-02],\n",
      "         ...,\n",
      "         [-6.59152167e-03, -6.35396464e-06, -1.20702982e-02, ...,\n",
      "          -1.97481969e-03, -1.36443255e-02,  7.93736242e-03],\n",
      "         [ 1.43537989e-06, -2.44783703e-04,  2.13156035e-03, ...,\n",
      "           4.31431504e-03, -9.01437830e-03,  5.37873851e-03],\n",
      "         [ 5.35578467e-03, -2.69346288e-04, -1.33180656e-02, ...,\n",
      "          -3.27057554e-03, -6.08109287e-04, -7.64988316e-03]],\n",
      "\n",
      "        [[ 7.95293320e-03,  2.53586593e-04,  1.40665993e-02, ...,\n",
      "           6.93549460e-04,  1.10631566e-02,  5.30531816e-03],\n",
      "         [ 1.60284678e-03,  1.46324208e-04, -1.60600338e-02, ...,\n",
      "          -3.58515978e-03, -5.27456542e-03,  1.22519555e-02],\n",
      "         [-1.07696746e-03, -9.60662510e-05,  1.47976577e-02, ...,\n",
      "           2.10389029e-03,  1.01266289e-02, -1.72071019e-03],\n",
      "         ...,\n",
      "         [-9.77524370e-03,  2.73419981e-04,  1.12990895e-03, ...,\n",
      "          -4.37125622e-04, -8.69980175e-03, -1.20781697e-02],\n",
      "         [ 5.56268846e-04,  1.80935618e-04,  6.20213198e-03, ...,\n",
      "          -3.18168220e-03,  1.14184646e-02,  1.54538208e-03],\n",
      "         [ 7.04762060e-03, -9.49744208e-06, -2.29963083e-02, ...,\n",
      "          -3.15632066e-03,  4.10670415e-03,  1.24538997e-02]]]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "count = -1\n",
    "for layer in model.layers:\n",
    "    if len(layer.get_weights())==1:\n",
    "        print(layer.name, layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89a32b26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv_1\n",
      "(1, 3, 3, 3, 32)\n",
      "(3, 3, 3, 32)\n",
      "1 conv_2\n",
      "(1, 3, 3, 32, 64)\n",
      "(3, 3, 32, 64)\n",
      "2 conv_3\n",
      "(1, 3, 3, 64, 128)\n",
      "(3, 3, 64, 128)\n",
      "3 conv_4\n",
      "(1, 1, 1, 128, 64)\n",
      "(1, 1, 128, 64)\n",
      "4 conv_5\n",
      "(1, 3, 3, 64, 128)\n",
      "(3, 3, 64, 128)\n",
      "5 conv_6\n",
      "(1, 3, 3, 128, 256)\n",
      "(3, 3, 128, 256)\n",
      "6 conv_7\n",
      "(1, 1, 1, 256, 128)\n",
      "(1, 1, 256, 128)\n",
      "7 conv_8\n",
      "(1, 3, 3, 128, 256)\n",
      "(3, 3, 128, 256)\n",
      "8 conv_9\n",
      "(1, 3, 3, 256, 512)\n",
      "(3, 3, 256, 512)\n",
      "9 conv_10\n",
      "(1, 1, 1, 512, 256)\n",
      "(1, 1, 512, 256)\n",
      "10 conv_11\n",
      "(1, 3, 3, 256, 512)\n",
      "(3, 3, 256, 512)\n",
      "11 conv_12\n",
      "(1, 1, 1, 512, 256)\n",
      "(1, 1, 512, 256)\n",
      "12 conv_13\n",
      "(1, 3, 3, 256, 512)\n",
      "(3, 3, 256, 512)\n",
      "13 conv_14\n",
      "(1, 3, 3, 512, 1024)\n",
      "(3, 3, 512, 1024)\n",
      "14 conv_15\n",
      "(1, 1, 1, 1024, 512)\n",
      "(1, 1, 1024, 512)\n",
      "15 conv_16\n",
      "(1, 3, 3, 512, 1024)\n",
      "(3, 3, 512, 1024)\n",
      "16 conv_17\n",
      "(1, 1, 1, 1024, 512)\n",
      "(1, 1, 1024, 512)\n",
      "17 conv_18\n",
      "(1, 3, 3, 512, 1024)\n",
      "(3, 3, 512, 1024)\n",
      "18 conv_19\n",
      "(1, 3, 3, 1024, 1024)\n",
      "(3, 3, 1024, 1024)\n",
      "19 conv_21\n",
      "(1, 1, 1, 512, 64)\n",
      "(1, 1, 512, 64)\n",
      "20 conv_20\n",
      "(1, 3, 3, 1024, 1024)\n",
      "(3, 3, 1024, 1024)\n",
      "21 conv_22\n",
      "(1, 3, 3, 1280, 1024)\n",
      "(3, 3, 1280, 1024)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "count = -1\n",
    "for layer in model.layers:\n",
    "    if len(layer.get_weights())>0:\n",
    "        #print(len(layer.get_weights()))\n",
    "        #print(len(weights_new[count]))\n",
    "        if len(layer.get_weights())==1:\n",
    "            count += 1\n",
    "            print(count,layer.name)\n",
    "            print(np.shape(layer.get_weights()))\n",
    "            print(np.shape(weights_new[count]))\n",
    "            layer.set_weights([weights_new[count]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5cff30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save('yolo_relu_latest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af63db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_W             = 13\n",
    "GRID_H             = 13\n",
    "BATCH_SIZE         = 34\n",
    "LAMBDA_NO_OBJECT = 1.0\n",
    "LAMBDA_OBJECT    = 5.0\n",
    "LAMBDA_COORD     = 1.0\n",
    "LAMBDA_CLASS     = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "044ffd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26038239",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0804200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 416, 416, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 416, 416, 32) 864         input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 416, 416, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 416, 416, 32) 0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_416to208 (MaxPooling2D (None, 208, 208, 32) 0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 208, 208, 64) 18432       maxpool1_416to208[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 208, 208, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 208, 208, 64) 0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_208to104 (MaxPooling2D (None, 104, 104, 64) 0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 104, 104, 128 73728       maxpool1_208to104[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 104, 104, 128 512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 104, 104, 128 0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 104, 104, 64) 8192        re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 104, 104, 64) 256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 104, 104, 64) 0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 104, 104, 128 73728       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 104, 104, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 104, 104, 128 0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_104to52 (MaxPooling2D) (None, 52, 52, 128)  0           re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 52, 52, 256)  294912      maxpool1_104to52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 52, 52, 256)  0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 52, 52, 128)  32768       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 52, 52, 128)  512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 52, 52, 128)  0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 52, 52, 256)  294912      re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 52, 52, 256)  0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_52to26 (MaxPooling2D)  (None, 26, 26, 256)  0           re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 26, 26, 512)  1179648     maxpool1_52to26[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)     (None, 26, 26, 512)  2048        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 26, 26, 512)  0           norm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 26, 26, 256)  131072      re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 26, 26, 256)  0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 26, 26, 512)  1179648     re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 26, 26, 512)  0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 26, 26, 256)  131072      re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 26, 26, 256)  0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 26, 26, 512)  1179648     re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 26, 26, 512)  0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1_26to13 (MaxPooling2D)  (None, 13, 13, 512)  0           re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 13, 13, 1024) 4718592     maxpool1_26to13[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 13, 13, 1024) 0           norm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 13, 13, 512)  524288      re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 13, 13, 512)  0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 13, 13, 1024) 4718592     re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 13, 13, 1024) 0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 13, 13, 512)  524288      re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 13, 13, 512)  0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 13, 13, 1024) 4718592     re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 13, 13, 1024) 0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 13, 13, 1024) 9437184     re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 26, 26, 64)   32768       re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 13, 13, 1024) 0           norm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 26, 26, 64)   256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 13, 13, 1024) 9437184     re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 26, 26, 64)   0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 13, 13, 256)  0           re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 13, 13, 1024) 0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 13, 13, 1280) 0           lambda[0][0]                     \n",
      "                                                                 re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 13, 13, 1024) 11796480    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 13, 13, 1024) 0           norm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 13, 13, 125)  128125      re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Reshape)          (None, 13, 13, 5, 25 0           conv_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_hack (InputLayer)         [(None, 1, 1, 1, 50, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hack_layer (Lambda)             (None, 13, 13, 5, 25 0           final_output[0][0]               \n",
      "                                                                 input_hack[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 50,676,061\n",
      "Trainable params: 128,125\n",
      "Non-trainable params: 50,547,936\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "new_model = tf.keras.models.load_model('yolo_relu.h5', custom_objects={\"custom_loss\":custom_loss_core})\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5852b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(loss=custom_loss, optimizer=optimizer, metrics=[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c3d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591951c4",
   "metadata": {},
   "source": [
    "### Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "064ccb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.framework import tensor_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6280f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.gfile.GFile(\"/home/dell/Documents/pretrained_models/resnet50_v1.pb\",'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4369c9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step Const []\n",
      "input_tensor Placeholder []\n",
      "resnet_model/Pad/paddings Const []\n",
      "resnet_model/Pad Pad ['input_tensor', 'resnet_model/Pad/paddings']\n",
      "resnet_model/conv2d/kernel Const []\n",
      "resnet_model/conv2d/kernel/read Identity ['resnet_model/conv2d/kernel']\n",
      "resnet_model/conv2d/Conv2D Conv2D ['resnet_model/Pad', 'resnet_model/conv2d/kernel/read']\n",
      "resnet_model/initial_conv Identity ['resnet_model/conv2d/Conv2D']\n",
      "resnet_model/batch_normalization/gamma Const []\n",
      "resnet_model/batch_normalization/gamma/read Identity ['resnet_model/batch_normalization/gamma']\n",
      "resnet_model/batch_normalization/beta Const []\n",
      "resnet_model/batch_normalization/beta/read Identity ['resnet_model/batch_normalization/beta']\n",
      "resnet_model/batch_normalization/moving_mean Const []\n",
      "resnet_model/batch_normalization/moving_mean/read Identity ['resnet_model/batch_normalization/moving_mean']\n",
      "resnet_model/batch_normalization/moving_variance Const []\n",
      "resnet_model/batch_normalization/moving_variance/read Identity ['resnet_model/batch_normalization/moving_variance']\n",
      "resnet_model/batch_normalization/FusedBatchNorm FusedBatchNorm ['resnet_model/initial_conv', 'resnet_model/batch_normalization/gamma/read', 'resnet_model/batch_normalization/beta/read', 'resnet_model/batch_normalization/moving_mean/read', 'resnet_model/batch_normalization/moving_variance/read']\n",
      "resnet_model/Relu Relu ['resnet_model/batch_normalization/FusedBatchNorm']\n",
      "resnet_model/max_pooling2d/MaxPool MaxPool ['resnet_model/Relu']\n",
      "resnet_model/initial_max_pool Identity ['resnet_model/max_pooling2d/MaxPool']\n",
      "resnet_model/conv2d_1/kernel Const []\n",
      "resnet_model/conv2d_1/kernel/read Identity ['resnet_model/conv2d_1/kernel']\n",
      "resnet_model/conv2d_1/Conv2D Conv2D ['resnet_model/initial_max_pool', 'resnet_model/conv2d_1/kernel/read']\n",
      "resnet_model/batch_normalization_1/gamma Const []\n",
      "resnet_model/batch_normalization_1/gamma/read Identity ['resnet_model/batch_normalization_1/gamma']\n",
      "resnet_model/batch_normalization_1/beta Const []\n",
      "resnet_model/batch_normalization_1/beta/read Identity ['resnet_model/batch_normalization_1/beta']\n",
      "resnet_model/batch_normalization_1/moving_mean Const []\n",
      "resnet_model/batch_normalization_1/moving_mean/read Identity ['resnet_model/batch_normalization_1/moving_mean']\n",
      "resnet_model/batch_normalization_1/moving_variance Const []\n",
      "resnet_model/batch_normalization_1/moving_variance/read Identity ['resnet_model/batch_normalization_1/moving_variance']\n",
      "resnet_model/batch_normalization_1/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_1/Conv2D', 'resnet_model/batch_normalization_1/gamma/read', 'resnet_model/batch_normalization_1/beta/read', 'resnet_model/batch_normalization_1/moving_mean/read', 'resnet_model/batch_normalization_1/moving_variance/read']\n",
      "resnet_model/conv2d_2/kernel Const []\n",
      "resnet_model/conv2d_2/kernel/read Identity ['resnet_model/conv2d_2/kernel']\n",
      "resnet_model/conv2d_2/Conv2D Conv2D ['resnet_model/initial_max_pool', 'resnet_model/conv2d_2/kernel/read']\n",
      "resnet_model/batch_normalization_2/gamma Const []\n",
      "resnet_model/batch_normalization_2/gamma/read Identity ['resnet_model/batch_normalization_2/gamma']\n",
      "resnet_model/batch_normalization_2/beta Const []\n",
      "resnet_model/batch_normalization_2/beta/read Identity ['resnet_model/batch_normalization_2/beta']\n",
      "resnet_model/batch_normalization_2/moving_mean Const []\n",
      "resnet_model/batch_normalization_2/moving_mean/read Identity ['resnet_model/batch_normalization_2/moving_mean']\n",
      "resnet_model/batch_normalization_2/moving_variance Const []\n",
      "resnet_model/batch_normalization_2/moving_variance/read Identity ['resnet_model/batch_normalization_2/moving_variance']\n",
      "resnet_model/batch_normalization_2/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_2/Conv2D', 'resnet_model/batch_normalization_2/gamma/read', 'resnet_model/batch_normalization_2/beta/read', 'resnet_model/batch_normalization_2/moving_mean/read', 'resnet_model/batch_normalization_2/moving_variance/read']\n",
      "resnet_model/Relu_1 Relu ['resnet_model/batch_normalization_2/FusedBatchNorm']\n",
      "resnet_model/conv2d_3/kernel Const []\n",
      "resnet_model/conv2d_3/kernel/read Identity ['resnet_model/conv2d_3/kernel']\n",
      "resnet_model/conv2d_3/Conv2D Conv2D ['resnet_model/Relu_1', 'resnet_model/conv2d_3/kernel/read']\n",
      "resnet_model/batch_normalization_3/gamma Const []\n",
      "resnet_model/batch_normalization_3/gamma/read Identity ['resnet_model/batch_normalization_3/gamma']\n",
      "resnet_model/batch_normalization_3/beta Const []\n",
      "resnet_model/batch_normalization_3/beta/read Identity ['resnet_model/batch_normalization_3/beta']\n",
      "resnet_model/batch_normalization_3/moving_mean Const []\n",
      "resnet_model/batch_normalization_3/moving_mean/read Identity ['resnet_model/batch_normalization_3/moving_mean']\n",
      "resnet_model/batch_normalization_3/moving_variance Const []\n",
      "resnet_model/batch_normalization_3/moving_variance/read Identity ['resnet_model/batch_normalization_3/moving_variance']\n",
      "resnet_model/batch_normalization_3/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_3/Conv2D', 'resnet_model/batch_normalization_3/gamma/read', 'resnet_model/batch_normalization_3/beta/read', 'resnet_model/batch_normalization_3/moving_mean/read', 'resnet_model/batch_normalization_3/moving_variance/read']\n",
      "resnet_model/Relu_2 Relu ['resnet_model/batch_normalization_3/FusedBatchNorm']\n",
      "resnet_model/conv2d_4/kernel Const []\n",
      "resnet_model/conv2d_4/kernel/read Identity ['resnet_model/conv2d_4/kernel']\n",
      "resnet_model/conv2d_4/Conv2D Conv2D ['resnet_model/Relu_2', 'resnet_model/conv2d_4/kernel/read']\n",
      "resnet_model/batch_normalization_4/gamma Const []\n",
      "resnet_model/batch_normalization_4/gamma/read Identity ['resnet_model/batch_normalization_4/gamma']\n",
      "resnet_model/batch_normalization_4/beta Const []\n",
      "resnet_model/batch_normalization_4/beta/read Identity ['resnet_model/batch_normalization_4/beta']\n",
      "resnet_model/batch_normalization_4/moving_mean Const []\n",
      "resnet_model/batch_normalization_4/moving_mean/read Identity ['resnet_model/batch_normalization_4/moving_mean']\n",
      "resnet_model/batch_normalization_4/moving_variance Const []\n",
      "resnet_model/batch_normalization_4/moving_variance/read Identity ['resnet_model/batch_normalization_4/moving_variance']\n",
      "resnet_model/batch_normalization_4/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_4/Conv2D', 'resnet_model/batch_normalization_4/gamma/read', 'resnet_model/batch_normalization_4/beta/read', 'resnet_model/batch_normalization_4/moving_mean/read', 'resnet_model/batch_normalization_4/moving_variance/read']\n",
      "resnet_model/add Add ['resnet_model/batch_normalization_4/FusedBatchNorm', 'resnet_model/batch_normalization_1/FusedBatchNorm']\n",
      "resnet_model/Relu_3 Relu ['resnet_model/add']\n",
      "resnet_model/conv2d_5/kernel Const []\n",
      "resnet_model/conv2d_5/kernel/read Identity ['resnet_model/conv2d_5/kernel']\n",
      "resnet_model/conv2d_5/Conv2D Conv2D ['resnet_model/Relu_3', 'resnet_model/conv2d_5/kernel/read']\n",
      "resnet_model/batch_normalization_5/gamma Const []\n",
      "resnet_model/batch_normalization_5/gamma/read Identity ['resnet_model/batch_normalization_5/gamma']\n",
      "resnet_model/batch_normalization_5/beta Const []\n",
      "resnet_model/batch_normalization_5/beta/read Identity ['resnet_model/batch_normalization_5/beta']\n",
      "resnet_model/batch_normalization_5/moving_mean Const []\n",
      "resnet_model/batch_normalization_5/moving_mean/read Identity ['resnet_model/batch_normalization_5/moving_mean']\n",
      "resnet_model/batch_normalization_5/moving_variance Const []\n",
      "resnet_model/batch_normalization_5/moving_variance/read Identity ['resnet_model/batch_normalization_5/moving_variance']\n",
      "resnet_model/batch_normalization_5/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_5/Conv2D', 'resnet_model/batch_normalization_5/gamma/read', 'resnet_model/batch_normalization_5/beta/read', 'resnet_model/batch_normalization_5/moving_mean/read', 'resnet_model/batch_normalization_5/moving_variance/read']\n",
      "resnet_model/Relu_4 Relu ['resnet_model/batch_normalization_5/FusedBatchNorm']\n",
      "resnet_model/conv2d_6/kernel Const []\n",
      "resnet_model/conv2d_6/kernel/read Identity ['resnet_model/conv2d_6/kernel']\n",
      "resnet_model/conv2d_6/Conv2D Conv2D ['resnet_model/Relu_4', 'resnet_model/conv2d_6/kernel/read']\n",
      "resnet_model/batch_normalization_6/gamma Const []\n",
      "resnet_model/batch_normalization_6/gamma/read Identity ['resnet_model/batch_normalization_6/gamma']\n",
      "resnet_model/batch_normalization_6/beta Const []\n",
      "resnet_model/batch_normalization_6/beta/read Identity ['resnet_model/batch_normalization_6/beta']\n",
      "resnet_model/batch_normalization_6/moving_mean Const []\n",
      "resnet_model/batch_normalization_6/moving_mean/read Identity ['resnet_model/batch_normalization_6/moving_mean']\n",
      "resnet_model/batch_normalization_6/moving_variance Const []\n",
      "resnet_model/batch_normalization_6/moving_variance/read Identity ['resnet_model/batch_normalization_6/moving_variance']\n",
      "resnet_model/batch_normalization_6/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_6/Conv2D', 'resnet_model/batch_normalization_6/gamma/read', 'resnet_model/batch_normalization_6/beta/read', 'resnet_model/batch_normalization_6/moving_mean/read', 'resnet_model/batch_normalization_6/moving_variance/read']\n",
      "resnet_model/Relu_5 Relu ['resnet_model/batch_normalization_6/FusedBatchNorm']\n",
      "resnet_model/conv2d_7/kernel Const []\n",
      "resnet_model/conv2d_7/kernel/read Identity ['resnet_model/conv2d_7/kernel']\n",
      "resnet_model/conv2d_7/Conv2D Conv2D ['resnet_model/Relu_5', 'resnet_model/conv2d_7/kernel/read']\n",
      "resnet_model/batch_normalization_7/gamma Const []\n",
      "resnet_model/batch_normalization_7/gamma/read Identity ['resnet_model/batch_normalization_7/gamma']\n",
      "resnet_model/batch_normalization_7/beta Const []\n",
      "resnet_model/batch_normalization_7/beta/read Identity ['resnet_model/batch_normalization_7/beta']\n",
      "resnet_model/batch_normalization_7/moving_mean Const []\n",
      "resnet_model/batch_normalization_7/moving_mean/read Identity ['resnet_model/batch_normalization_7/moving_mean']\n",
      "resnet_model/batch_normalization_7/moving_variance Const []\n",
      "resnet_model/batch_normalization_7/moving_variance/read Identity ['resnet_model/batch_normalization_7/moving_variance']\n",
      "resnet_model/batch_normalization_7/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_7/Conv2D', 'resnet_model/batch_normalization_7/gamma/read', 'resnet_model/batch_normalization_7/beta/read', 'resnet_model/batch_normalization_7/moving_mean/read', 'resnet_model/batch_normalization_7/moving_variance/read']\n",
      "resnet_model/add_1 Add ['resnet_model/batch_normalization_7/FusedBatchNorm', 'resnet_model/Relu_3']\n",
      "resnet_model/Relu_6 Relu ['resnet_model/add_1']\n",
      "resnet_model/conv2d_8/kernel Const []\n",
      "resnet_model/conv2d_8/kernel/read Identity ['resnet_model/conv2d_8/kernel']\n",
      "resnet_model/conv2d_8/Conv2D Conv2D ['resnet_model/Relu_6', 'resnet_model/conv2d_8/kernel/read']\n",
      "resnet_model/batch_normalization_8/gamma Const []\n",
      "resnet_model/batch_normalization_8/gamma/read Identity ['resnet_model/batch_normalization_8/gamma']\n",
      "resnet_model/batch_normalization_8/beta Const []\n",
      "resnet_model/batch_normalization_8/beta/read Identity ['resnet_model/batch_normalization_8/beta']\n",
      "resnet_model/batch_normalization_8/moving_mean Const []\n",
      "resnet_model/batch_normalization_8/moving_mean/read Identity ['resnet_model/batch_normalization_8/moving_mean']\n",
      "resnet_model/batch_normalization_8/moving_variance Const []\n",
      "resnet_model/batch_normalization_8/moving_variance/read Identity ['resnet_model/batch_normalization_8/moving_variance']\n",
      "resnet_model/batch_normalization_8/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_8/Conv2D', 'resnet_model/batch_normalization_8/gamma/read', 'resnet_model/batch_normalization_8/beta/read', 'resnet_model/batch_normalization_8/moving_mean/read', 'resnet_model/batch_normalization_8/moving_variance/read']\n",
      "resnet_model/Relu_7 Relu ['resnet_model/batch_normalization_8/FusedBatchNorm']\n",
      "resnet_model/conv2d_9/kernel Const []\n",
      "resnet_model/conv2d_9/kernel/read Identity ['resnet_model/conv2d_9/kernel']\n",
      "resnet_model/conv2d_9/Conv2D Conv2D ['resnet_model/Relu_7', 'resnet_model/conv2d_9/kernel/read']\n",
      "resnet_model/batch_normalization_9/gamma Const []\n",
      "resnet_model/batch_normalization_9/gamma/read Identity ['resnet_model/batch_normalization_9/gamma']\n",
      "resnet_model/batch_normalization_9/beta Const []\n",
      "resnet_model/batch_normalization_9/beta/read Identity ['resnet_model/batch_normalization_9/beta']\n",
      "resnet_model/batch_normalization_9/moving_mean Const []\n",
      "resnet_model/batch_normalization_9/moving_mean/read Identity ['resnet_model/batch_normalization_9/moving_mean']\n",
      "resnet_model/batch_normalization_9/moving_variance Const []\n",
      "resnet_model/batch_normalization_9/moving_variance/read Identity ['resnet_model/batch_normalization_9/moving_variance']\n",
      "resnet_model/batch_normalization_9/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_9/Conv2D', 'resnet_model/batch_normalization_9/gamma/read', 'resnet_model/batch_normalization_9/beta/read', 'resnet_model/batch_normalization_9/moving_mean/read', 'resnet_model/batch_normalization_9/moving_variance/read']\n",
      "resnet_model/Relu_8 Relu ['resnet_model/batch_normalization_9/FusedBatchNorm']\n",
      "resnet_model/conv2d_10/kernel Const []\n",
      "resnet_model/conv2d_10/kernel/read Identity ['resnet_model/conv2d_10/kernel']\n",
      "resnet_model/conv2d_10/Conv2D Conv2D ['resnet_model/Relu_8', 'resnet_model/conv2d_10/kernel/read']\n",
      "resnet_model/batch_normalization_10/gamma Const []\n",
      "resnet_model/batch_normalization_10/gamma/read Identity ['resnet_model/batch_normalization_10/gamma']\n",
      "resnet_model/batch_normalization_10/beta Const []\n",
      "resnet_model/batch_normalization_10/beta/read Identity ['resnet_model/batch_normalization_10/beta']\n",
      "resnet_model/batch_normalization_10/moving_mean Const []\n",
      "resnet_model/batch_normalization_10/moving_mean/read Identity ['resnet_model/batch_normalization_10/moving_mean']\n",
      "resnet_model/batch_normalization_10/moving_variance Const []\n",
      "resnet_model/batch_normalization_10/moving_variance/read Identity ['resnet_model/batch_normalization_10/moving_variance']\n",
      "resnet_model/batch_normalization_10/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_10/Conv2D', 'resnet_model/batch_normalization_10/gamma/read', 'resnet_model/batch_normalization_10/beta/read', 'resnet_model/batch_normalization_10/moving_mean/read', 'resnet_model/batch_normalization_10/moving_variance/read']\n",
      "resnet_model/add_2 Add ['resnet_model/batch_normalization_10/FusedBatchNorm', 'resnet_model/Relu_6']\n",
      "resnet_model/Relu_9 Relu ['resnet_model/add_2']\n",
      "resnet_model/block_layer1 Identity ['resnet_model/Relu_9']\n",
      "resnet_model/Pad_1/paddings Const []\n",
      "resnet_model/Pad_1 Pad ['resnet_model/block_layer1', 'resnet_model/Pad_1/paddings']\n",
      "resnet_model/conv2d_11/kernel Const []\n",
      "resnet_model/conv2d_11/kernel/read Identity ['resnet_model/conv2d_11/kernel']\n",
      "resnet_model/conv2d_11/Conv2D Conv2D ['resnet_model/Pad_1', 'resnet_model/conv2d_11/kernel/read']\n",
      "resnet_model/batch_normalization_11/gamma Const []\n",
      "resnet_model/batch_normalization_11/gamma/read Identity ['resnet_model/batch_normalization_11/gamma']\n",
      "resnet_model/batch_normalization_11/beta Const []\n",
      "resnet_model/batch_normalization_11/beta/read Identity ['resnet_model/batch_normalization_11/beta']\n",
      "resnet_model/batch_normalization_11/moving_mean Const []\n",
      "resnet_model/batch_normalization_11/moving_mean/read Identity ['resnet_model/batch_normalization_11/moving_mean']\n",
      "resnet_model/batch_normalization_11/moving_variance Const []\n",
      "resnet_model/batch_normalization_11/moving_variance/read Identity ['resnet_model/batch_normalization_11/moving_variance']\n",
      "resnet_model/batch_normalization_11/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_11/Conv2D', 'resnet_model/batch_normalization_11/gamma/read', 'resnet_model/batch_normalization_11/beta/read', 'resnet_model/batch_normalization_11/moving_mean/read', 'resnet_model/batch_normalization_11/moving_variance/read']\n",
      "resnet_model/conv2d_12/kernel Const []\n",
      "resnet_model/conv2d_12/kernel/read Identity ['resnet_model/conv2d_12/kernel']\n",
      "resnet_model/conv2d_12/Conv2D Conv2D ['resnet_model/block_layer1', 'resnet_model/conv2d_12/kernel/read']\n",
      "resnet_model/batch_normalization_12/gamma Const []\n",
      "resnet_model/batch_normalization_12/gamma/read Identity ['resnet_model/batch_normalization_12/gamma']\n",
      "resnet_model/batch_normalization_12/beta Const []\n",
      "resnet_model/batch_normalization_12/beta/read Identity ['resnet_model/batch_normalization_12/beta']\n",
      "resnet_model/batch_normalization_12/moving_mean Const []\n",
      "resnet_model/batch_normalization_12/moving_mean/read Identity ['resnet_model/batch_normalization_12/moving_mean']\n",
      "resnet_model/batch_normalization_12/moving_variance Const []\n",
      "resnet_model/batch_normalization_12/moving_variance/read Identity ['resnet_model/batch_normalization_12/moving_variance']\n",
      "resnet_model/batch_normalization_12/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_12/Conv2D', 'resnet_model/batch_normalization_12/gamma/read', 'resnet_model/batch_normalization_12/beta/read', 'resnet_model/batch_normalization_12/moving_mean/read', 'resnet_model/batch_normalization_12/moving_variance/read']\n",
      "resnet_model/Relu_10 Relu ['resnet_model/batch_normalization_12/FusedBatchNorm']\n",
      "resnet_model/Pad_2/paddings Const []\n",
      "resnet_model/Pad_2 Pad ['resnet_model/Relu_10', 'resnet_model/Pad_2/paddings']\n",
      "resnet_model/conv2d_13/kernel Const []\n",
      "resnet_model/conv2d_13/kernel/read Identity ['resnet_model/conv2d_13/kernel']\n",
      "resnet_model/conv2d_13/Conv2D Conv2D ['resnet_model/Pad_2', 'resnet_model/conv2d_13/kernel/read']\n",
      "resnet_model/batch_normalization_13/gamma Const []\n",
      "resnet_model/batch_normalization_13/gamma/read Identity ['resnet_model/batch_normalization_13/gamma']\n",
      "resnet_model/batch_normalization_13/beta Const []\n",
      "resnet_model/batch_normalization_13/beta/read Identity ['resnet_model/batch_normalization_13/beta']\n",
      "resnet_model/batch_normalization_13/moving_mean Const []\n",
      "resnet_model/batch_normalization_13/moving_mean/read Identity ['resnet_model/batch_normalization_13/moving_mean']\n",
      "resnet_model/batch_normalization_13/moving_variance Const []\n",
      "resnet_model/batch_normalization_13/moving_variance/read Identity ['resnet_model/batch_normalization_13/moving_variance']\n",
      "resnet_model/batch_normalization_13/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_13/Conv2D', 'resnet_model/batch_normalization_13/gamma/read', 'resnet_model/batch_normalization_13/beta/read', 'resnet_model/batch_normalization_13/moving_mean/read', 'resnet_model/batch_normalization_13/moving_variance/read']\n",
      "resnet_model/Relu_11 Relu ['resnet_model/batch_normalization_13/FusedBatchNorm']\n",
      "resnet_model/conv2d_14/kernel Const []\n",
      "resnet_model/conv2d_14/kernel/read Identity ['resnet_model/conv2d_14/kernel']\n",
      "resnet_model/conv2d_14/Conv2D Conv2D ['resnet_model/Relu_11', 'resnet_model/conv2d_14/kernel/read']\n",
      "resnet_model/batch_normalization_14/gamma Const []\n",
      "resnet_model/batch_normalization_14/gamma/read Identity ['resnet_model/batch_normalization_14/gamma']\n",
      "resnet_model/batch_normalization_14/beta Const []\n",
      "resnet_model/batch_normalization_14/beta/read Identity ['resnet_model/batch_normalization_14/beta']\n",
      "resnet_model/batch_normalization_14/moving_mean Const []\n",
      "resnet_model/batch_normalization_14/moving_mean/read Identity ['resnet_model/batch_normalization_14/moving_mean']\n",
      "resnet_model/batch_normalization_14/moving_variance Const []\n",
      "resnet_model/batch_normalization_14/moving_variance/read Identity ['resnet_model/batch_normalization_14/moving_variance']\n",
      "resnet_model/batch_normalization_14/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_14/Conv2D', 'resnet_model/batch_normalization_14/gamma/read', 'resnet_model/batch_normalization_14/beta/read', 'resnet_model/batch_normalization_14/moving_mean/read', 'resnet_model/batch_normalization_14/moving_variance/read']\n",
      "resnet_model/add_3 Add ['resnet_model/batch_normalization_14/FusedBatchNorm', 'resnet_model/batch_normalization_11/FusedBatchNorm']\n",
      "resnet_model/Relu_12 Relu ['resnet_model/add_3']\n",
      "resnet_model/conv2d_15/kernel Const []\n",
      "resnet_model/conv2d_15/kernel/read Identity ['resnet_model/conv2d_15/kernel']\n",
      "resnet_model/conv2d_15/Conv2D Conv2D ['resnet_model/Relu_12', 'resnet_model/conv2d_15/kernel/read']\n",
      "resnet_model/batch_normalization_15/gamma Const []\n",
      "resnet_model/batch_normalization_15/gamma/read Identity ['resnet_model/batch_normalization_15/gamma']\n",
      "resnet_model/batch_normalization_15/beta Const []\n",
      "resnet_model/batch_normalization_15/beta/read Identity ['resnet_model/batch_normalization_15/beta']\n",
      "resnet_model/batch_normalization_15/moving_mean Const []\n",
      "resnet_model/batch_normalization_15/moving_mean/read Identity ['resnet_model/batch_normalization_15/moving_mean']\n",
      "resnet_model/batch_normalization_15/moving_variance Const []\n",
      "resnet_model/batch_normalization_15/moving_variance/read Identity ['resnet_model/batch_normalization_15/moving_variance']\n",
      "resnet_model/batch_normalization_15/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_15/Conv2D', 'resnet_model/batch_normalization_15/gamma/read', 'resnet_model/batch_normalization_15/beta/read', 'resnet_model/batch_normalization_15/moving_mean/read', 'resnet_model/batch_normalization_15/moving_variance/read']\n",
      "resnet_model/Relu_13 Relu ['resnet_model/batch_normalization_15/FusedBatchNorm']\n",
      "resnet_model/conv2d_16/kernel Const []\n",
      "resnet_model/conv2d_16/kernel/read Identity ['resnet_model/conv2d_16/kernel']\n",
      "resnet_model/conv2d_16/Conv2D Conv2D ['resnet_model/Relu_13', 'resnet_model/conv2d_16/kernel/read']\n",
      "resnet_model/batch_normalization_16/gamma Const []\n",
      "resnet_model/batch_normalization_16/gamma/read Identity ['resnet_model/batch_normalization_16/gamma']\n",
      "resnet_model/batch_normalization_16/beta Const []\n",
      "resnet_model/batch_normalization_16/beta/read Identity ['resnet_model/batch_normalization_16/beta']\n",
      "resnet_model/batch_normalization_16/moving_mean Const []\n",
      "resnet_model/batch_normalization_16/moving_mean/read Identity ['resnet_model/batch_normalization_16/moving_mean']\n",
      "resnet_model/batch_normalization_16/moving_variance Const []\n",
      "resnet_model/batch_normalization_16/moving_variance/read Identity ['resnet_model/batch_normalization_16/moving_variance']\n",
      "resnet_model/batch_normalization_16/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_16/Conv2D', 'resnet_model/batch_normalization_16/gamma/read', 'resnet_model/batch_normalization_16/beta/read', 'resnet_model/batch_normalization_16/moving_mean/read', 'resnet_model/batch_normalization_16/moving_variance/read']\n",
      "resnet_model/Relu_14 Relu ['resnet_model/batch_normalization_16/FusedBatchNorm']\n",
      "resnet_model/conv2d_17/kernel Const []\n",
      "resnet_model/conv2d_17/kernel/read Identity ['resnet_model/conv2d_17/kernel']\n",
      "resnet_model/conv2d_17/Conv2D Conv2D ['resnet_model/Relu_14', 'resnet_model/conv2d_17/kernel/read']\n",
      "resnet_model/batch_normalization_17/gamma Const []\n",
      "resnet_model/batch_normalization_17/gamma/read Identity ['resnet_model/batch_normalization_17/gamma']\n",
      "resnet_model/batch_normalization_17/beta Const []\n",
      "resnet_model/batch_normalization_17/beta/read Identity ['resnet_model/batch_normalization_17/beta']\n",
      "resnet_model/batch_normalization_17/moving_mean Const []\n",
      "resnet_model/batch_normalization_17/moving_mean/read Identity ['resnet_model/batch_normalization_17/moving_mean']\n",
      "resnet_model/batch_normalization_17/moving_variance Const []\n",
      "resnet_model/batch_normalization_17/moving_variance/read Identity ['resnet_model/batch_normalization_17/moving_variance']\n",
      "resnet_model/batch_normalization_17/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_17/Conv2D', 'resnet_model/batch_normalization_17/gamma/read', 'resnet_model/batch_normalization_17/beta/read', 'resnet_model/batch_normalization_17/moving_mean/read', 'resnet_model/batch_normalization_17/moving_variance/read']\n",
      "resnet_model/add_4 Add ['resnet_model/batch_normalization_17/FusedBatchNorm', 'resnet_model/Relu_12']\n",
      "resnet_model/Relu_15 Relu ['resnet_model/add_4']\n",
      "resnet_model/conv2d_18/kernel Const []\n",
      "resnet_model/conv2d_18/kernel/read Identity ['resnet_model/conv2d_18/kernel']\n",
      "resnet_model/conv2d_18/Conv2D Conv2D ['resnet_model/Relu_15', 'resnet_model/conv2d_18/kernel/read']\n",
      "resnet_model/batch_normalization_18/gamma Const []\n",
      "resnet_model/batch_normalization_18/gamma/read Identity ['resnet_model/batch_normalization_18/gamma']\n",
      "resnet_model/batch_normalization_18/beta Const []\n",
      "resnet_model/batch_normalization_18/beta/read Identity ['resnet_model/batch_normalization_18/beta']\n",
      "resnet_model/batch_normalization_18/moving_mean Const []\n",
      "resnet_model/batch_normalization_18/moving_mean/read Identity ['resnet_model/batch_normalization_18/moving_mean']\n",
      "resnet_model/batch_normalization_18/moving_variance Const []\n",
      "resnet_model/batch_normalization_18/moving_variance/read Identity ['resnet_model/batch_normalization_18/moving_variance']\n",
      "resnet_model/batch_normalization_18/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_18/Conv2D', 'resnet_model/batch_normalization_18/gamma/read', 'resnet_model/batch_normalization_18/beta/read', 'resnet_model/batch_normalization_18/moving_mean/read', 'resnet_model/batch_normalization_18/moving_variance/read']\n",
      "resnet_model/Relu_16 Relu ['resnet_model/batch_normalization_18/FusedBatchNorm']\n",
      "resnet_model/conv2d_19/kernel Const []\n",
      "resnet_model/conv2d_19/kernel/read Identity ['resnet_model/conv2d_19/kernel']\n",
      "resnet_model/conv2d_19/Conv2D Conv2D ['resnet_model/Relu_16', 'resnet_model/conv2d_19/kernel/read']\n",
      "resnet_model/batch_normalization_19/gamma Const []\n",
      "resnet_model/batch_normalization_19/gamma/read Identity ['resnet_model/batch_normalization_19/gamma']\n",
      "resnet_model/batch_normalization_19/beta Const []\n",
      "resnet_model/batch_normalization_19/beta/read Identity ['resnet_model/batch_normalization_19/beta']\n",
      "resnet_model/batch_normalization_19/moving_mean Const []\n",
      "resnet_model/batch_normalization_19/moving_mean/read Identity ['resnet_model/batch_normalization_19/moving_mean']\n",
      "resnet_model/batch_normalization_19/moving_variance Const []\n",
      "resnet_model/batch_normalization_19/moving_variance/read Identity ['resnet_model/batch_normalization_19/moving_variance']\n",
      "resnet_model/batch_normalization_19/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_19/Conv2D', 'resnet_model/batch_normalization_19/gamma/read', 'resnet_model/batch_normalization_19/beta/read', 'resnet_model/batch_normalization_19/moving_mean/read', 'resnet_model/batch_normalization_19/moving_variance/read']\n",
      "resnet_model/Relu_17 Relu ['resnet_model/batch_normalization_19/FusedBatchNorm']\n",
      "resnet_model/conv2d_20/kernel Const []\n",
      "resnet_model/conv2d_20/kernel/read Identity ['resnet_model/conv2d_20/kernel']\n",
      "resnet_model/conv2d_20/Conv2D Conv2D ['resnet_model/Relu_17', 'resnet_model/conv2d_20/kernel/read']\n",
      "resnet_model/batch_normalization_20/gamma Const []\n",
      "resnet_model/batch_normalization_20/gamma/read Identity ['resnet_model/batch_normalization_20/gamma']\n",
      "resnet_model/batch_normalization_20/beta Const []\n",
      "resnet_model/batch_normalization_20/beta/read Identity ['resnet_model/batch_normalization_20/beta']\n",
      "resnet_model/batch_normalization_20/moving_mean Const []\n",
      "resnet_model/batch_normalization_20/moving_mean/read Identity ['resnet_model/batch_normalization_20/moving_mean']\n",
      "resnet_model/batch_normalization_20/moving_variance Const []\n",
      "resnet_model/batch_normalization_20/moving_variance/read Identity ['resnet_model/batch_normalization_20/moving_variance']\n",
      "resnet_model/batch_normalization_20/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_20/Conv2D', 'resnet_model/batch_normalization_20/gamma/read', 'resnet_model/batch_normalization_20/beta/read', 'resnet_model/batch_normalization_20/moving_mean/read', 'resnet_model/batch_normalization_20/moving_variance/read']\n",
      "resnet_model/add_5 Add ['resnet_model/batch_normalization_20/FusedBatchNorm', 'resnet_model/Relu_15']\n",
      "resnet_model/Relu_18 Relu ['resnet_model/add_5']\n",
      "resnet_model/conv2d_21/kernel Const []\n",
      "resnet_model/conv2d_21/kernel/read Identity ['resnet_model/conv2d_21/kernel']\n",
      "resnet_model/conv2d_21/Conv2D Conv2D ['resnet_model/Relu_18', 'resnet_model/conv2d_21/kernel/read']\n",
      "resnet_model/batch_normalization_21/gamma Const []\n",
      "resnet_model/batch_normalization_21/gamma/read Identity ['resnet_model/batch_normalization_21/gamma']\n",
      "resnet_model/batch_normalization_21/beta Const []\n",
      "resnet_model/batch_normalization_21/beta/read Identity ['resnet_model/batch_normalization_21/beta']\n",
      "resnet_model/batch_normalization_21/moving_mean Const []\n",
      "resnet_model/batch_normalization_21/moving_mean/read Identity ['resnet_model/batch_normalization_21/moving_mean']\n",
      "resnet_model/batch_normalization_21/moving_variance Const []\n",
      "resnet_model/batch_normalization_21/moving_variance/read Identity ['resnet_model/batch_normalization_21/moving_variance']\n",
      "resnet_model/batch_normalization_21/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_21/Conv2D', 'resnet_model/batch_normalization_21/gamma/read', 'resnet_model/batch_normalization_21/beta/read', 'resnet_model/batch_normalization_21/moving_mean/read', 'resnet_model/batch_normalization_21/moving_variance/read']\n",
      "resnet_model/Relu_19 Relu ['resnet_model/batch_normalization_21/FusedBatchNorm']\n",
      "resnet_model/conv2d_22/kernel Const []\n",
      "resnet_model/conv2d_22/kernel/read Identity ['resnet_model/conv2d_22/kernel']\n",
      "resnet_model/conv2d_22/Conv2D Conv2D ['resnet_model/Relu_19', 'resnet_model/conv2d_22/kernel/read']\n",
      "resnet_model/batch_normalization_22/gamma Const []\n",
      "resnet_model/batch_normalization_22/gamma/read Identity ['resnet_model/batch_normalization_22/gamma']\n",
      "resnet_model/batch_normalization_22/beta Const []\n",
      "resnet_model/batch_normalization_22/beta/read Identity ['resnet_model/batch_normalization_22/beta']\n",
      "resnet_model/batch_normalization_22/moving_mean Const []\n",
      "resnet_model/batch_normalization_22/moving_mean/read Identity ['resnet_model/batch_normalization_22/moving_mean']\n",
      "resnet_model/batch_normalization_22/moving_variance Const []\n",
      "resnet_model/batch_normalization_22/moving_variance/read Identity ['resnet_model/batch_normalization_22/moving_variance']\n",
      "resnet_model/batch_normalization_22/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_22/Conv2D', 'resnet_model/batch_normalization_22/gamma/read', 'resnet_model/batch_normalization_22/beta/read', 'resnet_model/batch_normalization_22/moving_mean/read', 'resnet_model/batch_normalization_22/moving_variance/read']\n",
      "resnet_model/Relu_20 Relu ['resnet_model/batch_normalization_22/FusedBatchNorm']\n",
      "resnet_model/conv2d_23/kernel Const []\n",
      "resnet_model/conv2d_23/kernel/read Identity ['resnet_model/conv2d_23/kernel']\n",
      "resnet_model/conv2d_23/Conv2D Conv2D ['resnet_model/Relu_20', 'resnet_model/conv2d_23/kernel/read']\n",
      "resnet_model/batch_normalization_23/gamma Const []\n",
      "resnet_model/batch_normalization_23/gamma/read Identity ['resnet_model/batch_normalization_23/gamma']\n",
      "resnet_model/batch_normalization_23/beta Const []\n",
      "resnet_model/batch_normalization_23/beta/read Identity ['resnet_model/batch_normalization_23/beta']\n",
      "resnet_model/batch_normalization_23/moving_mean Const []\n",
      "resnet_model/batch_normalization_23/moving_mean/read Identity ['resnet_model/batch_normalization_23/moving_mean']\n",
      "resnet_model/batch_normalization_23/moving_variance Const []\n",
      "resnet_model/batch_normalization_23/moving_variance/read Identity ['resnet_model/batch_normalization_23/moving_variance']\n",
      "resnet_model/batch_normalization_23/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_23/Conv2D', 'resnet_model/batch_normalization_23/gamma/read', 'resnet_model/batch_normalization_23/beta/read', 'resnet_model/batch_normalization_23/moving_mean/read', 'resnet_model/batch_normalization_23/moving_variance/read']\n",
      "resnet_model/add_6 Add ['resnet_model/batch_normalization_23/FusedBatchNorm', 'resnet_model/Relu_18']\n",
      "resnet_model/Relu_21 Relu ['resnet_model/add_6']\n",
      "resnet_model/block_layer2 Identity ['resnet_model/Relu_21']\n",
      "resnet_model/Pad_3/paddings Const []\n",
      "resnet_model/Pad_3 Pad ['resnet_model/block_layer2', 'resnet_model/Pad_3/paddings']\n",
      "resnet_model/conv2d_24/kernel Const []\n",
      "resnet_model/conv2d_24/kernel/read Identity ['resnet_model/conv2d_24/kernel']\n",
      "resnet_model/conv2d_24/Conv2D Conv2D ['resnet_model/Pad_3', 'resnet_model/conv2d_24/kernel/read']\n",
      "resnet_model/batch_normalization_24/gamma Const []\n",
      "resnet_model/batch_normalization_24/gamma/read Identity ['resnet_model/batch_normalization_24/gamma']\n",
      "resnet_model/batch_normalization_24/beta Const []\n",
      "resnet_model/batch_normalization_24/beta/read Identity ['resnet_model/batch_normalization_24/beta']\n",
      "resnet_model/batch_normalization_24/moving_mean Const []\n",
      "resnet_model/batch_normalization_24/moving_mean/read Identity ['resnet_model/batch_normalization_24/moving_mean']\n",
      "resnet_model/batch_normalization_24/moving_variance Const []\n",
      "resnet_model/batch_normalization_24/moving_variance/read Identity ['resnet_model/batch_normalization_24/moving_variance']\n",
      "resnet_model/batch_normalization_24/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_24/Conv2D', 'resnet_model/batch_normalization_24/gamma/read', 'resnet_model/batch_normalization_24/beta/read', 'resnet_model/batch_normalization_24/moving_mean/read', 'resnet_model/batch_normalization_24/moving_variance/read']\n",
      "resnet_model/conv2d_25/kernel Const []\n",
      "resnet_model/conv2d_25/kernel/read Identity ['resnet_model/conv2d_25/kernel']\n",
      "resnet_model/conv2d_25/Conv2D Conv2D ['resnet_model/block_layer2', 'resnet_model/conv2d_25/kernel/read']\n",
      "resnet_model/batch_normalization_25/gamma Const []\n",
      "resnet_model/batch_normalization_25/gamma/read Identity ['resnet_model/batch_normalization_25/gamma']\n",
      "resnet_model/batch_normalization_25/beta Const []\n",
      "resnet_model/batch_normalization_25/beta/read Identity ['resnet_model/batch_normalization_25/beta']\n",
      "resnet_model/batch_normalization_25/moving_mean Const []\n",
      "resnet_model/batch_normalization_25/moving_mean/read Identity ['resnet_model/batch_normalization_25/moving_mean']\n",
      "resnet_model/batch_normalization_25/moving_variance Const []\n",
      "resnet_model/batch_normalization_25/moving_variance/read Identity ['resnet_model/batch_normalization_25/moving_variance']\n",
      "resnet_model/batch_normalization_25/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_25/Conv2D', 'resnet_model/batch_normalization_25/gamma/read', 'resnet_model/batch_normalization_25/beta/read', 'resnet_model/batch_normalization_25/moving_mean/read', 'resnet_model/batch_normalization_25/moving_variance/read']\n",
      "resnet_model/Relu_22 Relu ['resnet_model/batch_normalization_25/FusedBatchNorm']\n",
      "resnet_model/Pad_4/paddings Const []\n",
      "resnet_model/Pad_4 Pad ['resnet_model/Relu_22', 'resnet_model/Pad_4/paddings']\n",
      "resnet_model/conv2d_26/kernel Const []\n",
      "resnet_model/conv2d_26/kernel/read Identity ['resnet_model/conv2d_26/kernel']\n",
      "resnet_model/conv2d_26/Conv2D Conv2D ['resnet_model/Pad_4', 'resnet_model/conv2d_26/kernel/read']\n",
      "resnet_model/batch_normalization_26/gamma Const []\n",
      "resnet_model/batch_normalization_26/gamma/read Identity ['resnet_model/batch_normalization_26/gamma']\n",
      "resnet_model/batch_normalization_26/beta Const []\n",
      "resnet_model/batch_normalization_26/beta/read Identity ['resnet_model/batch_normalization_26/beta']\n",
      "resnet_model/batch_normalization_26/moving_mean Const []\n",
      "resnet_model/batch_normalization_26/moving_mean/read Identity ['resnet_model/batch_normalization_26/moving_mean']\n",
      "resnet_model/batch_normalization_26/moving_variance Const []\n",
      "resnet_model/batch_normalization_26/moving_variance/read Identity ['resnet_model/batch_normalization_26/moving_variance']\n",
      "resnet_model/batch_normalization_26/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_26/Conv2D', 'resnet_model/batch_normalization_26/gamma/read', 'resnet_model/batch_normalization_26/beta/read', 'resnet_model/batch_normalization_26/moving_mean/read', 'resnet_model/batch_normalization_26/moving_variance/read']\n",
      "resnet_model/Relu_23 Relu ['resnet_model/batch_normalization_26/FusedBatchNorm']\n",
      "resnet_model/conv2d_27/kernel Const []\n",
      "resnet_model/conv2d_27/kernel/read Identity ['resnet_model/conv2d_27/kernel']\n",
      "resnet_model/conv2d_27/Conv2D Conv2D ['resnet_model/Relu_23', 'resnet_model/conv2d_27/kernel/read']\n",
      "resnet_model/batch_normalization_27/gamma Const []\n",
      "resnet_model/batch_normalization_27/gamma/read Identity ['resnet_model/batch_normalization_27/gamma']\n",
      "resnet_model/batch_normalization_27/beta Const []\n",
      "resnet_model/batch_normalization_27/beta/read Identity ['resnet_model/batch_normalization_27/beta']\n",
      "resnet_model/batch_normalization_27/moving_mean Const []\n",
      "resnet_model/batch_normalization_27/moving_mean/read Identity ['resnet_model/batch_normalization_27/moving_mean']\n",
      "resnet_model/batch_normalization_27/moving_variance Const []\n",
      "resnet_model/batch_normalization_27/moving_variance/read Identity ['resnet_model/batch_normalization_27/moving_variance']\n",
      "resnet_model/batch_normalization_27/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_27/Conv2D', 'resnet_model/batch_normalization_27/gamma/read', 'resnet_model/batch_normalization_27/beta/read', 'resnet_model/batch_normalization_27/moving_mean/read', 'resnet_model/batch_normalization_27/moving_variance/read']\n",
      "resnet_model/add_7 Add ['resnet_model/batch_normalization_27/FusedBatchNorm', 'resnet_model/batch_normalization_24/FusedBatchNorm']\n",
      "resnet_model/Relu_24 Relu ['resnet_model/add_7']\n",
      "resnet_model/conv2d_28/kernel Const []\n",
      "resnet_model/conv2d_28/kernel/read Identity ['resnet_model/conv2d_28/kernel']\n",
      "resnet_model/conv2d_28/Conv2D Conv2D ['resnet_model/Relu_24', 'resnet_model/conv2d_28/kernel/read']\n",
      "resnet_model/batch_normalization_28/gamma Const []\n",
      "resnet_model/batch_normalization_28/gamma/read Identity ['resnet_model/batch_normalization_28/gamma']\n",
      "resnet_model/batch_normalization_28/beta Const []\n",
      "resnet_model/batch_normalization_28/beta/read Identity ['resnet_model/batch_normalization_28/beta']\n",
      "resnet_model/batch_normalization_28/moving_mean Const []\n",
      "resnet_model/batch_normalization_28/moving_mean/read Identity ['resnet_model/batch_normalization_28/moving_mean']\n",
      "resnet_model/batch_normalization_28/moving_variance Const []\n",
      "resnet_model/batch_normalization_28/moving_variance/read Identity ['resnet_model/batch_normalization_28/moving_variance']\n",
      "resnet_model/batch_normalization_28/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_28/Conv2D', 'resnet_model/batch_normalization_28/gamma/read', 'resnet_model/batch_normalization_28/beta/read', 'resnet_model/batch_normalization_28/moving_mean/read', 'resnet_model/batch_normalization_28/moving_variance/read']\n",
      "resnet_model/Relu_25 Relu ['resnet_model/batch_normalization_28/FusedBatchNorm']\n",
      "resnet_model/conv2d_29/kernel Const []\n",
      "resnet_model/conv2d_29/kernel/read Identity ['resnet_model/conv2d_29/kernel']\n",
      "resnet_model/conv2d_29/Conv2D Conv2D ['resnet_model/Relu_25', 'resnet_model/conv2d_29/kernel/read']\n",
      "resnet_model/batch_normalization_29/gamma Const []\n",
      "resnet_model/batch_normalization_29/gamma/read Identity ['resnet_model/batch_normalization_29/gamma']\n",
      "resnet_model/batch_normalization_29/beta Const []\n",
      "resnet_model/batch_normalization_29/beta/read Identity ['resnet_model/batch_normalization_29/beta']\n",
      "resnet_model/batch_normalization_29/moving_mean Const []\n",
      "resnet_model/batch_normalization_29/moving_mean/read Identity ['resnet_model/batch_normalization_29/moving_mean']\n",
      "resnet_model/batch_normalization_29/moving_variance Const []\n",
      "resnet_model/batch_normalization_29/moving_variance/read Identity ['resnet_model/batch_normalization_29/moving_variance']\n",
      "resnet_model/batch_normalization_29/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_29/Conv2D', 'resnet_model/batch_normalization_29/gamma/read', 'resnet_model/batch_normalization_29/beta/read', 'resnet_model/batch_normalization_29/moving_mean/read', 'resnet_model/batch_normalization_29/moving_variance/read']\n",
      "resnet_model/Relu_26 Relu ['resnet_model/batch_normalization_29/FusedBatchNorm']\n",
      "resnet_model/conv2d_30/kernel Const []\n",
      "resnet_model/conv2d_30/kernel/read Identity ['resnet_model/conv2d_30/kernel']\n",
      "resnet_model/conv2d_30/Conv2D Conv2D ['resnet_model/Relu_26', 'resnet_model/conv2d_30/kernel/read']\n",
      "resnet_model/batch_normalization_30/gamma Const []\n",
      "resnet_model/batch_normalization_30/gamma/read Identity ['resnet_model/batch_normalization_30/gamma']\n",
      "resnet_model/batch_normalization_30/beta Const []\n",
      "resnet_model/batch_normalization_30/beta/read Identity ['resnet_model/batch_normalization_30/beta']\n",
      "resnet_model/batch_normalization_30/moving_mean Const []\n",
      "resnet_model/batch_normalization_30/moving_mean/read Identity ['resnet_model/batch_normalization_30/moving_mean']\n",
      "resnet_model/batch_normalization_30/moving_variance Const []\n",
      "resnet_model/batch_normalization_30/moving_variance/read Identity ['resnet_model/batch_normalization_30/moving_variance']\n",
      "resnet_model/batch_normalization_30/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_30/Conv2D', 'resnet_model/batch_normalization_30/gamma/read', 'resnet_model/batch_normalization_30/beta/read', 'resnet_model/batch_normalization_30/moving_mean/read', 'resnet_model/batch_normalization_30/moving_variance/read']\n",
      "resnet_model/add_8 Add ['resnet_model/batch_normalization_30/FusedBatchNorm', 'resnet_model/Relu_24']\n",
      "resnet_model/Relu_27 Relu ['resnet_model/add_8']\n",
      "resnet_model/conv2d_31/kernel Const []\n",
      "resnet_model/conv2d_31/kernel/read Identity ['resnet_model/conv2d_31/kernel']\n",
      "resnet_model/conv2d_31/Conv2D Conv2D ['resnet_model/Relu_27', 'resnet_model/conv2d_31/kernel/read']\n",
      "resnet_model/batch_normalization_31/gamma Const []\n",
      "resnet_model/batch_normalization_31/gamma/read Identity ['resnet_model/batch_normalization_31/gamma']\n",
      "resnet_model/batch_normalization_31/beta Const []\n",
      "resnet_model/batch_normalization_31/beta/read Identity ['resnet_model/batch_normalization_31/beta']\n",
      "resnet_model/batch_normalization_31/moving_mean Const []\n",
      "resnet_model/batch_normalization_31/moving_mean/read Identity ['resnet_model/batch_normalization_31/moving_mean']\n",
      "resnet_model/batch_normalization_31/moving_variance Const []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_model/batch_normalization_31/moving_variance/read Identity ['resnet_model/batch_normalization_31/moving_variance']\n",
      "resnet_model/batch_normalization_31/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_31/Conv2D', 'resnet_model/batch_normalization_31/gamma/read', 'resnet_model/batch_normalization_31/beta/read', 'resnet_model/batch_normalization_31/moving_mean/read', 'resnet_model/batch_normalization_31/moving_variance/read']\n",
      "resnet_model/Relu_28 Relu ['resnet_model/batch_normalization_31/FusedBatchNorm']\n",
      "resnet_model/conv2d_32/kernel Const []\n",
      "resnet_model/conv2d_32/kernel/read Identity ['resnet_model/conv2d_32/kernel']\n",
      "resnet_model/conv2d_32/Conv2D Conv2D ['resnet_model/Relu_28', 'resnet_model/conv2d_32/kernel/read']\n",
      "resnet_model/batch_normalization_32/gamma Const []\n",
      "resnet_model/batch_normalization_32/gamma/read Identity ['resnet_model/batch_normalization_32/gamma']\n",
      "resnet_model/batch_normalization_32/beta Const []\n",
      "resnet_model/batch_normalization_32/beta/read Identity ['resnet_model/batch_normalization_32/beta']\n",
      "resnet_model/batch_normalization_32/moving_mean Const []\n",
      "resnet_model/batch_normalization_32/moving_mean/read Identity ['resnet_model/batch_normalization_32/moving_mean']\n",
      "resnet_model/batch_normalization_32/moving_variance Const []\n",
      "resnet_model/batch_normalization_32/moving_variance/read Identity ['resnet_model/batch_normalization_32/moving_variance']\n",
      "resnet_model/batch_normalization_32/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_32/Conv2D', 'resnet_model/batch_normalization_32/gamma/read', 'resnet_model/batch_normalization_32/beta/read', 'resnet_model/batch_normalization_32/moving_mean/read', 'resnet_model/batch_normalization_32/moving_variance/read']\n",
      "resnet_model/Relu_29 Relu ['resnet_model/batch_normalization_32/FusedBatchNorm']\n",
      "resnet_model/conv2d_33/kernel Const []\n",
      "resnet_model/conv2d_33/kernel/read Identity ['resnet_model/conv2d_33/kernel']\n",
      "resnet_model/conv2d_33/Conv2D Conv2D ['resnet_model/Relu_29', 'resnet_model/conv2d_33/kernel/read']\n",
      "resnet_model/batch_normalization_33/gamma Const []\n",
      "resnet_model/batch_normalization_33/gamma/read Identity ['resnet_model/batch_normalization_33/gamma']\n",
      "resnet_model/batch_normalization_33/beta Const []\n",
      "resnet_model/batch_normalization_33/beta/read Identity ['resnet_model/batch_normalization_33/beta']\n",
      "resnet_model/batch_normalization_33/moving_mean Const []\n",
      "resnet_model/batch_normalization_33/moving_mean/read Identity ['resnet_model/batch_normalization_33/moving_mean']\n",
      "resnet_model/batch_normalization_33/moving_variance Const []\n",
      "resnet_model/batch_normalization_33/moving_variance/read Identity ['resnet_model/batch_normalization_33/moving_variance']\n",
      "resnet_model/batch_normalization_33/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_33/Conv2D', 'resnet_model/batch_normalization_33/gamma/read', 'resnet_model/batch_normalization_33/beta/read', 'resnet_model/batch_normalization_33/moving_mean/read', 'resnet_model/batch_normalization_33/moving_variance/read']\n",
      "resnet_model/add_9 Add ['resnet_model/batch_normalization_33/FusedBatchNorm', 'resnet_model/Relu_27']\n",
      "resnet_model/Relu_30 Relu ['resnet_model/add_9']\n",
      "resnet_model/conv2d_34/kernel Const []\n",
      "resnet_model/conv2d_34/kernel/read Identity ['resnet_model/conv2d_34/kernel']\n",
      "resnet_model/conv2d_34/Conv2D Conv2D ['resnet_model/Relu_30', 'resnet_model/conv2d_34/kernel/read']\n",
      "resnet_model/batch_normalization_34/gamma Const []\n",
      "resnet_model/batch_normalization_34/gamma/read Identity ['resnet_model/batch_normalization_34/gamma']\n",
      "resnet_model/batch_normalization_34/beta Const []\n",
      "resnet_model/batch_normalization_34/beta/read Identity ['resnet_model/batch_normalization_34/beta']\n",
      "resnet_model/batch_normalization_34/moving_mean Const []\n",
      "resnet_model/batch_normalization_34/moving_mean/read Identity ['resnet_model/batch_normalization_34/moving_mean']\n",
      "resnet_model/batch_normalization_34/moving_variance Const []\n",
      "resnet_model/batch_normalization_34/moving_variance/read Identity ['resnet_model/batch_normalization_34/moving_variance']\n",
      "resnet_model/batch_normalization_34/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_34/Conv2D', 'resnet_model/batch_normalization_34/gamma/read', 'resnet_model/batch_normalization_34/beta/read', 'resnet_model/batch_normalization_34/moving_mean/read', 'resnet_model/batch_normalization_34/moving_variance/read']\n",
      "resnet_model/Relu_31 Relu ['resnet_model/batch_normalization_34/FusedBatchNorm']\n",
      "resnet_model/conv2d_35/kernel Const []\n",
      "resnet_model/conv2d_35/kernel/read Identity ['resnet_model/conv2d_35/kernel']\n",
      "resnet_model/conv2d_35/Conv2D Conv2D ['resnet_model/Relu_31', 'resnet_model/conv2d_35/kernel/read']\n",
      "resnet_model/batch_normalization_35/gamma Const []\n",
      "resnet_model/batch_normalization_35/gamma/read Identity ['resnet_model/batch_normalization_35/gamma']\n",
      "resnet_model/batch_normalization_35/beta Const []\n",
      "resnet_model/batch_normalization_35/beta/read Identity ['resnet_model/batch_normalization_35/beta']\n",
      "resnet_model/batch_normalization_35/moving_mean Const []\n",
      "resnet_model/batch_normalization_35/moving_mean/read Identity ['resnet_model/batch_normalization_35/moving_mean']\n",
      "resnet_model/batch_normalization_35/moving_variance Const []\n",
      "resnet_model/batch_normalization_35/moving_variance/read Identity ['resnet_model/batch_normalization_35/moving_variance']\n",
      "resnet_model/batch_normalization_35/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_35/Conv2D', 'resnet_model/batch_normalization_35/gamma/read', 'resnet_model/batch_normalization_35/beta/read', 'resnet_model/batch_normalization_35/moving_mean/read', 'resnet_model/batch_normalization_35/moving_variance/read']\n",
      "resnet_model/Relu_32 Relu ['resnet_model/batch_normalization_35/FusedBatchNorm']\n",
      "resnet_model/conv2d_36/kernel Const []\n",
      "resnet_model/conv2d_36/kernel/read Identity ['resnet_model/conv2d_36/kernel']\n",
      "resnet_model/conv2d_36/Conv2D Conv2D ['resnet_model/Relu_32', 'resnet_model/conv2d_36/kernel/read']\n",
      "resnet_model/batch_normalization_36/gamma Const []\n",
      "resnet_model/batch_normalization_36/gamma/read Identity ['resnet_model/batch_normalization_36/gamma']\n",
      "resnet_model/batch_normalization_36/beta Const []\n",
      "resnet_model/batch_normalization_36/beta/read Identity ['resnet_model/batch_normalization_36/beta']\n",
      "resnet_model/batch_normalization_36/moving_mean Const []\n",
      "resnet_model/batch_normalization_36/moving_mean/read Identity ['resnet_model/batch_normalization_36/moving_mean']\n",
      "resnet_model/batch_normalization_36/moving_variance Const []\n",
      "resnet_model/batch_normalization_36/moving_variance/read Identity ['resnet_model/batch_normalization_36/moving_variance']\n",
      "resnet_model/batch_normalization_36/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_36/Conv2D', 'resnet_model/batch_normalization_36/gamma/read', 'resnet_model/batch_normalization_36/beta/read', 'resnet_model/batch_normalization_36/moving_mean/read', 'resnet_model/batch_normalization_36/moving_variance/read']\n",
      "resnet_model/add_10 Add ['resnet_model/batch_normalization_36/FusedBatchNorm', 'resnet_model/Relu_30']\n",
      "resnet_model/Relu_33 Relu ['resnet_model/add_10']\n",
      "resnet_model/conv2d_37/kernel Const []\n",
      "resnet_model/conv2d_37/kernel/read Identity ['resnet_model/conv2d_37/kernel']\n",
      "resnet_model/conv2d_37/Conv2D Conv2D ['resnet_model/Relu_33', 'resnet_model/conv2d_37/kernel/read']\n",
      "resnet_model/batch_normalization_37/gamma Const []\n",
      "resnet_model/batch_normalization_37/gamma/read Identity ['resnet_model/batch_normalization_37/gamma']\n",
      "resnet_model/batch_normalization_37/beta Const []\n",
      "resnet_model/batch_normalization_37/beta/read Identity ['resnet_model/batch_normalization_37/beta']\n",
      "resnet_model/batch_normalization_37/moving_mean Const []\n",
      "resnet_model/batch_normalization_37/moving_mean/read Identity ['resnet_model/batch_normalization_37/moving_mean']\n",
      "resnet_model/batch_normalization_37/moving_variance Const []\n",
      "resnet_model/batch_normalization_37/moving_variance/read Identity ['resnet_model/batch_normalization_37/moving_variance']\n",
      "resnet_model/batch_normalization_37/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_37/Conv2D', 'resnet_model/batch_normalization_37/gamma/read', 'resnet_model/batch_normalization_37/beta/read', 'resnet_model/batch_normalization_37/moving_mean/read', 'resnet_model/batch_normalization_37/moving_variance/read']\n",
      "resnet_model/Relu_34 Relu ['resnet_model/batch_normalization_37/FusedBatchNorm']\n",
      "resnet_model/conv2d_38/kernel Const []\n",
      "resnet_model/conv2d_38/kernel/read Identity ['resnet_model/conv2d_38/kernel']\n",
      "resnet_model/conv2d_38/Conv2D Conv2D ['resnet_model/Relu_34', 'resnet_model/conv2d_38/kernel/read']\n",
      "resnet_model/batch_normalization_38/gamma Const []\n",
      "resnet_model/batch_normalization_38/gamma/read Identity ['resnet_model/batch_normalization_38/gamma']\n",
      "resnet_model/batch_normalization_38/beta Const []\n",
      "resnet_model/batch_normalization_38/beta/read Identity ['resnet_model/batch_normalization_38/beta']\n",
      "resnet_model/batch_normalization_38/moving_mean Const []\n",
      "resnet_model/batch_normalization_38/moving_mean/read Identity ['resnet_model/batch_normalization_38/moving_mean']\n",
      "resnet_model/batch_normalization_38/moving_variance Const []\n",
      "resnet_model/batch_normalization_38/moving_variance/read Identity ['resnet_model/batch_normalization_38/moving_variance']\n",
      "resnet_model/batch_normalization_38/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_38/Conv2D', 'resnet_model/batch_normalization_38/gamma/read', 'resnet_model/batch_normalization_38/beta/read', 'resnet_model/batch_normalization_38/moving_mean/read', 'resnet_model/batch_normalization_38/moving_variance/read']\n",
      "resnet_model/Relu_35 Relu ['resnet_model/batch_normalization_38/FusedBatchNorm']\n",
      "resnet_model/conv2d_39/kernel Const []\n",
      "resnet_model/conv2d_39/kernel/read Identity ['resnet_model/conv2d_39/kernel']\n",
      "resnet_model/conv2d_39/Conv2D Conv2D ['resnet_model/Relu_35', 'resnet_model/conv2d_39/kernel/read']\n",
      "resnet_model/batch_normalization_39/gamma Const []\n",
      "resnet_model/batch_normalization_39/gamma/read Identity ['resnet_model/batch_normalization_39/gamma']\n",
      "resnet_model/batch_normalization_39/beta Const []\n",
      "resnet_model/batch_normalization_39/beta/read Identity ['resnet_model/batch_normalization_39/beta']\n",
      "resnet_model/batch_normalization_39/moving_mean Const []\n",
      "resnet_model/batch_normalization_39/moving_mean/read Identity ['resnet_model/batch_normalization_39/moving_mean']\n",
      "resnet_model/batch_normalization_39/moving_variance Const []\n",
      "resnet_model/batch_normalization_39/moving_variance/read Identity ['resnet_model/batch_normalization_39/moving_variance']\n",
      "resnet_model/batch_normalization_39/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_39/Conv2D', 'resnet_model/batch_normalization_39/gamma/read', 'resnet_model/batch_normalization_39/beta/read', 'resnet_model/batch_normalization_39/moving_mean/read', 'resnet_model/batch_normalization_39/moving_variance/read']\n",
      "resnet_model/add_11 Add ['resnet_model/batch_normalization_39/FusedBatchNorm', 'resnet_model/Relu_33']\n",
      "resnet_model/Relu_36 Relu ['resnet_model/add_11']\n",
      "resnet_model/conv2d_40/kernel Const []\n",
      "resnet_model/conv2d_40/kernel/read Identity ['resnet_model/conv2d_40/kernel']\n",
      "resnet_model/conv2d_40/Conv2D Conv2D ['resnet_model/Relu_36', 'resnet_model/conv2d_40/kernel/read']\n",
      "resnet_model/batch_normalization_40/gamma Const []\n",
      "resnet_model/batch_normalization_40/gamma/read Identity ['resnet_model/batch_normalization_40/gamma']\n",
      "resnet_model/batch_normalization_40/beta Const []\n",
      "resnet_model/batch_normalization_40/beta/read Identity ['resnet_model/batch_normalization_40/beta']\n",
      "resnet_model/batch_normalization_40/moving_mean Const []\n",
      "resnet_model/batch_normalization_40/moving_mean/read Identity ['resnet_model/batch_normalization_40/moving_mean']\n",
      "resnet_model/batch_normalization_40/moving_variance Const []\n",
      "resnet_model/batch_normalization_40/moving_variance/read Identity ['resnet_model/batch_normalization_40/moving_variance']\n",
      "resnet_model/batch_normalization_40/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_40/Conv2D', 'resnet_model/batch_normalization_40/gamma/read', 'resnet_model/batch_normalization_40/beta/read', 'resnet_model/batch_normalization_40/moving_mean/read', 'resnet_model/batch_normalization_40/moving_variance/read']\n",
      "resnet_model/Relu_37 Relu ['resnet_model/batch_normalization_40/FusedBatchNorm']\n",
      "resnet_model/conv2d_41/kernel Const []\n",
      "resnet_model/conv2d_41/kernel/read Identity ['resnet_model/conv2d_41/kernel']\n",
      "resnet_model/conv2d_41/Conv2D Conv2D ['resnet_model/Relu_37', 'resnet_model/conv2d_41/kernel/read']\n",
      "resnet_model/batch_normalization_41/gamma Const []\n",
      "resnet_model/batch_normalization_41/gamma/read Identity ['resnet_model/batch_normalization_41/gamma']\n",
      "resnet_model/batch_normalization_41/beta Const []\n",
      "resnet_model/batch_normalization_41/beta/read Identity ['resnet_model/batch_normalization_41/beta']\n",
      "resnet_model/batch_normalization_41/moving_mean Const []\n",
      "resnet_model/batch_normalization_41/moving_mean/read Identity ['resnet_model/batch_normalization_41/moving_mean']\n",
      "resnet_model/batch_normalization_41/moving_variance Const []\n",
      "resnet_model/batch_normalization_41/moving_variance/read Identity ['resnet_model/batch_normalization_41/moving_variance']\n",
      "resnet_model/batch_normalization_41/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_41/Conv2D', 'resnet_model/batch_normalization_41/gamma/read', 'resnet_model/batch_normalization_41/beta/read', 'resnet_model/batch_normalization_41/moving_mean/read', 'resnet_model/batch_normalization_41/moving_variance/read']\n",
      "resnet_model/Relu_38 Relu ['resnet_model/batch_normalization_41/FusedBatchNorm']\n",
      "resnet_model/conv2d_42/kernel Const []\n",
      "resnet_model/conv2d_42/kernel/read Identity ['resnet_model/conv2d_42/kernel']\n",
      "resnet_model/conv2d_42/Conv2D Conv2D ['resnet_model/Relu_38', 'resnet_model/conv2d_42/kernel/read']\n",
      "resnet_model/batch_normalization_42/gamma Const []\n",
      "resnet_model/batch_normalization_42/gamma/read Identity ['resnet_model/batch_normalization_42/gamma']\n",
      "resnet_model/batch_normalization_42/beta Const []\n",
      "resnet_model/batch_normalization_42/beta/read Identity ['resnet_model/batch_normalization_42/beta']\n",
      "resnet_model/batch_normalization_42/moving_mean Const []\n",
      "resnet_model/batch_normalization_42/moving_mean/read Identity ['resnet_model/batch_normalization_42/moving_mean']\n",
      "resnet_model/batch_normalization_42/moving_variance Const []\n",
      "resnet_model/batch_normalization_42/moving_variance/read Identity ['resnet_model/batch_normalization_42/moving_variance']\n",
      "resnet_model/batch_normalization_42/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_42/Conv2D', 'resnet_model/batch_normalization_42/gamma/read', 'resnet_model/batch_normalization_42/beta/read', 'resnet_model/batch_normalization_42/moving_mean/read', 'resnet_model/batch_normalization_42/moving_variance/read']\n",
      "resnet_model/add_12 Add ['resnet_model/batch_normalization_42/FusedBatchNorm', 'resnet_model/Relu_36']\n",
      "resnet_model/Relu_39 Relu ['resnet_model/add_12']\n",
      "resnet_model/block_layer3 Identity ['resnet_model/Relu_39']\n",
      "resnet_model/Pad_5/paddings Const []\n",
      "resnet_model/Pad_5 Pad ['resnet_model/block_layer3', 'resnet_model/Pad_5/paddings']\n",
      "resnet_model/conv2d_43/kernel Const []\n",
      "resnet_model/conv2d_43/kernel/read Identity ['resnet_model/conv2d_43/kernel']\n",
      "resnet_model/conv2d_43/Conv2D Conv2D ['resnet_model/Pad_5', 'resnet_model/conv2d_43/kernel/read']\n",
      "resnet_model/batch_normalization_43/gamma Const []\n",
      "resnet_model/batch_normalization_43/gamma/read Identity ['resnet_model/batch_normalization_43/gamma']\n",
      "resnet_model/batch_normalization_43/beta Const []\n",
      "resnet_model/batch_normalization_43/beta/read Identity ['resnet_model/batch_normalization_43/beta']\n",
      "resnet_model/batch_normalization_43/moving_mean Const []\n",
      "resnet_model/batch_normalization_43/moving_mean/read Identity ['resnet_model/batch_normalization_43/moving_mean']\n",
      "resnet_model/batch_normalization_43/moving_variance Const []\n",
      "resnet_model/batch_normalization_43/moving_variance/read Identity ['resnet_model/batch_normalization_43/moving_variance']\n",
      "resnet_model/batch_normalization_43/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_43/Conv2D', 'resnet_model/batch_normalization_43/gamma/read', 'resnet_model/batch_normalization_43/beta/read', 'resnet_model/batch_normalization_43/moving_mean/read', 'resnet_model/batch_normalization_43/moving_variance/read']\n",
      "resnet_model/conv2d_44/kernel Const []\n",
      "resnet_model/conv2d_44/kernel/read Identity ['resnet_model/conv2d_44/kernel']\n",
      "resnet_model/conv2d_44/Conv2D Conv2D ['resnet_model/block_layer3', 'resnet_model/conv2d_44/kernel/read']\n",
      "resnet_model/batch_normalization_44/gamma Const []\n",
      "resnet_model/batch_normalization_44/gamma/read Identity ['resnet_model/batch_normalization_44/gamma']\n",
      "resnet_model/batch_normalization_44/beta Const []\n",
      "resnet_model/batch_normalization_44/beta/read Identity ['resnet_model/batch_normalization_44/beta']\n",
      "resnet_model/batch_normalization_44/moving_mean Const []\n",
      "resnet_model/batch_normalization_44/moving_mean/read Identity ['resnet_model/batch_normalization_44/moving_mean']\n",
      "resnet_model/batch_normalization_44/moving_variance Const []\n",
      "resnet_model/batch_normalization_44/moving_variance/read Identity ['resnet_model/batch_normalization_44/moving_variance']\n",
      "resnet_model/batch_normalization_44/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_44/Conv2D', 'resnet_model/batch_normalization_44/gamma/read', 'resnet_model/batch_normalization_44/beta/read', 'resnet_model/batch_normalization_44/moving_mean/read', 'resnet_model/batch_normalization_44/moving_variance/read']\n",
      "resnet_model/Relu_40 Relu ['resnet_model/batch_normalization_44/FusedBatchNorm']\n",
      "resnet_model/Pad_6/paddings Const []\n",
      "resnet_model/Pad_6 Pad ['resnet_model/Relu_40', 'resnet_model/Pad_6/paddings']\n",
      "resnet_model/conv2d_45/kernel Const []\n",
      "resnet_model/conv2d_45/kernel/read Identity ['resnet_model/conv2d_45/kernel']\n",
      "resnet_model/conv2d_45/Conv2D Conv2D ['resnet_model/Pad_6', 'resnet_model/conv2d_45/kernel/read']\n",
      "resnet_model/batch_normalization_45/gamma Const []\n",
      "resnet_model/batch_normalization_45/gamma/read Identity ['resnet_model/batch_normalization_45/gamma']\n",
      "resnet_model/batch_normalization_45/beta Const []\n",
      "resnet_model/batch_normalization_45/beta/read Identity ['resnet_model/batch_normalization_45/beta']\n",
      "resnet_model/batch_normalization_45/moving_mean Const []\n",
      "resnet_model/batch_normalization_45/moving_mean/read Identity ['resnet_model/batch_normalization_45/moving_mean']\n",
      "resnet_model/batch_normalization_45/moving_variance Const []\n",
      "resnet_model/batch_normalization_45/moving_variance/read Identity ['resnet_model/batch_normalization_45/moving_variance']\n",
      "resnet_model/batch_normalization_45/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_45/Conv2D', 'resnet_model/batch_normalization_45/gamma/read', 'resnet_model/batch_normalization_45/beta/read', 'resnet_model/batch_normalization_45/moving_mean/read', 'resnet_model/batch_normalization_45/moving_variance/read']\n",
      "resnet_model/Relu_41 Relu ['resnet_model/batch_normalization_45/FusedBatchNorm']\n",
      "resnet_model/conv2d_46/kernel Const []\n",
      "resnet_model/conv2d_46/kernel/read Identity ['resnet_model/conv2d_46/kernel']\n",
      "resnet_model/conv2d_46/Conv2D Conv2D ['resnet_model/Relu_41', 'resnet_model/conv2d_46/kernel/read']\n",
      "resnet_model/batch_normalization_46/gamma Const []\n",
      "resnet_model/batch_normalization_46/gamma/read Identity ['resnet_model/batch_normalization_46/gamma']\n",
      "resnet_model/batch_normalization_46/beta Const []\n",
      "resnet_model/batch_normalization_46/beta/read Identity ['resnet_model/batch_normalization_46/beta']\n",
      "resnet_model/batch_normalization_46/moving_mean Const []\n",
      "resnet_model/batch_normalization_46/moving_mean/read Identity ['resnet_model/batch_normalization_46/moving_mean']\n",
      "resnet_model/batch_normalization_46/moving_variance Const []\n",
      "resnet_model/batch_normalization_46/moving_variance/read Identity ['resnet_model/batch_normalization_46/moving_variance']\n",
      "resnet_model/batch_normalization_46/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_46/Conv2D', 'resnet_model/batch_normalization_46/gamma/read', 'resnet_model/batch_normalization_46/beta/read', 'resnet_model/batch_normalization_46/moving_mean/read', 'resnet_model/batch_normalization_46/moving_variance/read']\n",
      "resnet_model/add_13 Add ['resnet_model/batch_normalization_46/FusedBatchNorm', 'resnet_model/batch_normalization_43/FusedBatchNorm']\n",
      "resnet_model/Relu_42 Relu ['resnet_model/add_13']\n",
      "resnet_model/conv2d_47/kernel Const []\n",
      "resnet_model/conv2d_47/kernel/read Identity ['resnet_model/conv2d_47/kernel']\n",
      "resnet_model/conv2d_47/Conv2D Conv2D ['resnet_model/Relu_42', 'resnet_model/conv2d_47/kernel/read']\n",
      "resnet_model/batch_normalization_47/gamma Const []\n",
      "resnet_model/batch_normalization_47/gamma/read Identity ['resnet_model/batch_normalization_47/gamma']\n",
      "resnet_model/batch_normalization_47/beta Const []\n",
      "resnet_model/batch_normalization_47/beta/read Identity ['resnet_model/batch_normalization_47/beta']\n",
      "resnet_model/batch_normalization_47/moving_mean Const []\n",
      "resnet_model/batch_normalization_47/moving_mean/read Identity ['resnet_model/batch_normalization_47/moving_mean']\n",
      "resnet_model/batch_normalization_47/moving_variance Const []\n",
      "resnet_model/batch_normalization_47/moving_variance/read Identity ['resnet_model/batch_normalization_47/moving_variance']\n",
      "resnet_model/batch_normalization_47/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_47/Conv2D', 'resnet_model/batch_normalization_47/gamma/read', 'resnet_model/batch_normalization_47/beta/read', 'resnet_model/batch_normalization_47/moving_mean/read', 'resnet_model/batch_normalization_47/moving_variance/read']\n",
      "resnet_model/Relu_43 Relu ['resnet_model/batch_normalization_47/FusedBatchNorm']\n",
      "resnet_model/conv2d_48/kernel Const []\n",
      "resnet_model/conv2d_48/kernel/read Identity ['resnet_model/conv2d_48/kernel']\n",
      "resnet_model/conv2d_48/Conv2D Conv2D ['resnet_model/Relu_43', 'resnet_model/conv2d_48/kernel/read']\n",
      "resnet_model/batch_normalization_48/gamma Const []\n",
      "resnet_model/batch_normalization_48/gamma/read Identity ['resnet_model/batch_normalization_48/gamma']\n",
      "resnet_model/batch_normalization_48/beta Const []\n",
      "resnet_model/batch_normalization_48/beta/read Identity ['resnet_model/batch_normalization_48/beta']\n",
      "resnet_model/batch_normalization_48/moving_mean Const []\n",
      "resnet_model/batch_normalization_48/moving_mean/read Identity ['resnet_model/batch_normalization_48/moving_mean']\n",
      "resnet_model/batch_normalization_48/moving_variance Const []\n",
      "resnet_model/batch_normalization_48/moving_variance/read Identity ['resnet_model/batch_normalization_48/moving_variance']\n",
      "resnet_model/batch_normalization_48/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_48/Conv2D', 'resnet_model/batch_normalization_48/gamma/read', 'resnet_model/batch_normalization_48/beta/read', 'resnet_model/batch_normalization_48/moving_mean/read', 'resnet_model/batch_normalization_48/moving_variance/read']\n",
      "resnet_model/Relu_44 Relu ['resnet_model/batch_normalization_48/FusedBatchNorm']\n",
      "resnet_model/conv2d_49/kernel Const []\n",
      "resnet_model/conv2d_49/kernel/read Identity ['resnet_model/conv2d_49/kernel']\n",
      "resnet_model/conv2d_49/Conv2D Conv2D ['resnet_model/Relu_44', 'resnet_model/conv2d_49/kernel/read']\n",
      "resnet_model/batch_normalization_49/gamma Const []\n",
      "resnet_model/batch_normalization_49/gamma/read Identity ['resnet_model/batch_normalization_49/gamma']\n",
      "resnet_model/batch_normalization_49/beta Const []\n",
      "resnet_model/batch_normalization_49/beta/read Identity ['resnet_model/batch_normalization_49/beta']\n",
      "resnet_model/batch_normalization_49/moving_mean Const []\n",
      "resnet_model/batch_normalization_49/moving_mean/read Identity ['resnet_model/batch_normalization_49/moving_mean']\n",
      "resnet_model/batch_normalization_49/moving_variance Const []\n",
      "resnet_model/batch_normalization_49/moving_variance/read Identity ['resnet_model/batch_normalization_49/moving_variance']\n",
      "resnet_model/batch_normalization_49/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_49/Conv2D', 'resnet_model/batch_normalization_49/gamma/read', 'resnet_model/batch_normalization_49/beta/read', 'resnet_model/batch_normalization_49/moving_mean/read', 'resnet_model/batch_normalization_49/moving_variance/read']\n",
      "resnet_model/add_14 Add ['resnet_model/batch_normalization_49/FusedBatchNorm', 'resnet_model/Relu_42']\n",
      "resnet_model/Relu_45 Relu ['resnet_model/add_14']\n",
      "resnet_model/conv2d_50/kernel Const []\n",
      "resnet_model/conv2d_50/kernel/read Identity ['resnet_model/conv2d_50/kernel']\n",
      "resnet_model/conv2d_50/Conv2D Conv2D ['resnet_model/Relu_45', 'resnet_model/conv2d_50/kernel/read']\n",
      "resnet_model/batch_normalization_50/gamma Const []\n",
      "resnet_model/batch_normalization_50/gamma/read Identity ['resnet_model/batch_normalization_50/gamma']\n",
      "resnet_model/batch_normalization_50/beta Const []\n",
      "resnet_model/batch_normalization_50/beta/read Identity ['resnet_model/batch_normalization_50/beta']\n",
      "resnet_model/batch_normalization_50/moving_mean Const []\n",
      "resnet_model/batch_normalization_50/moving_mean/read Identity ['resnet_model/batch_normalization_50/moving_mean']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_model/batch_normalization_50/moving_variance Const []\n",
      "resnet_model/batch_normalization_50/moving_variance/read Identity ['resnet_model/batch_normalization_50/moving_variance']\n",
      "resnet_model/batch_normalization_50/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_50/Conv2D', 'resnet_model/batch_normalization_50/gamma/read', 'resnet_model/batch_normalization_50/beta/read', 'resnet_model/batch_normalization_50/moving_mean/read', 'resnet_model/batch_normalization_50/moving_variance/read']\n",
      "resnet_model/Relu_46 Relu ['resnet_model/batch_normalization_50/FusedBatchNorm']\n",
      "resnet_model/conv2d_51/kernel Const []\n",
      "resnet_model/conv2d_51/kernel/read Identity ['resnet_model/conv2d_51/kernel']\n",
      "resnet_model/conv2d_51/Conv2D Conv2D ['resnet_model/Relu_46', 'resnet_model/conv2d_51/kernel/read']\n",
      "resnet_model/batch_normalization_51/gamma Const []\n",
      "resnet_model/batch_normalization_51/gamma/read Identity ['resnet_model/batch_normalization_51/gamma']\n",
      "resnet_model/batch_normalization_51/beta Const []\n",
      "resnet_model/batch_normalization_51/beta/read Identity ['resnet_model/batch_normalization_51/beta']\n",
      "resnet_model/batch_normalization_51/moving_mean Const []\n",
      "resnet_model/batch_normalization_51/moving_mean/read Identity ['resnet_model/batch_normalization_51/moving_mean']\n",
      "resnet_model/batch_normalization_51/moving_variance Const []\n",
      "resnet_model/batch_normalization_51/moving_variance/read Identity ['resnet_model/batch_normalization_51/moving_variance']\n",
      "resnet_model/batch_normalization_51/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_51/Conv2D', 'resnet_model/batch_normalization_51/gamma/read', 'resnet_model/batch_normalization_51/beta/read', 'resnet_model/batch_normalization_51/moving_mean/read', 'resnet_model/batch_normalization_51/moving_variance/read']\n",
      "resnet_model/Relu_47 Relu ['resnet_model/batch_normalization_51/FusedBatchNorm']\n",
      "resnet_model/conv2d_52/kernel Const []\n",
      "resnet_model/conv2d_52/kernel/read Identity ['resnet_model/conv2d_52/kernel']\n",
      "resnet_model/conv2d_52/Conv2D Conv2D ['resnet_model/Relu_47', 'resnet_model/conv2d_52/kernel/read']\n",
      "resnet_model/batch_normalization_52/gamma Const []\n",
      "resnet_model/batch_normalization_52/gamma/read Identity ['resnet_model/batch_normalization_52/gamma']\n",
      "resnet_model/batch_normalization_52/beta Const []\n",
      "resnet_model/batch_normalization_52/beta/read Identity ['resnet_model/batch_normalization_52/beta']\n",
      "resnet_model/batch_normalization_52/moving_mean Const []\n",
      "resnet_model/batch_normalization_52/moving_mean/read Identity ['resnet_model/batch_normalization_52/moving_mean']\n",
      "resnet_model/batch_normalization_52/moving_variance Const []\n",
      "resnet_model/batch_normalization_52/moving_variance/read Identity ['resnet_model/batch_normalization_52/moving_variance']\n",
      "resnet_model/batch_normalization_52/FusedBatchNorm FusedBatchNorm ['resnet_model/conv2d_52/Conv2D', 'resnet_model/batch_normalization_52/gamma/read', 'resnet_model/batch_normalization_52/beta/read', 'resnet_model/batch_normalization_52/moving_mean/read', 'resnet_model/batch_normalization_52/moving_variance/read']\n",
      "resnet_model/add_15 Add ['resnet_model/batch_normalization_52/FusedBatchNorm', 'resnet_model/Relu_45']\n",
      "resnet_model/Relu_48 Relu ['resnet_model/add_15']\n",
      "resnet_model/block_layer4 Identity ['resnet_model/Relu_48']\n",
      "resnet_model/Mean/reduction_indices Const []\n",
      "resnet_model/Mean Mean ['resnet_model/block_layer4', 'resnet_model/Mean/reduction_indices']\n",
      "resnet_model/final_reduce_mean Identity ['resnet_model/Mean']\n",
      "resnet_model/Squeeze Squeeze ['resnet_model/final_reduce_mean']\n",
      "resnet_model/dense/kernel Const []\n",
      "resnet_model/dense/kernel/read Identity ['resnet_model/dense/kernel']\n",
      "resnet_model/dense/bias Const []\n",
      "resnet_model/dense/bias/read Identity ['resnet_model/dense/bias']\n",
      "resnet_model/dense/MatMul MatMul ['resnet_model/Squeeze', 'resnet_model/dense/kernel/read']\n",
      "resnet_model/dense/BiasAdd BiasAdd ['resnet_model/dense/MatMul', 'resnet_model/dense/bias/read']\n",
      "resnet_model/final_dense Identity ['resnet_model/dense/BiasAdd']\n",
      "ArgMax/dimension Const []\n",
      "ArgMax ArgMax ['resnet_model/final_dense', 'ArgMax/dimension']\n",
      "softmax_tensor Softmax ['resnet_model/final_dense']\n"
     ]
    }
   ],
   "source": [
    "master_dict = {}\n",
    "for i in graph_def.node:\n",
    "    print(i.name, i.op, i.input)\n",
    "    master_dict[i.name] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d38e4e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "for node in graph_def.node:\n",
    "    if G.has_node(node.name)==False:\n",
    "        G.add_node(node.name)\n",
    "    for inp in node.input:\n",
    "        if G.has_node(inp)== False:\n",
    "            G.add_node(inp)\n",
    "        G.add_edge(inp,node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8543897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet_model/conv2d_1/Conv2D', 'resnet_model/conv2d_2/Conv2D']\n"
     ]
    }
   ],
   "source": [
    "for i in list(G.nodes):\n",
    "    node = master_dict[i]\n",
    "    if node.name == 'resnet_model/initial_max_pool':\n",
    "        print(list(G.neighbors(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c6d7f3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input_tensor', 'resnet_model/Pad')\n",
      "('resnet_model/Pad/paddings', 'resnet_model/Pad')\n",
      "('resnet_model/Pad', 'resnet_model/conv2d/Conv2D')\n",
      "('resnet_model/conv2d/kernel', 'resnet_model/conv2d/kernel/read')\n",
      "('resnet_model/conv2d/kernel/read', 'resnet_model/conv2d/Conv2D')\n",
      "('resnet_model/conv2d/Conv2D', 'resnet_model/initial_conv')\n",
      "('resnet_model/initial_conv', 'resnet_model/batch_normalization/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization/gamma', 'resnet_model/batch_normalization/gamma/read')\n",
      "('resnet_model/batch_normalization/gamma/read', 'resnet_model/batch_normalization/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization/beta', 'resnet_model/batch_normalization/beta/read')\n",
      "('resnet_model/batch_normalization/beta/read', 'resnet_model/batch_normalization/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization/moving_mean', 'resnet_model/batch_normalization/moving_mean/read')\n",
      "('resnet_model/batch_normalization/moving_mean/read', 'resnet_model/batch_normalization/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization/moving_variance', 'resnet_model/batch_normalization/moving_variance/read')\n",
      "('resnet_model/batch_normalization/moving_variance/read', 'resnet_model/batch_normalization/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization/FusedBatchNorm', 'resnet_model/Relu')\n",
      "('resnet_model/Relu', 'resnet_model/max_pooling2d/MaxPool')\n",
      "('resnet_model/max_pooling2d/MaxPool', 'resnet_model/initial_max_pool')\n",
      "('resnet_model/initial_max_pool', 'resnet_model/conv2d_1/Conv2D')\n",
      "('resnet_model/initial_max_pool', 'resnet_model/conv2d_2/Conv2D')\n",
      "('resnet_model/conv2d_1/kernel', 'resnet_model/conv2d_1/kernel/read')\n",
      "('resnet_model/conv2d_1/kernel/read', 'resnet_model/conv2d_1/Conv2D')\n",
      "('resnet_model/conv2d_1/Conv2D', 'resnet_model/batch_normalization_1/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_1/gamma', 'resnet_model/batch_normalization_1/gamma/read')\n",
      "('resnet_model/batch_normalization_1/gamma/read', 'resnet_model/batch_normalization_1/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_1/beta', 'resnet_model/batch_normalization_1/beta/read')\n",
      "('resnet_model/batch_normalization_1/beta/read', 'resnet_model/batch_normalization_1/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_1/moving_mean', 'resnet_model/batch_normalization_1/moving_mean/read')\n",
      "('resnet_model/batch_normalization_1/moving_mean/read', 'resnet_model/batch_normalization_1/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_1/moving_variance', 'resnet_model/batch_normalization_1/moving_variance/read')\n",
      "('resnet_model/batch_normalization_1/moving_variance/read', 'resnet_model/batch_normalization_1/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_1/FusedBatchNorm', 'resnet_model/add')\n",
      "('resnet_model/conv2d_2/kernel', 'resnet_model/conv2d_2/kernel/read')\n",
      "('resnet_model/conv2d_2/kernel/read', 'resnet_model/conv2d_2/Conv2D')\n",
      "('resnet_model/conv2d_2/Conv2D', 'resnet_model/batch_normalization_2/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_2/gamma', 'resnet_model/batch_normalization_2/gamma/read')\n",
      "('resnet_model/batch_normalization_2/gamma/read', 'resnet_model/batch_normalization_2/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_2/beta', 'resnet_model/batch_normalization_2/beta/read')\n",
      "('resnet_model/batch_normalization_2/beta/read', 'resnet_model/batch_normalization_2/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_2/moving_mean', 'resnet_model/batch_normalization_2/moving_mean/read')\n",
      "('resnet_model/batch_normalization_2/moving_mean/read', 'resnet_model/batch_normalization_2/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_2/moving_variance', 'resnet_model/batch_normalization_2/moving_variance/read')\n",
      "('resnet_model/batch_normalization_2/moving_variance/read', 'resnet_model/batch_normalization_2/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_2/FusedBatchNorm', 'resnet_model/Relu_1')\n",
      "('resnet_model/Relu_1', 'resnet_model/conv2d_3/Conv2D')\n",
      "('resnet_model/conv2d_3/kernel', 'resnet_model/conv2d_3/kernel/read')\n",
      "('resnet_model/conv2d_3/kernel/read', 'resnet_model/conv2d_3/Conv2D')\n",
      "('resnet_model/conv2d_3/Conv2D', 'resnet_model/batch_normalization_3/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_3/gamma', 'resnet_model/batch_normalization_3/gamma/read')\n",
      "('resnet_model/batch_normalization_3/gamma/read', 'resnet_model/batch_normalization_3/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_3/beta', 'resnet_model/batch_normalization_3/beta/read')\n",
      "('resnet_model/batch_normalization_3/beta/read', 'resnet_model/batch_normalization_3/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_3/moving_mean', 'resnet_model/batch_normalization_3/moving_mean/read')\n",
      "('resnet_model/batch_normalization_3/moving_mean/read', 'resnet_model/batch_normalization_3/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_3/moving_variance', 'resnet_model/batch_normalization_3/moving_variance/read')\n",
      "('resnet_model/batch_normalization_3/moving_variance/read', 'resnet_model/batch_normalization_3/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_3/FusedBatchNorm', 'resnet_model/Relu_2')\n",
      "('resnet_model/Relu_2', 'resnet_model/conv2d_4/Conv2D')\n",
      "('resnet_model/conv2d_4/kernel', 'resnet_model/conv2d_4/kernel/read')\n",
      "('resnet_model/conv2d_4/kernel/read', 'resnet_model/conv2d_4/Conv2D')\n",
      "('resnet_model/conv2d_4/Conv2D', 'resnet_model/batch_normalization_4/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_4/gamma', 'resnet_model/batch_normalization_4/gamma/read')\n",
      "('resnet_model/batch_normalization_4/gamma/read', 'resnet_model/batch_normalization_4/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_4/beta', 'resnet_model/batch_normalization_4/beta/read')\n",
      "('resnet_model/batch_normalization_4/beta/read', 'resnet_model/batch_normalization_4/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_4/moving_mean', 'resnet_model/batch_normalization_4/moving_mean/read')\n",
      "('resnet_model/batch_normalization_4/moving_mean/read', 'resnet_model/batch_normalization_4/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_4/moving_variance', 'resnet_model/batch_normalization_4/moving_variance/read')\n",
      "('resnet_model/batch_normalization_4/moving_variance/read', 'resnet_model/batch_normalization_4/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_4/FusedBatchNorm', 'resnet_model/add')\n",
      "('resnet_model/add', 'resnet_model/Relu_3')\n",
      "('resnet_model/Relu_3', 'resnet_model/conv2d_5/Conv2D')\n",
      "('resnet_model/Relu_3', 'resnet_model/add_1')\n",
      "('resnet_model/conv2d_5/kernel', 'resnet_model/conv2d_5/kernel/read')\n",
      "('resnet_model/conv2d_5/kernel/read', 'resnet_model/conv2d_5/Conv2D')\n",
      "('resnet_model/conv2d_5/Conv2D', 'resnet_model/batch_normalization_5/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_5/gamma', 'resnet_model/batch_normalization_5/gamma/read')\n",
      "('resnet_model/batch_normalization_5/gamma/read', 'resnet_model/batch_normalization_5/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_5/beta', 'resnet_model/batch_normalization_5/beta/read')\n",
      "('resnet_model/batch_normalization_5/beta/read', 'resnet_model/batch_normalization_5/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_5/moving_mean', 'resnet_model/batch_normalization_5/moving_mean/read')\n",
      "('resnet_model/batch_normalization_5/moving_mean/read', 'resnet_model/batch_normalization_5/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_5/moving_variance', 'resnet_model/batch_normalization_5/moving_variance/read')\n",
      "('resnet_model/batch_normalization_5/moving_variance/read', 'resnet_model/batch_normalization_5/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_5/FusedBatchNorm', 'resnet_model/Relu_4')\n",
      "('resnet_model/Relu_4', 'resnet_model/conv2d_6/Conv2D')\n",
      "('resnet_model/conv2d_6/kernel', 'resnet_model/conv2d_6/kernel/read')\n",
      "('resnet_model/conv2d_6/kernel/read', 'resnet_model/conv2d_6/Conv2D')\n",
      "('resnet_model/conv2d_6/Conv2D', 'resnet_model/batch_normalization_6/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_6/gamma', 'resnet_model/batch_normalization_6/gamma/read')\n",
      "('resnet_model/batch_normalization_6/gamma/read', 'resnet_model/batch_normalization_6/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_6/beta', 'resnet_model/batch_normalization_6/beta/read')\n",
      "('resnet_model/batch_normalization_6/beta/read', 'resnet_model/batch_normalization_6/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_6/moving_mean', 'resnet_model/batch_normalization_6/moving_mean/read')\n",
      "('resnet_model/batch_normalization_6/moving_mean/read', 'resnet_model/batch_normalization_6/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_6/moving_variance', 'resnet_model/batch_normalization_6/moving_variance/read')\n",
      "('resnet_model/batch_normalization_6/moving_variance/read', 'resnet_model/batch_normalization_6/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_6/FusedBatchNorm', 'resnet_model/Relu_5')\n",
      "('resnet_model/Relu_5', 'resnet_model/conv2d_7/Conv2D')\n",
      "('resnet_model/conv2d_7/kernel', 'resnet_model/conv2d_7/kernel/read')\n",
      "('resnet_model/conv2d_7/kernel/read', 'resnet_model/conv2d_7/Conv2D')\n",
      "('resnet_model/conv2d_7/Conv2D', 'resnet_model/batch_normalization_7/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_7/gamma', 'resnet_model/batch_normalization_7/gamma/read')\n",
      "('resnet_model/batch_normalization_7/gamma/read', 'resnet_model/batch_normalization_7/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_7/beta', 'resnet_model/batch_normalization_7/beta/read')\n",
      "('resnet_model/batch_normalization_7/beta/read', 'resnet_model/batch_normalization_7/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_7/moving_mean', 'resnet_model/batch_normalization_7/moving_mean/read')\n",
      "('resnet_model/batch_normalization_7/moving_mean/read', 'resnet_model/batch_normalization_7/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_7/moving_variance', 'resnet_model/batch_normalization_7/moving_variance/read')\n",
      "('resnet_model/batch_normalization_7/moving_variance/read', 'resnet_model/batch_normalization_7/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_7/FusedBatchNorm', 'resnet_model/add_1')\n",
      "('resnet_model/add_1', 'resnet_model/Relu_6')\n",
      "('resnet_model/Relu_6', 'resnet_model/conv2d_8/Conv2D')\n",
      "('resnet_model/Relu_6', 'resnet_model/add_2')\n",
      "('resnet_model/conv2d_8/kernel', 'resnet_model/conv2d_8/kernel/read')\n",
      "('resnet_model/conv2d_8/kernel/read', 'resnet_model/conv2d_8/Conv2D')\n",
      "('resnet_model/conv2d_8/Conv2D', 'resnet_model/batch_normalization_8/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_8/gamma', 'resnet_model/batch_normalization_8/gamma/read')\n",
      "('resnet_model/batch_normalization_8/gamma/read', 'resnet_model/batch_normalization_8/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_8/beta', 'resnet_model/batch_normalization_8/beta/read')\n",
      "('resnet_model/batch_normalization_8/beta/read', 'resnet_model/batch_normalization_8/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_8/moving_mean', 'resnet_model/batch_normalization_8/moving_mean/read')\n",
      "('resnet_model/batch_normalization_8/moving_mean/read', 'resnet_model/batch_normalization_8/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_8/moving_variance', 'resnet_model/batch_normalization_8/moving_variance/read')\n",
      "('resnet_model/batch_normalization_8/moving_variance/read', 'resnet_model/batch_normalization_8/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_8/FusedBatchNorm', 'resnet_model/Relu_7')\n",
      "('resnet_model/Relu_7', 'resnet_model/conv2d_9/Conv2D')\n",
      "('resnet_model/conv2d_9/kernel', 'resnet_model/conv2d_9/kernel/read')\n",
      "('resnet_model/conv2d_9/kernel/read', 'resnet_model/conv2d_9/Conv2D')\n",
      "('resnet_model/conv2d_9/Conv2D', 'resnet_model/batch_normalization_9/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_9/gamma', 'resnet_model/batch_normalization_9/gamma/read')\n",
      "('resnet_model/batch_normalization_9/gamma/read', 'resnet_model/batch_normalization_9/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_9/beta', 'resnet_model/batch_normalization_9/beta/read')\n",
      "('resnet_model/batch_normalization_9/beta/read', 'resnet_model/batch_normalization_9/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_9/moving_mean', 'resnet_model/batch_normalization_9/moving_mean/read')\n",
      "('resnet_model/batch_normalization_9/moving_mean/read', 'resnet_model/batch_normalization_9/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_9/moving_variance', 'resnet_model/batch_normalization_9/moving_variance/read')\n",
      "('resnet_model/batch_normalization_9/moving_variance/read', 'resnet_model/batch_normalization_9/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_9/FusedBatchNorm', 'resnet_model/Relu_8')\n",
      "('resnet_model/Relu_8', 'resnet_model/conv2d_10/Conv2D')\n",
      "('resnet_model/conv2d_10/kernel', 'resnet_model/conv2d_10/kernel/read')\n",
      "('resnet_model/conv2d_10/kernel/read', 'resnet_model/conv2d_10/Conv2D')\n",
      "('resnet_model/conv2d_10/Conv2D', 'resnet_model/batch_normalization_10/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_10/gamma', 'resnet_model/batch_normalization_10/gamma/read')\n",
      "('resnet_model/batch_normalization_10/gamma/read', 'resnet_model/batch_normalization_10/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_10/beta', 'resnet_model/batch_normalization_10/beta/read')\n",
      "('resnet_model/batch_normalization_10/beta/read', 'resnet_model/batch_normalization_10/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_10/moving_mean', 'resnet_model/batch_normalization_10/moving_mean/read')\n",
      "('resnet_model/batch_normalization_10/moving_mean/read', 'resnet_model/batch_normalization_10/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_10/moving_variance', 'resnet_model/batch_normalization_10/moving_variance/read')\n",
      "('resnet_model/batch_normalization_10/moving_variance/read', 'resnet_model/batch_normalization_10/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_10/FusedBatchNorm', 'resnet_model/add_2')\n",
      "('resnet_model/add_2', 'resnet_model/Relu_9')\n",
      "('resnet_model/Relu_9', 'resnet_model/block_layer1')\n",
      "('resnet_model/block_layer1', 'resnet_model/Pad_1')\n",
      "('resnet_model/block_layer1', 'resnet_model/conv2d_12/Conv2D')\n",
      "('resnet_model/Pad_1/paddings', 'resnet_model/Pad_1')\n",
      "('resnet_model/Pad_1', 'resnet_model/conv2d_11/Conv2D')\n",
      "('resnet_model/conv2d_11/kernel', 'resnet_model/conv2d_11/kernel/read')\n",
      "('resnet_model/conv2d_11/kernel/read', 'resnet_model/conv2d_11/Conv2D')\n",
      "('resnet_model/conv2d_11/Conv2D', 'resnet_model/batch_normalization_11/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_11/gamma', 'resnet_model/batch_normalization_11/gamma/read')\n",
      "('resnet_model/batch_normalization_11/gamma/read', 'resnet_model/batch_normalization_11/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_11/beta', 'resnet_model/batch_normalization_11/beta/read')\n",
      "('resnet_model/batch_normalization_11/beta/read', 'resnet_model/batch_normalization_11/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_11/moving_mean', 'resnet_model/batch_normalization_11/moving_mean/read')\n",
      "('resnet_model/batch_normalization_11/moving_mean/read', 'resnet_model/batch_normalization_11/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_11/moving_variance', 'resnet_model/batch_normalization_11/moving_variance/read')\n",
      "('resnet_model/batch_normalization_11/moving_variance/read', 'resnet_model/batch_normalization_11/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_11/FusedBatchNorm', 'resnet_model/add_3')\n",
      "('resnet_model/conv2d_12/kernel', 'resnet_model/conv2d_12/kernel/read')\n",
      "('resnet_model/conv2d_12/kernel/read', 'resnet_model/conv2d_12/Conv2D')\n",
      "('resnet_model/conv2d_12/Conv2D', 'resnet_model/batch_normalization_12/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_12/gamma', 'resnet_model/batch_normalization_12/gamma/read')\n",
      "('resnet_model/batch_normalization_12/gamma/read', 'resnet_model/batch_normalization_12/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_12/beta', 'resnet_model/batch_normalization_12/beta/read')\n",
      "('resnet_model/batch_normalization_12/beta/read', 'resnet_model/batch_normalization_12/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_12/moving_mean', 'resnet_model/batch_normalization_12/moving_mean/read')\n",
      "('resnet_model/batch_normalization_12/moving_mean/read', 'resnet_model/batch_normalization_12/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_12/moving_variance', 'resnet_model/batch_normalization_12/moving_variance/read')\n",
      "('resnet_model/batch_normalization_12/moving_variance/read', 'resnet_model/batch_normalization_12/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_12/FusedBatchNorm', 'resnet_model/Relu_10')\n",
      "('resnet_model/Relu_10', 'resnet_model/Pad_2')\n",
      "('resnet_model/Pad_2/paddings', 'resnet_model/Pad_2')\n",
      "('resnet_model/Pad_2', 'resnet_model/conv2d_13/Conv2D')\n",
      "('resnet_model/conv2d_13/kernel', 'resnet_model/conv2d_13/kernel/read')\n",
      "('resnet_model/conv2d_13/kernel/read', 'resnet_model/conv2d_13/Conv2D')\n",
      "('resnet_model/conv2d_13/Conv2D', 'resnet_model/batch_normalization_13/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_13/gamma', 'resnet_model/batch_normalization_13/gamma/read')\n",
      "('resnet_model/batch_normalization_13/gamma/read', 'resnet_model/batch_normalization_13/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_13/beta', 'resnet_model/batch_normalization_13/beta/read')\n",
      "('resnet_model/batch_normalization_13/beta/read', 'resnet_model/batch_normalization_13/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_13/moving_mean', 'resnet_model/batch_normalization_13/moving_mean/read')\n",
      "('resnet_model/batch_normalization_13/moving_mean/read', 'resnet_model/batch_normalization_13/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_13/moving_variance', 'resnet_model/batch_normalization_13/moving_variance/read')\n",
      "('resnet_model/batch_normalization_13/moving_variance/read', 'resnet_model/batch_normalization_13/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_13/FusedBatchNorm', 'resnet_model/Relu_11')\n",
      "('resnet_model/Relu_11', 'resnet_model/conv2d_14/Conv2D')\n",
      "('resnet_model/conv2d_14/kernel', 'resnet_model/conv2d_14/kernel/read')\n",
      "('resnet_model/conv2d_14/kernel/read', 'resnet_model/conv2d_14/Conv2D')\n",
      "('resnet_model/conv2d_14/Conv2D', 'resnet_model/batch_normalization_14/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_14/gamma', 'resnet_model/batch_normalization_14/gamma/read')\n",
      "('resnet_model/batch_normalization_14/gamma/read', 'resnet_model/batch_normalization_14/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_14/beta', 'resnet_model/batch_normalization_14/beta/read')\n",
      "('resnet_model/batch_normalization_14/beta/read', 'resnet_model/batch_normalization_14/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_14/moving_mean', 'resnet_model/batch_normalization_14/moving_mean/read')\n",
      "('resnet_model/batch_normalization_14/moving_mean/read', 'resnet_model/batch_normalization_14/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_14/moving_variance', 'resnet_model/batch_normalization_14/moving_variance/read')\n",
      "('resnet_model/batch_normalization_14/moving_variance/read', 'resnet_model/batch_normalization_14/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_14/FusedBatchNorm', 'resnet_model/add_3')\n",
      "('resnet_model/add_3', 'resnet_model/Relu_12')\n",
      "('resnet_model/Relu_12', 'resnet_model/conv2d_15/Conv2D')\n",
      "('resnet_model/Relu_12', 'resnet_model/add_4')\n",
      "('resnet_model/conv2d_15/kernel', 'resnet_model/conv2d_15/kernel/read')\n",
      "('resnet_model/conv2d_15/kernel/read', 'resnet_model/conv2d_15/Conv2D')\n",
      "('resnet_model/conv2d_15/Conv2D', 'resnet_model/batch_normalization_15/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_15/gamma', 'resnet_model/batch_normalization_15/gamma/read')\n",
      "('resnet_model/batch_normalization_15/gamma/read', 'resnet_model/batch_normalization_15/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_15/beta', 'resnet_model/batch_normalization_15/beta/read')\n",
      "('resnet_model/batch_normalization_15/beta/read', 'resnet_model/batch_normalization_15/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_15/moving_mean', 'resnet_model/batch_normalization_15/moving_mean/read')\n",
      "('resnet_model/batch_normalization_15/moving_mean/read', 'resnet_model/batch_normalization_15/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_15/moving_variance', 'resnet_model/batch_normalization_15/moving_variance/read')\n",
      "('resnet_model/batch_normalization_15/moving_variance/read', 'resnet_model/batch_normalization_15/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_15/FusedBatchNorm', 'resnet_model/Relu_13')\n",
      "('resnet_model/Relu_13', 'resnet_model/conv2d_16/Conv2D')\n",
      "('resnet_model/conv2d_16/kernel', 'resnet_model/conv2d_16/kernel/read')\n",
      "('resnet_model/conv2d_16/kernel/read', 'resnet_model/conv2d_16/Conv2D')\n",
      "('resnet_model/conv2d_16/Conv2D', 'resnet_model/batch_normalization_16/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_16/gamma', 'resnet_model/batch_normalization_16/gamma/read')\n",
      "('resnet_model/batch_normalization_16/gamma/read', 'resnet_model/batch_normalization_16/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_16/beta', 'resnet_model/batch_normalization_16/beta/read')\n",
      "('resnet_model/batch_normalization_16/beta/read', 'resnet_model/batch_normalization_16/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_16/moving_mean', 'resnet_model/batch_normalization_16/moving_mean/read')\n",
      "('resnet_model/batch_normalization_16/moving_mean/read', 'resnet_model/batch_normalization_16/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_16/moving_variance', 'resnet_model/batch_normalization_16/moving_variance/read')\n",
      "('resnet_model/batch_normalization_16/moving_variance/read', 'resnet_model/batch_normalization_16/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_16/FusedBatchNorm', 'resnet_model/Relu_14')\n",
      "('resnet_model/Relu_14', 'resnet_model/conv2d_17/Conv2D')\n",
      "('resnet_model/conv2d_17/kernel', 'resnet_model/conv2d_17/kernel/read')\n",
      "('resnet_model/conv2d_17/kernel/read', 'resnet_model/conv2d_17/Conv2D')\n",
      "('resnet_model/conv2d_17/Conv2D', 'resnet_model/batch_normalization_17/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_17/gamma', 'resnet_model/batch_normalization_17/gamma/read')\n",
      "('resnet_model/batch_normalization_17/gamma/read', 'resnet_model/batch_normalization_17/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_17/beta', 'resnet_model/batch_normalization_17/beta/read')\n",
      "('resnet_model/batch_normalization_17/beta/read', 'resnet_model/batch_normalization_17/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_17/moving_mean', 'resnet_model/batch_normalization_17/moving_mean/read')\n",
      "('resnet_model/batch_normalization_17/moving_mean/read', 'resnet_model/batch_normalization_17/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_17/moving_variance', 'resnet_model/batch_normalization_17/moving_variance/read')\n",
      "('resnet_model/batch_normalization_17/moving_variance/read', 'resnet_model/batch_normalization_17/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_17/FusedBatchNorm', 'resnet_model/add_4')\n",
      "('resnet_model/add_4', 'resnet_model/Relu_15')\n",
      "('resnet_model/Relu_15', 'resnet_model/conv2d_18/Conv2D')\n",
      "('resnet_model/Relu_15', 'resnet_model/add_5')\n",
      "('resnet_model/conv2d_18/kernel', 'resnet_model/conv2d_18/kernel/read')\n",
      "('resnet_model/conv2d_18/kernel/read', 'resnet_model/conv2d_18/Conv2D')\n",
      "('resnet_model/conv2d_18/Conv2D', 'resnet_model/batch_normalization_18/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_18/gamma', 'resnet_model/batch_normalization_18/gamma/read')\n",
      "('resnet_model/batch_normalization_18/gamma/read', 'resnet_model/batch_normalization_18/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_18/beta', 'resnet_model/batch_normalization_18/beta/read')\n",
      "('resnet_model/batch_normalization_18/beta/read', 'resnet_model/batch_normalization_18/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_18/moving_mean', 'resnet_model/batch_normalization_18/moving_mean/read')\n",
      "('resnet_model/batch_normalization_18/moving_mean/read', 'resnet_model/batch_normalization_18/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_18/moving_variance', 'resnet_model/batch_normalization_18/moving_variance/read')\n",
      "('resnet_model/batch_normalization_18/moving_variance/read', 'resnet_model/batch_normalization_18/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_18/FusedBatchNorm', 'resnet_model/Relu_16')\n",
      "('resnet_model/Relu_16', 'resnet_model/conv2d_19/Conv2D')\n",
      "('resnet_model/conv2d_19/kernel', 'resnet_model/conv2d_19/kernel/read')\n",
      "('resnet_model/conv2d_19/kernel/read', 'resnet_model/conv2d_19/Conv2D')\n",
      "('resnet_model/conv2d_19/Conv2D', 'resnet_model/batch_normalization_19/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_19/gamma', 'resnet_model/batch_normalization_19/gamma/read')\n",
      "('resnet_model/batch_normalization_19/gamma/read', 'resnet_model/batch_normalization_19/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_19/beta', 'resnet_model/batch_normalization_19/beta/read')\n",
      "('resnet_model/batch_normalization_19/beta/read', 'resnet_model/batch_normalization_19/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_19/moving_mean', 'resnet_model/batch_normalization_19/moving_mean/read')\n",
      "('resnet_model/batch_normalization_19/moving_mean/read', 'resnet_model/batch_normalization_19/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_19/moving_variance', 'resnet_model/batch_normalization_19/moving_variance/read')\n",
      "('resnet_model/batch_normalization_19/moving_variance/read', 'resnet_model/batch_normalization_19/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_19/FusedBatchNorm', 'resnet_model/Relu_17')\n",
      "('resnet_model/Relu_17', 'resnet_model/conv2d_20/Conv2D')\n",
      "('resnet_model/conv2d_20/kernel', 'resnet_model/conv2d_20/kernel/read')\n",
      "('resnet_model/conv2d_20/kernel/read', 'resnet_model/conv2d_20/Conv2D')\n",
      "('resnet_model/conv2d_20/Conv2D', 'resnet_model/batch_normalization_20/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_20/gamma', 'resnet_model/batch_normalization_20/gamma/read')\n",
      "('resnet_model/batch_normalization_20/gamma/read', 'resnet_model/batch_normalization_20/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_20/beta', 'resnet_model/batch_normalization_20/beta/read')\n",
      "('resnet_model/batch_normalization_20/beta/read', 'resnet_model/batch_normalization_20/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_20/moving_mean', 'resnet_model/batch_normalization_20/moving_mean/read')\n",
      "('resnet_model/batch_normalization_20/moving_mean/read', 'resnet_model/batch_normalization_20/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_20/moving_variance', 'resnet_model/batch_normalization_20/moving_variance/read')\n",
      "('resnet_model/batch_normalization_20/moving_variance/read', 'resnet_model/batch_normalization_20/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_20/FusedBatchNorm', 'resnet_model/add_5')\n",
      "('resnet_model/add_5', 'resnet_model/Relu_18')\n",
      "('resnet_model/Relu_18', 'resnet_model/conv2d_21/Conv2D')\n",
      "('resnet_model/Relu_18', 'resnet_model/add_6')\n",
      "('resnet_model/conv2d_21/kernel', 'resnet_model/conv2d_21/kernel/read')\n",
      "('resnet_model/conv2d_21/kernel/read', 'resnet_model/conv2d_21/Conv2D')\n",
      "('resnet_model/conv2d_21/Conv2D', 'resnet_model/batch_normalization_21/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_21/gamma', 'resnet_model/batch_normalization_21/gamma/read')\n",
      "('resnet_model/batch_normalization_21/gamma/read', 'resnet_model/batch_normalization_21/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_21/beta', 'resnet_model/batch_normalization_21/beta/read')\n",
      "('resnet_model/batch_normalization_21/beta/read', 'resnet_model/batch_normalization_21/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_21/moving_mean', 'resnet_model/batch_normalization_21/moving_mean/read')\n",
      "('resnet_model/batch_normalization_21/moving_mean/read', 'resnet_model/batch_normalization_21/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_21/moving_variance', 'resnet_model/batch_normalization_21/moving_variance/read')\n",
      "('resnet_model/batch_normalization_21/moving_variance/read', 'resnet_model/batch_normalization_21/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_21/FusedBatchNorm', 'resnet_model/Relu_19')\n",
      "('resnet_model/Relu_19', 'resnet_model/conv2d_22/Conv2D')\n",
      "('resnet_model/conv2d_22/kernel', 'resnet_model/conv2d_22/kernel/read')\n",
      "('resnet_model/conv2d_22/kernel/read', 'resnet_model/conv2d_22/Conv2D')\n",
      "('resnet_model/conv2d_22/Conv2D', 'resnet_model/batch_normalization_22/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_22/gamma', 'resnet_model/batch_normalization_22/gamma/read')\n",
      "('resnet_model/batch_normalization_22/gamma/read', 'resnet_model/batch_normalization_22/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_22/beta', 'resnet_model/batch_normalization_22/beta/read')\n",
      "('resnet_model/batch_normalization_22/beta/read', 'resnet_model/batch_normalization_22/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_22/moving_mean', 'resnet_model/batch_normalization_22/moving_mean/read')\n",
      "('resnet_model/batch_normalization_22/moving_mean/read', 'resnet_model/batch_normalization_22/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_22/moving_variance', 'resnet_model/batch_normalization_22/moving_variance/read')\n",
      "('resnet_model/batch_normalization_22/moving_variance/read', 'resnet_model/batch_normalization_22/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_22/FusedBatchNorm', 'resnet_model/Relu_20')\n",
      "('resnet_model/Relu_20', 'resnet_model/conv2d_23/Conv2D')\n",
      "('resnet_model/conv2d_23/kernel', 'resnet_model/conv2d_23/kernel/read')\n",
      "('resnet_model/conv2d_23/kernel/read', 'resnet_model/conv2d_23/Conv2D')\n",
      "('resnet_model/conv2d_23/Conv2D', 'resnet_model/batch_normalization_23/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_23/gamma', 'resnet_model/batch_normalization_23/gamma/read')\n",
      "('resnet_model/batch_normalization_23/gamma/read', 'resnet_model/batch_normalization_23/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_23/beta', 'resnet_model/batch_normalization_23/beta/read')\n",
      "('resnet_model/batch_normalization_23/beta/read', 'resnet_model/batch_normalization_23/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_23/moving_mean', 'resnet_model/batch_normalization_23/moving_mean/read')\n",
      "('resnet_model/batch_normalization_23/moving_mean/read', 'resnet_model/batch_normalization_23/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_23/moving_variance', 'resnet_model/batch_normalization_23/moving_variance/read')\n",
      "('resnet_model/batch_normalization_23/moving_variance/read', 'resnet_model/batch_normalization_23/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_23/FusedBatchNorm', 'resnet_model/add_6')\n",
      "('resnet_model/add_6', 'resnet_model/Relu_21')\n",
      "('resnet_model/Relu_21', 'resnet_model/block_layer2')\n",
      "('resnet_model/block_layer2', 'resnet_model/Pad_3')\n",
      "('resnet_model/block_layer2', 'resnet_model/conv2d_25/Conv2D')\n",
      "('resnet_model/Pad_3/paddings', 'resnet_model/Pad_3')\n",
      "('resnet_model/Pad_3', 'resnet_model/conv2d_24/Conv2D')\n",
      "('resnet_model/conv2d_24/kernel', 'resnet_model/conv2d_24/kernel/read')\n",
      "('resnet_model/conv2d_24/kernel/read', 'resnet_model/conv2d_24/Conv2D')\n",
      "('resnet_model/conv2d_24/Conv2D', 'resnet_model/batch_normalization_24/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_24/gamma', 'resnet_model/batch_normalization_24/gamma/read')\n",
      "('resnet_model/batch_normalization_24/gamma/read', 'resnet_model/batch_normalization_24/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_24/beta', 'resnet_model/batch_normalization_24/beta/read')\n",
      "('resnet_model/batch_normalization_24/beta/read', 'resnet_model/batch_normalization_24/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_24/moving_mean', 'resnet_model/batch_normalization_24/moving_mean/read')\n",
      "('resnet_model/batch_normalization_24/moving_mean/read', 'resnet_model/batch_normalization_24/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_24/moving_variance', 'resnet_model/batch_normalization_24/moving_variance/read')\n",
      "('resnet_model/batch_normalization_24/moving_variance/read', 'resnet_model/batch_normalization_24/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_24/FusedBatchNorm', 'resnet_model/add_7')\n",
      "('resnet_model/conv2d_25/kernel', 'resnet_model/conv2d_25/kernel/read')\n",
      "('resnet_model/conv2d_25/kernel/read', 'resnet_model/conv2d_25/Conv2D')\n",
      "('resnet_model/conv2d_25/Conv2D', 'resnet_model/batch_normalization_25/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_25/gamma', 'resnet_model/batch_normalization_25/gamma/read')\n",
      "('resnet_model/batch_normalization_25/gamma/read', 'resnet_model/batch_normalization_25/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_25/beta', 'resnet_model/batch_normalization_25/beta/read')\n",
      "('resnet_model/batch_normalization_25/beta/read', 'resnet_model/batch_normalization_25/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_25/moving_mean', 'resnet_model/batch_normalization_25/moving_mean/read')\n",
      "('resnet_model/batch_normalization_25/moving_mean/read', 'resnet_model/batch_normalization_25/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_25/moving_variance', 'resnet_model/batch_normalization_25/moving_variance/read')\n",
      "('resnet_model/batch_normalization_25/moving_variance/read', 'resnet_model/batch_normalization_25/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_25/FusedBatchNorm', 'resnet_model/Relu_22')\n",
      "('resnet_model/Relu_22', 'resnet_model/Pad_4')\n",
      "('resnet_model/Pad_4/paddings', 'resnet_model/Pad_4')\n",
      "('resnet_model/Pad_4', 'resnet_model/conv2d_26/Conv2D')\n",
      "('resnet_model/conv2d_26/kernel', 'resnet_model/conv2d_26/kernel/read')\n",
      "('resnet_model/conv2d_26/kernel/read', 'resnet_model/conv2d_26/Conv2D')\n",
      "('resnet_model/conv2d_26/Conv2D', 'resnet_model/batch_normalization_26/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_26/gamma', 'resnet_model/batch_normalization_26/gamma/read')\n",
      "('resnet_model/batch_normalization_26/gamma/read', 'resnet_model/batch_normalization_26/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_26/beta', 'resnet_model/batch_normalization_26/beta/read')\n",
      "('resnet_model/batch_normalization_26/beta/read', 'resnet_model/batch_normalization_26/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_26/moving_mean', 'resnet_model/batch_normalization_26/moving_mean/read')\n",
      "('resnet_model/batch_normalization_26/moving_mean/read', 'resnet_model/batch_normalization_26/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_26/moving_variance', 'resnet_model/batch_normalization_26/moving_variance/read')\n",
      "('resnet_model/batch_normalization_26/moving_variance/read', 'resnet_model/batch_normalization_26/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_26/FusedBatchNorm', 'resnet_model/Relu_23')\n",
      "('resnet_model/Relu_23', 'resnet_model/conv2d_27/Conv2D')\n",
      "('resnet_model/conv2d_27/kernel', 'resnet_model/conv2d_27/kernel/read')\n",
      "('resnet_model/conv2d_27/kernel/read', 'resnet_model/conv2d_27/Conv2D')\n",
      "('resnet_model/conv2d_27/Conv2D', 'resnet_model/batch_normalization_27/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_27/gamma', 'resnet_model/batch_normalization_27/gamma/read')\n",
      "('resnet_model/batch_normalization_27/gamma/read', 'resnet_model/batch_normalization_27/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_27/beta', 'resnet_model/batch_normalization_27/beta/read')\n",
      "('resnet_model/batch_normalization_27/beta/read', 'resnet_model/batch_normalization_27/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_27/moving_mean', 'resnet_model/batch_normalization_27/moving_mean/read')\n",
      "('resnet_model/batch_normalization_27/moving_mean/read', 'resnet_model/batch_normalization_27/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_27/moving_variance', 'resnet_model/batch_normalization_27/moving_variance/read')\n",
      "('resnet_model/batch_normalization_27/moving_variance/read', 'resnet_model/batch_normalization_27/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_27/FusedBatchNorm', 'resnet_model/add_7')\n",
      "('resnet_model/add_7', 'resnet_model/Relu_24')\n",
      "('resnet_model/Relu_24', 'resnet_model/conv2d_28/Conv2D')\n",
      "('resnet_model/Relu_24', 'resnet_model/add_8')\n",
      "('resnet_model/conv2d_28/kernel', 'resnet_model/conv2d_28/kernel/read')\n",
      "('resnet_model/conv2d_28/kernel/read', 'resnet_model/conv2d_28/Conv2D')\n",
      "('resnet_model/conv2d_28/Conv2D', 'resnet_model/batch_normalization_28/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_28/gamma', 'resnet_model/batch_normalization_28/gamma/read')\n",
      "('resnet_model/batch_normalization_28/gamma/read', 'resnet_model/batch_normalization_28/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_28/beta', 'resnet_model/batch_normalization_28/beta/read')\n",
      "('resnet_model/batch_normalization_28/beta/read', 'resnet_model/batch_normalization_28/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_28/moving_mean', 'resnet_model/batch_normalization_28/moving_mean/read')\n",
      "('resnet_model/batch_normalization_28/moving_mean/read', 'resnet_model/batch_normalization_28/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_28/moving_variance', 'resnet_model/batch_normalization_28/moving_variance/read')\n",
      "('resnet_model/batch_normalization_28/moving_variance/read', 'resnet_model/batch_normalization_28/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_28/FusedBatchNorm', 'resnet_model/Relu_25')\n",
      "('resnet_model/Relu_25', 'resnet_model/conv2d_29/Conv2D')\n",
      "('resnet_model/conv2d_29/kernel', 'resnet_model/conv2d_29/kernel/read')\n",
      "('resnet_model/conv2d_29/kernel/read', 'resnet_model/conv2d_29/Conv2D')\n",
      "('resnet_model/conv2d_29/Conv2D', 'resnet_model/batch_normalization_29/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_29/gamma', 'resnet_model/batch_normalization_29/gamma/read')\n",
      "('resnet_model/batch_normalization_29/gamma/read', 'resnet_model/batch_normalization_29/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_29/beta', 'resnet_model/batch_normalization_29/beta/read')\n",
      "('resnet_model/batch_normalization_29/beta/read', 'resnet_model/batch_normalization_29/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_29/moving_mean', 'resnet_model/batch_normalization_29/moving_mean/read')\n",
      "('resnet_model/batch_normalization_29/moving_mean/read', 'resnet_model/batch_normalization_29/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_29/moving_variance', 'resnet_model/batch_normalization_29/moving_variance/read')\n",
      "('resnet_model/batch_normalization_29/moving_variance/read', 'resnet_model/batch_normalization_29/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_29/FusedBatchNorm', 'resnet_model/Relu_26')\n",
      "('resnet_model/Relu_26', 'resnet_model/conv2d_30/Conv2D')\n",
      "('resnet_model/conv2d_30/kernel', 'resnet_model/conv2d_30/kernel/read')\n",
      "('resnet_model/conv2d_30/kernel/read', 'resnet_model/conv2d_30/Conv2D')\n",
      "('resnet_model/conv2d_30/Conv2D', 'resnet_model/batch_normalization_30/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_30/gamma', 'resnet_model/batch_normalization_30/gamma/read')\n",
      "('resnet_model/batch_normalization_30/gamma/read', 'resnet_model/batch_normalization_30/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_30/beta', 'resnet_model/batch_normalization_30/beta/read')\n",
      "('resnet_model/batch_normalization_30/beta/read', 'resnet_model/batch_normalization_30/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_30/moving_mean', 'resnet_model/batch_normalization_30/moving_mean/read')\n",
      "('resnet_model/batch_normalization_30/moving_mean/read', 'resnet_model/batch_normalization_30/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_30/moving_variance', 'resnet_model/batch_normalization_30/moving_variance/read')\n",
      "('resnet_model/batch_normalization_30/moving_variance/read', 'resnet_model/batch_normalization_30/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_30/FusedBatchNorm', 'resnet_model/add_8')\n",
      "('resnet_model/add_8', 'resnet_model/Relu_27')\n",
      "('resnet_model/Relu_27', 'resnet_model/conv2d_31/Conv2D')\n",
      "('resnet_model/Relu_27', 'resnet_model/add_9')\n",
      "('resnet_model/conv2d_31/kernel', 'resnet_model/conv2d_31/kernel/read')\n",
      "('resnet_model/conv2d_31/kernel/read', 'resnet_model/conv2d_31/Conv2D')\n",
      "('resnet_model/conv2d_31/Conv2D', 'resnet_model/batch_normalization_31/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_31/gamma', 'resnet_model/batch_normalization_31/gamma/read')\n",
      "('resnet_model/batch_normalization_31/gamma/read', 'resnet_model/batch_normalization_31/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_31/beta', 'resnet_model/batch_normalization_31/beta/read')\n",
      "('resnet_model/batch_normalization_31/beta/read', 'resnet_model/batch_normalization_31/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_31/moving_mean', 'resnet_model/batch_normalization_31/moving_mean/read')\n",
      "('resnet_model/batch_normalization_31/moving_mean/read', 'resnet_model/batch_normalization_31/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_31/moving_variance', 'resnet_model/batch_normalization_31/moving_variance/read')\n",
      "('resnet_model/batch_normalization_31/moving_variance/read', 'resnet_model/batch_normalization_31/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_31/FusedBatchNorm', 'resnet_model/Relu_28')\n",
      "('resnet_model/Relu_28', 'resnet_model/conv2d_32/Conv2D')\n",
      "('resnet_model/conv2d_32/kernel', 'resnet_model/conv2d_32/kernel/read')\n",
      "('resnet_model/conv2d_32/kernel/read', 'resnet_model/conv2d_32/Conv2D')\n",
      "('resnet_model/conv2d_32/Conv2D', 'resnet_model/batch_normalization_32/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_32/gamma', 'resnet_model/batch_normalization_32/gamma/read')\n",
      "('resnet_model/batch_normalization_32/gamma/read', 'resnet_model/batch_normalization_32/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_32/beta', 'resnet_model/batch_normalization_32/beta/read')\n",
      "('resnet_model/batch_normalization_32/beta/read', 'resnet_model/batch_normalization_32/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_32/moving_mean', 'resnet_model/batch_normalization_32/moving_mean/read')\n",
      "('resnet_model/batch_normalization_32/moving_mean/read', 'resnet_model/batch_normalization_32/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_32/moving_variance', 'resnet_model/batch_normalization_32/moving_variance/read')\n",
      "('resnet_model/batch_normalization_32/moving_variance/read', 'resnet_model/batch_normalization_32/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_32/FusedBatchNorm', 'resnet_model/Relu_29')\n",
      "('resnet_model/Relu_29', 'resnet_model/conv2d_33/Conv2D')\n",
      "('resnet_model/conv2d_33/kernel', 'resnet_model/conv2d_33/kernel/read')\n",
      "('resnet_model/conv2d_33/kernel/read', 'resnet_model/conv2d_33/Conv2D')\n",
      "('resnet_model/conv2d_33/Conv2D', 'resnet_model/batch_normalization_33/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_33/gamma', 'resnet_model/batch_normalization_33/gamma/read')\n",
      "('resnet_model/batch_normalization_33/gamma/read', 'resnet_model/batch_normalization_33/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_33/beta', 'resnet_model/batch_normalization_33/beta/read')\n",
      "('resnet_model/batch_normalization_33/beta/read', 'resnet_model/batch_normalization_33/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_33/moving_mean', 'resnet_model/batch_normalization_33/moving_mean/read')\n",
      "('resnet_model/batch_normalization_33/moving_mean/read', 'resnet_model/batch_normalization_33/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_33/moving_variance', 'resnet_model/batch_normalization_33/moving_variance/read')\n",
      "('resnet_model/batch_normalization_33/moving_variance/read', 'resnet_model/batch_normalization_33/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_33/FusedBatchNorm', 'resnet_model/add_9')\n",
      "('resnet_model/add_9', 'resnet_model/Relu_30')\n",
      "('resnet_model/Relu_30', 'resnet_model/conv2d_34/Conv2D')\n",
      "('resnet_model/Relu_30', 'resnet_model/add_10')\n",
      "('resnet_model/conv2d_34/kernel', 'resnet_model/conv2d_34/kernel/read')\n",
      "('resnet_model/conv2d_34/kernel/read', 'resnet_model/conv2d_34/Conv2D')\n",
      "('resnet_model/conv2d_34/Conv2D', 'resnet_model/batch_normalization_34/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_34/gamma', 'resnet_model/batch_normalization_34/gamma/read')\n",
      "('resnet_model/batch_normalization_34/gamma/read', 'resnet_model/batch_normalization_34/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_34/beta', 'resnet_model/batch_normalization_34/beta/read')\n",
      "('resnet_model/batch_normalization_34/beta/read', 'resnet_model/batch_normalization_34/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_34/moving_mean', 'resnet_model/batch_normalization_34/moving_mean/read')\n",
      "('resnet_model/batch_normalization_34/moving_mean/read', 'resnet_model/batch_normalization_34/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_34/moving_variance', 'resnet_model/batch_normalization_34/moving_variance/read')\n",
      "('resnet_model/batch_normalization_34/moving_variance/read', 'resnet_model/batch_normalization_34/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_34/FusedBatchNorm', 'resnet_model/Relu_31')\n",
      "('resnet_model/Relu_31', 'resnet_model/conv2d_35/Conv2D')\n",
      "('resnet_model/conv2d_35/kernel', 'resnet_model/conv2d_35/kernel/read')\n",
      "('resnet_model/conv2d_35/kernel/read', 'resnet_model/conv2d_35/Conv2D')\n",
      "('resnet_model/conv2d_35/Conv2D', 'resnet_model/batch_normalization_35/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_35/gamma', 'resnet_model/batch_normalization_35/gamma/read')\n",
      "('resnet_model/batch_normalization_35/gamma/read', 'resnet_model/batch_normalization_35/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_35/beta', 'resnet_model/batch_normalization_35/beta/read')\n",
      "('resnet_model/batch_normalization_35/beta/read', 'resnet_model/batch_normalization_35/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_35/moving_mean', 'resnet_model/batch_normalization_35/moving_mean/read')\n",
      "('resnet_model/batch_normalization_35/moving_mean/read', 'resnet_model/batch_normalization_35/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_35/moving_variance', 'resnet_model/batch_normalization_35/moving_variance/read')\n",
      "('resnet_model/batch_normalization_35/moving_variance/read', 'resnet_model/batch_normalization_35/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_35/FusedBatchNorm', 'resnet_model/Relu_32')\n",
      "('resnet_model/Relu_32', 'resnet_model/conv2d_36/Conv2D')\n",
      "('resnet_model/conv2d_36/kernel', 'resnet_model/conv2d_36/kernel/read')\n",
      "('resnet_model/conv2d_36/kernel/read', 'resnet_model/conv2d_36/Conv2D')\n",
      "('resnet_model/conv2d_36/Conv2D', 'resnet_model/batch_normalization_36/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_36/gamma', 'resnet_model/batch_normalization_36/gamma/read')\n",
      "('resnet_model/batch_normalization_36/gamma/read', 'resnet_model/batch_normalization_36/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_36/beta', 'resnet_model/batch_normalization_36/beta/read')\n",
      "('resnet_model/batch_normalization_36/beta/read', 'resnet_model/batch_normalization_36/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_36/moving_mean', 'resnet_model/batch_normalization_36/moving_mean/read')\n",
      "('resnet_model/batch_normalization_36/moving_mean/read', 'resnet_model/batch_normalization_36/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_36/moving_variance', 'resnet_model/batch_normalization_36/moving_variance/read')\n",
      "('resnet_model/batch_normalization_36/moving_variance/read', 'resnet_model/batch_normalization_36/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_36/FusedBatchNorm', 'resnet_model/add_10')\n",
      "('resnet_model/add_10', 'resnet_model/Relu_33')\n",
      "('resnet_model/Relu_33', 'resnet_model/conv2d_37/Conv2D')\n",
      "('resnet_model/Relu_33', 'resnet_model/add_11')\n",
      "('resnet_model/conv2d_37/kernel', 'resnet_model/conv2d_37/kernel/read')\n",
      "('resnet_model/conv2d_37/kernel/read', 'resnet_model/conv2d_37/Conv2D')\n",
      "('resnet_model/conv2d_37/Conv2D', 'resnet_model/batch_normalization_37/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_37/gamma', 'resnet_model/batch_normalization_37/gamma/read')\n",
      "('resnet_model/batch_normalization_37/gamma/read', 'resnet_model/batch_normalization_37/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_37/beta', 'resnet_model/batch_normalization_37/beta/read')\n",
      "('resnet_model/batch_normalization_37/beta/read', 'resnet_model/batch_normalization_37/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_37/moving_mean', 'resnet_model/batch_normalization_37/moving_mean/read')\n",
      "('resnet_model/batch_normalization_37/moving_mean/read', 'resnet_model/batch_normalization_37/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_37/moving_variance', 'resnet_model/batch_normalization_37/moving_variance/read')\n",
      "('resnet_model/batch_normalization_37/moving_variance/read', 'resnet_model/batch_normalization_37/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_37/FusedBatchNorm', 'resnet_model/Relu_34')\n",
      "('resnet_model/Relu_34', 'resnet_model/conv2d_38/Conv2D')\n",
      "('resnet_model/conv2d_38/kernel', 'resnet_model/conv2d_38/kernel/read')\n",
      "('resnet_model/conv2d_38/kernel/read', 'resnet_model/conv2d_38/Conv2D')\n",
      "('resnet_model/conv2d_38/Conv2D', 'resnet_model/batch_normalization_38/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_38/gamma', 'resnet_model/batch_normalization_38/gamma/read')\n",
      "('resnet_model/batch_normalization_38/gamma/read', 'resnet_model/batch_normalization_38/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_38/beta', 'resnet_model/batch_normalization_38/beta/read')\n",
      "('resnet_model/batch_normalization_38/beta/read', 'resnet_model/batch_normalization_38/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_38/moving_mean', 'resnet_model/batch_normalization_38/moving_mean/read')\n",
      "('resnet_model/batch_normalization_38/moving_mean/read', 'resnet_model/batch_normalization_38/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_38/moving_variance', 'resnet_model/batch_normalization_38/moving_variance/read')\n",
      "('resnet_model/batch_normalization_38/moving_variance/read', 'resnet_model/batch_normalization_38/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_38/FusedBatchNorm', 'resnet_model/Relu_35')\n",
      "('resnet_model/Relu_35', 'resnet_model/conv2d_39/Conv2D')\n",
      "('resnet_model/conv2d_39/kernel', 'resnet_model/conv2d_39/kernel/read')\n",
      "('resnet_model/conv2d_39/kernel/read', 'resnet_model/conv2d_39/Conv2D')\n",
      "('resnet_model/conv2d_39/Conv2D', 'resnet_model/batch_normalization_39/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_39/gamma', 'resnet_model/batch_normalization_39/gamma/read')\n",
      "('resnet_model/batch_normalization_39/gamma/read', 'resnet_model/batch_normalization_39/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_39/beta', 'resnet_model/batch_normalization_39/beta/read')\n",
      "('resnet_model/batch_normalization_39/beta/read', 'resnet_model/batch_normalization_39/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_39/moving_mean', 'resnet_model/batch_normalization_39/moving_mean/read')\n",
      "('resnet_model/batch_normalization_39/moving_mean/read', 'resnet_model/batch_normalization_39/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_39/moving_variance', 'resnet_model/batch_normalization_39/moving_variance/read')\n",
      "('resnet_model/batch_normalization_39/moving_variance/read', 'resnet_model/batch_normalization_39/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_39/FusedBatchNorm', 'resnet_model/add_11')\n",
      "('resnet_model/add_11', 'resnet_model/Relu_36')\n",
      "('resnet_model/Relu_36', 'resnet_model/conv2d_40/Conv2D')\n",
      "('resnet_model/Relu_36', 'resnet_model/add_12')\n",
      "('resnet_model/conv2d_40/kernel', 'resnet_model/conv2d_40/kernel/read')\n",
      "('resnet_model/conv2d_40/kernel/read', 'resnet_model/conv2d_40/Conv2D')\n",
      "('resnet_model/conv2d_40/Conv2D', 'resnet_model/batch_normalization_40/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_40/gamma', 'resnet_model/batch_normalization_40/gamma/read')\n",
      "('resnet_model/batch_normalization_40/gamma/read', 'resnet_model/batch_normalization_40/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_40/beta', 'resnet_model/batch_normalization_40/beta/read')\n",
      "('resnet_model/batch_normalization_40/beta/read', 'resnet_model/batch_normalization_40/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_40/moving_mean', 'resnet_model/batch_normalization_40/moving_mean/read')\n",
      "('resnet_model/batch_normalization_40/moving_mean/read', 'resnet_model/batch_normalization_40/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_40/moving_variance', 'resnet_model/batch_normalization_40/moving_variance/read')\n",
      "('resnet_model/batch_normalization_40/moving_variance/read', 'resnet_model/batch_normalization_40/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_40/FusedBatchNorm', 'resnet_model/Relu_37')\n",
      "('resnet_model/Relu_37', 'resnet_model/conv2d_41/Conv2D')\n",
      "('resnet_model/conv2d_41/kernel', 'resnet_model/conv2d_41/kernel/read')\n",
      "('resnet_model/conv2d_41/kernel/read', 'resnet_model/conv2d_41/Conv2D')\n",
      "('resnet_model/conv2d_41/Conv2D', 'resnet_model/batch_normalization_41/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_41/gamma', 'resnet_model/batch_normalization_41/gamma/read')\n",
      "('resnet_model/batch_normalization_41/gamma/read', 'resnet_model/batch_normalization_41/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_41/beta', 'resnet_model/batch_normalization_41/beta/read')\n",
      "('resnet_model/batch_normalization_41/beta/read', 'resnet_model/batch_normalization_41/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_41/moving_mean', 'resnet_model/batch_normalization_41/moving_mean/read')\n",
      "('resnet_model/batch_normalization_41/moving_mean/read', 'resnet_model/batch_normalization_41/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_41/moving_variance', 'resnet_model/batch_normalization_41/moving_variance/read')\n",
      "('resnet_model/batch_normalization_41/moving_variance/read', 'resnet_model/batch_normalization_41/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_41/FusedBatchNorm', 'resnet_model/Relu_38')\n",
      "('resnet_model/Relu_38', 'resnet_model/conv2d_42/Conv2D')\n",
      "('resnet_model/conv2d_42/kernel', 'resnet_model/conv2d_42/kernel/read')\n",
      "('resnet_model/conv2d_42/kernel/read', 'resnet_model/conv2d_42/Conv2D')\n",
      "('resnet_model/conv2d_42/Conv2D', 'resnet_model/batch_normalization_42/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_42/gamma', 'resnet_model/batch_normalization_42/gamma/read')\n",
      "('resnet_model/batch_normalization_42/gamma/read', 'resnet_model/batch_normalization_42/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_42/beta', 'resnet_model/batch_normalization_42/beta/read')\n",
      "('resnet_model/batch_normalization_42/beta/read', 'resnet_model/batch_normalization_42/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_42/moving_mean', 'resnet_model/batch_normalization_42/moving_mean/read')\n",
      "('resnet_model/batch_normalization_42/moving_mean/read', 'resnet_model/batch_normalization_42/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_42/moving_variance', 'resnet_model/batch_normalization_42/moving_variance/read')\n",
      "('resnet_model/batch_normalization_42/moving_variance/read', 'resnet_model/batch_normalization_42/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_42/FusedBatchNorm', 'resnet_model/add_12')\n",
      "('resnet_model/add_12', 'resnet_model/Relu_39')\n",
      "('resnet_model/Relu_39', 'resnet_model/block_layer3')\n",
      "('resnet_model/block_layer3', 'resnet_model/Pad_5')\n",
      "('resnet_model/block_layer3', 'resnet_model/conv2d_44/Conv2D')\n",
      "('resnet_model/Pad_5/paddings', 'resnet_model/Pad_5')\n",
      "('resnet_model/Pad_5', 'resnet_model/conv2d_43/Conv2D')\n",
      "('resnet_model/conv2d_43/kernel', 'resnet_model/conv2d_43/kernel/read')\n",
      "('resnet_model/conv2d_43/kernel/read', 'resnet_model/conv2d_43/Conv2D')\n",
      "('resnet_model/conv2d_43/Conv2D', 'resnet_model/batch_normalization_43/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_43/gamma', 'resnet_model/batch_normalization_43/gamma/read')\n",
      "('resnet_model/batch_normalization_43/gamma/read', 'resnet_model/batch_normalization_43/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_43/beta', 'resnet_model/batch_normalization_43/beta/read')\n",
      "('resnet_model/batch_normalization_43/beta/read', 'resnet_model/batch_normalization_43/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_43/moving_mean', 'resnet_model/batch_normalization_43/moving_mean/read')\n",
      "('resnet_model/batch_normalization_43/moving_mean/read', 'resnet_model/batch_normalization_43/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_43/moving_variance', 'resnet_model/batch_normalization_43/moving_variance/read')\n",
      "('resnet_model/batch_normalization_43/moving_variance/read', 'resnet_model/batch_normalization_43/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_43/FusedBatchNorm', 'resnet_model/add_13')\n",
      "('resnet_model/conv2d_44/kernel', 'resnet_model/conv2d_44/kernel/read')\n",
      "('resnet_model/conv2d_44/kernel/read', 'resnet_model/conv2d_44/Conv2D')\n",
      "('resnet_model/conv2d_44/Conv2D', 'resnet_model/batch_normalization_44/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_44/gamma', 'resnet_model/batch_normalization_44/gamma/read')\n",
      "('resnet_model/batch_normalization_44/gamma/read', 'resnet_model/batch_normalization_44/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_44/beta', 'resnet_model/batch_normalization_44/beta/read')\n",
      "('resnet_model/batch_normalization_44/beta/read', 'resnet_model/batch_normalization_44/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_44/moving_mean', 'resnet_model/batch_normalization_44/moving_mean/read')\n",
      "('resnet_model/batch_normalization_44/moving_mean/read', 'resnet_model/batch_normalization_44/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_44/moving_variance', 'resnet_model/batch_normalization_44/moving_variance/read')\n",
      "('resnet_model/batch_normalization_44/moving_variance/read', 'resnet_model/batch_normalization_44/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_44/FusedBatchNorm', 'resnet_model/Relu_40')\n",
      "('resnet_model/Relu_40', 'resnet_model/Pad_6')\n",
      "('resnet_model/Pad_6/paddings', 'resnet_model/Pad_6')\n",
      "('resnet_model/Pad_6', 'resnet_model/conv2d_45/Conv2D')\n",
      "('resnet_model/conv2d_45/kernel', 'resnet_model/conv2d_45/kernel/read')\n",
      "('resnet_model/conv2d_45/kernel/read', 'resnet_model/conv2d_45/Conv2D')\n",
      "('resnet_model/conv2d_45/Conv2D', 'resnet_model/batch_normalization_45/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_45/gamma', 'resnet_model/batch_normalization_45/gamma/read')\n",
      "('resnet_model/batch_normalization_45/gamma/read', 'resnet_model/batch_normalization_45/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_45/beta', 'resnet_model/batch_normalization_45/beta/read')\n",
      "('resnet_model/batch_normalization_45/beta/read', 'resnet_model/batch_normalization_45/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_45/moving_mean', 'resnet_model/batch_normalization_45/moving_mean/read')\n",
      "('resnet_model/batch_normalization_45/moving_mean/read', 'resnet_model/batch_normalization_45/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_45/moving_variance', 'resnet_model/batch_normalization_45/moving_variance/read')\n",
      "('resnet_model/batch_normalization_45/moving_variance/read', 'resnet_model/batch_normalization_45/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_45/FusedBatchNorm', 'resnet_model/Relu_41')\n",
      "('resnet_model/Relu_41', 'resnet_model/conv2d_46/Conv2D')\n",
      "('resnet_model/conv2d_46/kernel', 'resnet_model/conv2d_46/kernel/read')\n",
      "('resnet_model/conv2d_46/kernel/read', 'resnet_model/conv2d_46/Conv2D')\n",
      "('resnet_model/conv2d_46/Conv2D', 'resnet_model/batch_normalization_46/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_46/gamma', 'resnet_model/batch_normalization_46/gamma/read')\n",
      "('resnet_model/batch_normalization_46/gamma/read', 'resnet_model/batch_normalization_46/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_46/beta', 'resnet_model/batch_normalization_46/beta/read')\n",
      "('resnet_model/batch_normalization_46/beta/read', 'resnet_model/batch_normalization_46/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_46/moving_mean', 'resnet_model/batch_normalization_46/moving_mean/read')\n",
      "('resnet_model/batch_normalization_46/moving_mean/read', 'resnet_model/batch_normalization_46/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_46/moving_variance', 'resnet_model/batch_normalization_46/moving_variance/read')\n",
      "('resnet_model/batch_normalization_46/moving_variance/read', 'resnet_model/batch_normalization_46/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_46/FusedBatchNorm', 'resnet_model/add_13')\n",
      "('resnet_model/add_13', 'resnet_model/Relu_42')\n",
      "('resnet_model/Relu_42', 'resnet_model/conv2d_47/Conv2D')\n",
      "('resnet_model/Relu_42', 'resnet_model/add_14')\n",
      "('resnet_model/conv2d_47/kernel', 'resnet_model/conv2d_47/kernel/read')\n",
      "('resnet_model/conv2d_47/kernel/read', 'resnet_model/conv2d_47/Conv2D')\n",
      "('resnet_model/conv2d_47/Conv2D', 'resnet_model/batch_normalization_47/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_47/gamma', 'resnet_model/batch_normalization_47/gamma/read')\n",
      "('resnet_model/batch_normalization_47/gamma/read', 'resnet_model/batch_normalization_47/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_47/beta', 'resnet_model/batch_normalization_47/beta/read')\n",
      "('resnet_model/batch_normalization_47/beta/read', 'resnet_model/batch_normalization_47/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_47/moving_mean', 'resnet_model/batch_normalization_47/moving_mean/read')\n",
      "('resnet_model/batch_normalization_47/moving_mean/read', 'resnet_model/batch_normalization_47/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_47/moving_variance', 'resnet_model/batch_normalization_47/moving_variance/read')\n",
      "('resnet_model/batch_normalization_47/moving_variance/read', 'resnet_model/batch_normalization_47/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_47/FusedBatchNorm', 'resnet_model/Relu_43')\n",
      "('resnet_model/Relu_43', 'resnet_model/conv2d_48/Conv2D')\n",
      "('resnet_model/conv2d_48/kernel', 'resnet_model/conv2d_48/kernel/read')\n",
      "('resnet_model/conv2d_48/kernel/read', 'resnet_model/conv2d_48/Conv2D')\n",
      "('resnet_model/conv2d_48/Conv2D', 'resnet_model/batch_normalization_48/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_48/gamma', 'resnet_model/batch_normalization_48/gamma/read')\n",
      "('resnet_model/batch_normalization_48/gamma/read', 'resnet_model/batch_normalization_48/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_48/beta', 'resnet_model/batch_normalization_48/beta/read')\n",
      "('resnet_model/batch_normalization_48/beta/read', 'resnet_model/batch_normalization_48/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_48/moving_mean', 'resnet_model/batch_normalization_48/moving_mean/read')\n",
      "('resnet_model/batch_normalization_48/moving_mean/read', 'resnet_model/batch_normalization_48/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_48/moving_variance', 'resnet_model/batch_normalization_48/moving_variance/read')\n",
      "('resnet_model/batch_normalization_48/moving_variance/read', 'resnet_model/batch_normalization_48/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_48/FusedBatchNorm', 'resnet_model/Relu_44')\n",
      "('resnet_model/Relu_44', 'resnet_model/conv2d_49/Conv2D')\n",
      "('resnet_model/conv2d_49/kernel', 'resnet_model/conv2d_49/kernel/read')\n",
      "('resnet_model/conv2d_49/kernel/read', 'resnet_model/conv2d_49/Conv2D')\n",
      "('resnet_model/conv2d_49/Conv2D', 'resnet_model/batch_normalization_49/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_49/gamma', 'resnet_model/batch_normalization_49/gamma/read')\n",
      "('resnet_model/batch_normalization_49/gamma/read', 'resnet_model/batch_normalization_49/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_49/beta', 'resnet_model/batch_normalization_49/beta/read')\n",
      "('resnet_model/batch_normalization_49/beta/read', 'resnet_model/batch_normalization_49/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_49/moving_mean', 'resnet_model/batch_normalization_49/moving_mean/read')\n",
      "('resnet_model/batch_normalization_49/moving_mean/read', 'resnet_model/batch_normalization_49/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_49/moving_variance', 'resnet_model/batch_normalization_49/moving_variance/read')\n",
      "('resnet_model/batch_normalization_49/moving_variance/read', 'resnet_model/batch_normalization_49/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_49/FusedBatchNorm', 'resnet_model/add_14')\n",
      "('resnet_model/add_14', 'resnet_model/Relu_45')\n",
      "('resnet_model/Relu_45', 'resnet_model/conv2d_50/Conv2D')\n",
      "('resnet_model/Relu_45', 'resnet_model/add_15')\n",
      "('resnet_model/conv2d_50/kernel', 'resnet_model/conv2d_50/kernel/read')\n",
      "('resnet_model/conv2d_50/kernel/read', 'resnet_model/conv2d_50/Conv2D')\n",
      "('resnet_model/conv2d_50/Conv2D', 'resnet_model/batch_normalization_50/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_50/gamma', 'resnet_model/batch_normalization_50/gamma/read')\n",
      "('resnet_model/batch_normalization_50/gamma/read', 'resnet_model/batch_normalization_50/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_50/beta', 'resnet_model/batch_normalization_50/beta/read')\n",
      "('resnet_model/batch_normalization_50/beta/read', 'resnet_model/batch_normalization_50/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_50/moving_mean', 'resnet_model/batch_normalization_50/moving_mean/read')\n",
      "('resnet_model/batch_normalization_50/moving_mean/read', 'resnet_model/batch_normalization_50/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_50/moving_variance', 'resnet_model/batch_normalization_50/moving_variance/read')\n",
      "('resnet_model/batch_normalization_50/moving_variance/read', 'resnet_model/batch_normalization_50/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_50/FusedBatchNorm', 'resnet_model/Relu_46')\n",
      "('resnet_model/Relu_46', 'resnet_model/conv2d_51/Conv2D')\n",
      "('resnet_model/conv2d_51/kernel', 'resnet_model/conv2d_51/kernel/read')\n",
      "('resnet_model/conv2d_51/kernel/read', 'resnet_model/conv2d_51/Conv2D')\n",
      "('resnet_model/conv2d_51/Conv2D', 'resnet_model/batch_normalization_51/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_51/gamma', 'resnet_model/batch_normalization_51/gamma/read')\n",
      "('resnet_model/batch_normalization_51/gamma/read', 'resnet_model/batch_normalization_51/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_51/beta', 'resnet_model/batch_normalization_51/beta/read')\n",
      "('resnet_model/batch_normalization_51/beta/read', 'resnet_model/batch_normalization_51/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_51/moving_mean', 'resnet_model/batch_normalization_51/moving_mean/read')\n",
      "('resnet_model/batch_normalization_51/moving_mean/read', 'resnet_model/batch_normalization_51/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_51/moving_variance', 'resnet_model/batch_normalization_51/moving_variance/read')\n",
      "('resnet_model/batch_normalization_51/moving_variance/read', 'resnet_model/batch_normalization_51/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_51/FusedBatchNorm', 'resnet_model/Relu_47')\n",
      "('resnet_model/Relu_47', 'resnet_model/conv2d_52/Conv2D')\n",
      "('resnet_model/conv2d_52/kernel', 'resnet_model/conv2d_52/kernel/read')\n",
      "('resnet_model/conv2d_52/kernel/read', 'resnet_model/conv2d_52/Conv2D')\n",
      "('resnet_model/conv2d_52/Conv2D', 'resnet_model/batch_normalization_52/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_52/gamma', 'resnet_model/batch_normalization_52/gamma/read')\n",
      "('resnet_model/batch_normalization_52/gamma/read', 'resnet_model/batch_normalization_52/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_52/beta', 'resnet_model/batch_normalization_52/beta/read')\n",
      "('resnet_model/batch_normalization_52/beta/read', 'resnet_model/batch_normalization_52/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_52/moving_mean', 'resnet_model/batch_normalization_52/moving_mean/read')\n",
      "('resnet_model/batch_normalization_52/moving_mean/read', 'resnet_model/batch_normalization_52/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_52/moving_variance', 'resnet_model/batch_normalization_52/moving_variance/read')\n",
      "('resnet_model/batch_normalization_52/moving_variance/read', 'resnet_model/batch_normalization_52/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_52/FusedBatchNorm', 'resnet_model/add_15')\n",
      "('resnet_model/add_15', 'resnet_model/Relu_48')\n",
      "('resnet_model/Relu_48', 'resnet_model/block_layer4')\n",
      "('resnet_model/block_layer4', 'resnet_model/Mean')\n",
      "('resnet_model/Mean/reduction_indices', 'resnet_model/Mean')\n",
      "('resnet_model/Mean', 'resnet_model/final_reduce_mean')\n",
      "('resnet_model/final_reduce_mean', 'resnet_model/Squeeze')\n",
      "('resnet_model/Squeeze', 'resnet_model/dense/MatMul')\n",
      "('resnet_model/dense/kernel', 'resnet_model/dense/kernel/read')\n",
      "('resnet_model/dense/kernel/read', 'resnet_model/dense/MatMul')\n",
      "('resnet_model/dense/bias', 'resnet_model/dense/bias/read')\n",
      "('resnet_model/dense/bias/read', 'resnet_model/dense/BiasAdd')\n",
      "('resnet_model/dense/MatMul', 'resnet_model/dense/BiasAdd')\n",
      "('resnet_model/dense/BiasAdd', 'resnet_model/final_dense')\n",
      "('resnet_model/final_dense', 'ArgMax')\n",
      "('resnet_model/final_dense', 'softmax_tensor')\n",
      "('ArgMax/dimension', 'ArgMax')\n"
     ]
    }
   ],
   "source": [
    "for i in list(G.edges):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5eda6c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = ['Conv2D', 'MatMul', 'FusedBatchNorm', 'BiasAdd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "75ad8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "for node in graph_def.node:\n",
    "    if node.op in node_list:\n",
    "        if G.has_node(node.name)==False:\n",
    "            G.add_node(node.name)\n",
    "        #print(node.input)\n",
    "        for inp in node.input:\n",
    "            inp = master_dict[inp]\n",
    "            #print(inp.name)\n",
    "            if inp.op == 'Identity':\n",
    "                inp = master_dict[inp.input[0]]\n",
    "                #print(inp.name)\n",
    "                if inp.op == 'Const' and inp.attr['dtype'].type<=1:\n",
    "                    if G.has_node(inp.name)== False:\n",
    "                        G.add_node(inp.name)\n",
    "                    G.add_edge(inp.name,node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e533fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_model/batch_normalization/FusedBatchNorm\n",
      "resnet_model/batch_normalization_1/FusedBatchNorm\n",
      "resnet_model/batch_normalization_2/FusedBatchNorm\n",
      "resnet_model/batch_normalization_3/FusedBatchNorm\n",
      "resnet_model/batch_normalization_4/FusedBatchNorm\n",
      "resnet_model/batch_normalization_5/FusedBatchNorm\n",
      "resnet_model/batch_normalization_6/FusedBatchNorm\n",
      "resnet_model/batch_normalization_7/FusedBatchNorm\n",
      "resnet_model/batch_normalization_8/FusedBatchNorm\n",
      "resnet_model/batch_normalization_9/FusedBatchNorm\n",
      "resnet_model/batch_normalization_10/FusedBatchNorm\n",
      "resnet_model/batch_normalization_11/FusedBatchNorm\n",
      "resnet_model/batch_normalization_12/FusedBatchNorm\n",
      "resnet_model/batch_normalization_13/FusedBatchNorm\n",
      "resnet_model/batch_normalization_14/FusedBatchNorm\n",
      "resnet_model/batch_normalization_15/FusedBatchNorm\n",
      "resnet_model/batch_normalization_16/FusedBatchNorm\n",
      "resnet_model/batch_normalization_17/FusedBatchNorm\n",
      "resnet_model/batch_normalization_18/FusedBatchNorm\n",
      "resnet_model/batch_normalization_19/FusedBatchNorm\n",
      "resnet_model/batch_normalization_20/FusedBatchNorm\n",
      "resnet_model/batch_normalization_21/FusedBatchNorm\n",
      "resnet_model/batch_normalization_22/FusedBatchNorm\n",
      "resnet_model/batch_normalization_23/FusedBatchNorm\n",
      "resnet_model/batch_normalization_24/FusedBatchNorm\n",
      "resnet_model/batch_normalization_25/FusedBatchNorm\n",
      "resnet_model/batch_normalization_26/FusedBatchNorm\n",
      "resnet_model/batch_normalization_27/FusedBatchNorm\n",
      "resnet_model/batch_normalization_28/FusedBatchNorm\n",
      "resnet_model/batch_normalization_29/FusedBatchNorm\n",
      "resnet_model/batch_normalization_30/FusedBatchNorm\n",
      "resnet_model/batch_normalization_31/FusedBatchNorm\n",
      "resnet_model/batch_normalization_32/FusedBatchNorm\n",
      "resnet_model/batch_normalization_33/FusedBatchNorm\n",
      "resnet_model/batch_normalization_34/FusedBatchNorm\n",
      "resnet_model/batch_normalization_35/FusedBatchNorm\n",
      "resnet_model/batch_normalization_36/FusedBatchNorm\n",
      "resnet_model/batch_normalization_37/FusedBatchNorm\n",
      "resnet_model/batch_normalization_38/FusedBatchNorm\n",
      "resnet_model/batch_normalization_39/FusedBatchNorm\n",
      "resnet_model/batch_normalization_40/FusedBatchNorm\n",
      "resnet_model/batch_normalization_41/FusedBatchNorm\n",
      "resnet_model/batch_normalization_42/FusedBatchNorm\n",
      "resnet_model/batch_normalization_43/FusedBatchNorm\n",
      "resnet_model/batch_normalization_44/FusedBatchNorm\n",
      "resnet_model/batch_normalization_45/FusedBatchNorm\n",
      "resnet_model/batch_normalization_46/FusedBatchNorm\n",
      "resnet_model/batch_normalization_47/FusedBatchNorm\n",
      "resnet_model/batch_normalization_48/FusedBatchNorm\n",
      "resnet_model/batch_normalization_49/FusedBatchNorm\n",
      "resnet_model/batch_normalization_50/FusedBatchNorm\n",
      "resnet_model/batch_normalization_51/FusedBatchNorm\n",
      "resnet_model/batch_normalization_52/FusedBatchNorm\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "for node in graph_def.node:\n",
    "    if node.op=='FusedBatchNorm':\n",
    "        print(node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3f61d1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_model/conv2d/Conv2D []\n",
      "resnet_model/conv2d/kernel ['resnet_model/conv2d/Conv2D']\n",
      "resnet_model/batch_normalization/FusedBatchNorm []\n",
      "resnet_model/batch_normalization/gamma ['resnet_model/batch_normalization/FusedBatchNorm']\n",
      "resnet_model/batch_normalization/beta ['resnet_model/batch_normalization/FusedBatchNorm']\n",
      "resnet_model/batch_normalization/moving_mean ['resnet_model/batch_normalization/FusedBatchNorm']\n",
      "resnet_model/batch_normalization/moving_variance ['resnet_model/batch_normalization/FusedBatchNorm']\n",
      "resnet_model/conv2d_1/Conv2D []\n",
      "resnet_model/conv2d_1/kernel ['resnet_model/conv2d_1/Conv2D']\n",
      "resnet_model/batch_normalization_1/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_1/gamma ['resnet_model/batch_normalization_1/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_1/beta ['resnet_model/batch_normalization_1/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_1/moving_mean ['resnet_model/batch_normalization_1/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_1/moving_variance ['resnet_model/batch_normalization_1/FusedBatchNorm']\n",
      "resnet_model/conv2d_2/Conv2D []\n",
      "resnet_model/conv2d_2/kernel ['resnet_model/conv2d_2/Conv2D']\n",
      "resnet_model/batch_normalization_2/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_2/gamma ['resnet_model/batch_normalization_2/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_2/beta ['resnet_model/batch_normalization_2/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_2/moving_mean ['resnet_model/batch_normalization_2/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_2/moving_variance ['resnet_model/batch_normalization_2/FusedBatchNorm']\n",
      "resnet_model/conv2d_3/Conv2D []\n",
      "resnet_model/conv2d_3/kernel ['resnet_model/conv2d_3/Conv2D']\n",
      "resnet_model/batch_normalization_3/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_3/gamma ['resnet_model/batch_normalization_3/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_3/beta ['resnet_model/batch_normalization_3/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_3/moving_mean ['resnet_model/batch_normalization_3/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_3/moving_variance ['resnet_model/batch_normalization_3/FusedBatchNorm']\n",
      "resnet_model/conv2d_4/Conv2D []\n",
      "resnet_model/conv2d_4/kernel ['resnet_model/conv2d_4/Conv2D']\n",
      "resnet_model/batch_normalization_4/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_4/gamma ['resnet_model/batch_normalization_4/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_4/beta ['resnet_model/batch_normalization_4/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_4/moving_mean ['resnet_model/batch_normalization_4/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_4/moving_variance ['resnet_model/batch_normalization_4/FusedBatchNorm']\n",
      "resnet_model/conv2d_5/Conv2D []\n",
      "resnet_model/conv2d_5/kernel ['resnet_model/conv2d_5/Conv2D']\n",
      "resnet_model/batch_normalization_5/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_5/gamma ['resnet_model/batch_normalization_5/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_5/beta ['resnet_model/batch_normalization_5/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_5/moving_mean ['resnet_model/batch_normalization_5/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_5/moving_variance ['resnet_model/batch_normalization_5/FusedBatchNorm']\n",
      "resnet_model/conv2d_6/Conv2D []\n",
      "resnet_model/conv2d_6/kernel ['resnet_model/conv2d_6/Conv2D']\n",
      "resnet_model/batch_normalization_6/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_6/gamma ['resnet_model/batch_normalization_6/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_6/beta ['resnet_model/batch_normalization_6/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_6/moving_mean ['resnet_model/batch_normalization_6/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_6/moving_variance ['resnet_model/batch_normalization_6/FusedBatchNorm']\n",
      "resnet_model/conv2d_7/Conv2D []\n",
      "resnet_model/conv2d_7/kernel ['resnet_model/conv2d_7/Conv2D']\n",
      "resnet_model/batch_normalization_7/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_7/gamma ['resnet_model/batch_normalization_7/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_7/beta ['resnet_model/batch_normalization_7/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_7/moving_mean ['resnet_model/batch_normalization_7/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_7/moving_variance ['resnet_model/batch_normalization_7/FusedBatchNorm']\n",
      "resnet_model/conv2d_8/Conv2D []\n",
      "resnet_model/conv2d_8/kernel ['resnet_model/conv2d_8/Conv2D']\n",
      "resnet_model/batch_normalization_8/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_8/gamma ['resnet_model/batch_normalization_8/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_8/beta ['resnet_model/batch_normalization_8/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_8/moving_mean ['resnet_model/batch_normalization_8/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_8/moving_variance ['resnet_model/batch_normalization_8/FusedBatchNorm']\n",
      "resnet_model/conv2d_9/Conv2D []\n",
      "resnet_model/conv2d_9/kernel ['resnet_model/conv2d_9/Conv2D']\n",
      "resnet_model/batch_normalization_9/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_9/gamma ['resnet_model/batch_normalization_9/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_9/beta ['resnet_model/batch_normalization_9/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_9/moving_mean ['resnet_model/batch_normalization_9/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_9/moving_variance ['resnet_model/batch_normalization_9/FusedBatchNorm']\n",
      "resnet_model/conv2d_10/Conv2D []\n",
      "resnet_model/conv2d_10/kernel ['resnet_model/conv2d_10/Conv2D']\n",
      "resnet_model/batch_normalization_10/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_10/gamma ['resnet_model/batch_normalization_10/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_10/beta ['resnet_model/batch_normalization_10/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_10/moving_mean ['resnet_model/batch_normalization_10/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_10/moving_variance ['resnet_model/batch_normalization_10/FusedBatchNorm']\n",
      "resnet_model/conv2d_11/Conv2D []\n",
      "resnet_model/conv2d_11/kernel ['resnet_model/conv2d_11/Conv2D']\n",
      "resnet_model/batch_normalization_11/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_11/gamma ['resnet_model/batch_normalization_11/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_11/beta ['resnet_model/batch_normalization_11/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_11/moving_mean ['resnet_model/batch_normalization_11/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_11/moving_variance ['resnet_model/batch_normalization_11/FusedBatchNorm']\n",
      "resnet_model/conv2d_12/Conv2D []\n",
      "resnet_model/conv2d_12/kernel ['resnet_model/conv2d_12/Conv2D']\n",
      "resnet_model/batch_normalization_12/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_12/gamma ['resnet_model/batch_normalization_12/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_12/beta ['resnet_model/batch_normalization_12/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_12/moving_mean ['resnet_model/batch_normalization_12/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_12/moving_variance ['resnet_model/batch_normalization_12/FusedBatchNorm']\n",
      "resnet_model/conv2d_13/Conv2D []\n",
      "resnet_model/conv2d_13/kernel ['resnet_model/conv2d_13/Conv2D']\n",
      "resnet_model/batch_normalization_13/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_13/gamma ['resnet_model/batch_normalization_13/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_13/beta ['resnet_model/batch_normalization_13/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_13/moving_mean ['resnet_model/batch_normalization_13/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_13/moving_variance ['resnet_model/batch_normalization_13/FusedBatchNorm']\n",
      "resnet_model/conv2d_14/Conv2D []\n",
      "resnet_model/conv2d_14/kernel ['resnet_model/conv2d_14/Conv2D']\n",
      "resnet_model/batch_normalization_14/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_14/gamma ['resnet_model/batch_normalization_14/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_14/beta ['resnet_model/batch_normalization_14/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_14/moving_mean ['resnet_model/batch_normalization_14/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_14/moving_variance ['resnet_model/batch_normalization_14/FusedBatchNorm']\n",
      "resnet_model/conv2d_15/Conv2D []\n",
      "resnet_model/conv2d_15/kernel ['resnet_model/conv2d_15/Conv2D']\n",
      "resnet_model/batch_normalization_15/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_15/gamma ['resnet_model/batch_normalization_15/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_15/beta ['resnet_model/batch_normalization_15/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_15/moving_mean ['resnet_model/batch_normalization_15/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_15/moving_variance ['resnet_model/batch_normalization_15/FusedBatchNorm']\n",
      "resnet_model/conv2d_16/Conv2D []\n",
      "resnet_model/conv2d_16/kernel ['resnet_model/conv2d_16/Conv2D']\n",
      "resnet_model/batch_normalization_16/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_16/gamma ['resnet_model/batch_normalization_16/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_16/beta ['resnet_model/batch_normalization_16/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_16/moving_mean ['resnet_model/batch_normalization_16/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_16/moving_variance ['resnet_model/batch_normalization_16/FusedBatchNorm']\n",
      "resnet_model/conv2d_17/Conv2D []\n",
      "resnet_model/conv2d_17/kernel ['resnet_model/conv2d_17/Conv2D']\n",
      "resnet_model/batch_normalization_17/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_17/gamma ['resnet_model/batch_normalization_17/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_17/beta ['resnet_model/batch_normalization_17/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_17/moving_mean ['resnet_model/batch_normalization_17/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_17/moving_variance ['resnet_model/batch_normalization_17/FusedBatchNorm']\n",
      "resnet_model/conv2d_18/Conv2D []\n",
      "resnet_model/conv2d_18/kernel ['resnet_model/conv2d_18/Conv2D']\n",
      "resnet_model/batch_normalization_18/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_18/gamma ['resnet_model/batch_normalization_18/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_18/beta ['resnet_model/batch_normalization_18/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_18/moving_mean ['resnet_model/batch_normalization_18/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_18/moving_variance ['resnet_model/batch_normalization_18/FusedBatchNorm']\n",
      "resnet_model/conv2d_19/Conv2D []\n",
      "resnet_model/conv2d_19/kernel ['resnet_model/conv2d_19/Conv2D']\n",
      "resnet_model/batch_normalization_19/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_19/gamma ['resnet_model/batch_normalization_19/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_19/beta ['resnet_model/batch_normalization_19/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_19/moving_mean ['resnet_model/batch_normalization_19/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_19/moving_variance ['resnet_model/batch_normalization_19/FusedBatchNorm']\n",
      "resnet_model/conv2d_20/Conv2D []\n",
      "resnet_model/conv2d_20/kernel ['resnet_model/conv2d_20/Conv2D']\n",
      "resnet_model/batch_normalization_20/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_20/gamma ['resnet_model/batch_normalization_20/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_20/beta ['resnet_model/batch_normalization_20/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_20/moving_mean ['resnet_model/batch_normalization_20/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_20/moving_variance ['resnet_model/batch_normalization_20/FusedBatchNorm']\n",
      "resnet_model/conv2d_21/Conv2D []\n",
      "resnet_model/conv2d_21/kernel ['resnet_model/conv2d_21/Conv2D']\n",
      "resnet_model/batch_normalization_21/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_21/gamma ['resnet_model/batch_normalization_21/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_21/beta ['resnet_model/batch_normalization_21/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_21/moving_mean ['resnet_model/batch_normalization_21/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_21/moving_variance ['resnet_model/batch_normalization_21/FusedBatchNorm']\n",
      "resnet_model/conv2d_22/Conv2D []\n",
      "resnet_model/conv2d_22/kernel ['resnet_model/conv2d_22/Conv2D']\n",
      "resnet_model/batch_normalization_22/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_22/gamma ['resnet_model/batch_normalization_22/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_22/beta ['resnet_model/batch_normalization_22/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_22/moving_mean ['resnet_model/batch_normalization_22/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_22/moving_variance ['resnet_model/batch_normalization_22/FusedBatchNorm']\n",
      "resnet_model/conv2d_23/Conv2D []\n",
      "resnet_model/conv2d_23/kernel ['resnet_model/conv2d_23/Conv2D']\n",
      "resnet_model/batch_normalization_23/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_23/gamma ['resnet_model/batch_normalization_23/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_23/beta ['resnet_model/batch_normalization_23/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_23/moving_mean ['resnet_model/batch_normalization_23/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_23/moving_variance ['resnet_model/batch_normalization_23/FusedBatchNorm']\n",
      "resnet_model/conv2d_24/Conv2D []\n",
      "resnet_model/conv2d_24/kernel ['resnet_model/conv2d_24/Conv2D']\n",
      "resnet_model/batch_normalization_24/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_24/gamma ['resnet_model/batch_normalization_24/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_24/beta ['resnet_model/batch_normalization_24/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_24/moving_mean ['resnet_model/batch_normalization_24/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_24/moving_variance ['resnet_model/batch_normalization_24/FusedBatchNorm']\n",
      "resnet_model/conv2d_25/Conv2D []\n",
      "resnet_model/conv2d_25/kernel ['resnet_model/conv2d_25/Conv2D']\n",
      "resnet_model/batch_normalization_25/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_25/gamma ['resnet_model/batch_normalization_25/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_25/beta ['resnet_model/batch_normalization_25/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_25/moving_mean ['resnet_model/batch_normalization_25/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_25/moving_variance ['resnet_model/batch_normalization_25/FusedBatchNorm']\n",
      "resnet_model/conv2d_26/Conv2D []\n",
      "resnet_model/conv2d_26/kernel ['resnet_model/conv2d_26/Conv2D']\n",
      "resnet_model/batch_normalization_26/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_26/gamma ['resnet_model/batch_normalization_26/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_26/beta ['resnet_model/batch_normalization_26/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_26/moving_mean ['resnet_model/batch_normalization_26/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_26/moving_variance ['resnet_model/batch_normalization_26/FusedBatchNorm']\n",
      "resnet_model/conv2d_27/Conv2D []\n",
      "resnet_model/conv2d_27/kernel ['resnet_model/conv2d_27/Conv2D']\n",
      "resnet_model/batch_normalization_27/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_27/gamma ['resnet_model/batch_normalization_27/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_27/beta ['resnet_model/batch_normalization_27/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_27/moving_mean ['resnet_model/batch_normalization_27/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_27/moving_variance ['resnet_model/batch_normalization_27/FusedBatchNorm']\n",
      "resnet_model/conv2d_28/Conv2D []\n",
      "resnet_model/conv2d_28/kernel ['resnet_model/conv2d_28/Conv2D']\n",
      "resnet_model/batch_normalization_28/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_28/gamma ['resnet_model/batch_normalization_28/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_28/beta ['resnet_model/batch_normalization_28/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_28/moving_mean ['resnet_model/batch_normalization_28/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_28/moving_variance ['resnet_model/batch_normalization_28/FusedBatchNorm']\n",
      "resnet_model/conv2d_29/Conv2D []\n",
      "resnet_model/conv2d_29/kernel ['resnet_model/conv2d_29/Conv2D']\n",
      "resnet_model/batch_normalization_29/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_29/gamma ['resnet_model/batch_normalization_29/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_29/beta ['resnet_model/batch_normalization_29/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_29/moving_mean ['resnet_model/batch_normalization_29/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_29/moving_variance ['resnet_model/batch_normalization_29/FusedBatchNorm']\n",
      "resnet_model/conv2d_30/Conv2D []\n",
      "resnet_model/conv2d_30/kernel ['resnet_model/conv2d_30/Conv2D']\n",
      "resnet_model/batch_normalization_30/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_30/gamma ['resnet_model/batch_normalization_30/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_30/beta ['resnet_model/batch_normalization_30/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_30/moving_mean ['resnet_model/batch_normalization_30/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_30/moving_variance ['resnet_model/batch_normalization_30/FusedBatchNorm']\n",
      "resnet_model/conv2d_31/Conv2D []\n",
      "resnet_model/conv2d_31/kernel ['resnet_model/conv2d_31/Conv2D']\n",
      "resnet_model/batch_normalization_31/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_31/gamma ['resnet_model/batch_normalization_31/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_31/beta ['resnet_model/batch_normalization_31/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_31/moving_mean ['resnet_model/batch_normalization_31/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_31/moving_variance ['resnet_model/batch_normalization_31/FusedBatchNorm']\n",
      "resnet_model/conv2d_32/Conv2D []\n",
      "resnet_model/conv2d_32/kernel ['resnet_model/conv2d_32/Conv2D']\n",
      "resnet_model/batch_normalization_32/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_32/gamma ['resnet_model/batch_normalization_32/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_32/beta ['resnet_model/batch_normalization_32/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_32/moving_mean ['resnet_model/batch_normalization_32/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_32/moving_variance ['resnet_model/batch_normalization_32/FusedBatchNorm']\n",
      "resnet_model/conv2d_33/Conv2D []\n",
      "resnet_model/conv2d_33/kernel ['resnet_model/conv2d_33/Conv2D']\n",
      "resnet_model/batch_normalization_33/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_33/gamma ['resnet_model/batch_normalization_33/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_33/beta ['resnet_model/batch_normalization_33/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_33/moving_mean ['resnet_model/batch_normalization_33/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_33/moving_variance ['resnet_model/batch_normalization_33/FusedBatchNorm']\n",
      "resnet_model/conv2d_34/Conv2D []\n",
      "resnet_model/conv2d_34/kernel ['resnet_model/conv2d_34/Conv2D']\n",
      "resnet_model/batch_normalization_34/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_34/gamma ['resnet_model/batch_normalization_34/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_34/beta ['resnet_model/batch_normalization_34/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_34/moving_mean ['resnet_model/batch_normalization_34/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_34/moving_variance ['resnet_model/batch_normalization_34/FusedBatchNorm']\n",
      "resnet_model/conv2d_35/Conv2D []\n",
      "resnet_model/conv2d_35/kernel ['resnet_model/conv2d_35/Conv2D']\n",
      "resnet_model/batch_normalization_35/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_35/gamma ['resnet_model/batch_normalization_35/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_35/beta ['resnet_model/batch_normalization_35/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_35/moving_mean ['resnet_model/batch_normalization_35/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_35/moving_variance ['resnet_model/batch_normalization_35/FusedBatchNorm']\n",
      "resnet_model/conv2d_36/Conv2D []\n",
      "resnet_model/conv2d_36/kernel ['resnet_model/conv2d_36/Conv2D']\n",
      "resnet_model/batch_normalization_36/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_36/gamma ['resnet_model/batch_normalization_36/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_36/beta ['resnet_model/batch_normalization_36/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_36/moving_mean ['resnet_model/batch_normalization_36/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_36/moving_variance ['resnet_model/batch_normalization_36/FusedBatchNorm']\n",
      "resnet_model/conv2d_37/Conv2D []\n",
      "resnet_model/conv2d_37/kernel ['resnet_model/conv2d_37/Conv2D']\n",
      "resnet_model/batch_normalization_37/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_37/gamma ['resnet_model/batch_normalization_37/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_37/beta ['resnet_model/batch_normalization_37/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_37/moving_mean ['resnet_model/batch_normalization_37/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_37/moving_variance ['resnet_model/batch_normalization_37/FusedBatchNorm']\n",
      "resnet_model/conv2d_38/Conv2D []\n",
      "resnet_model/conv2d_38/kernel ['resnet_model/conv2d_38/Conv2D']\n",
      "resnet_model/batch_normalization_38/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_38/gamma ['resnet_model/batch_normalization_38/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_38/beta ['resnet_model/batch_normalization_38/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_38/moving_mean ['resnet_model/batch_normalization_38/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_38/moving_variance ['resnet_model/batch_normalization_38/FusedBatchNorm']\n",
      "resnet_model/conv2d_39/Conv2D []\n",
      "resnet_model/conv2d_39/kernel ['resnet_model/conv2d_39/Conv2D']\n",
      "resnet_model/batch_normalization_39/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_39/gamma ['resnet_model/batch_normalization_39/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_39/beta ['resnet_model/batch_normalization_39/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_39/moving_mean ['resnet_model/batch_normalization_39/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_39/moving_variance ['resnet_model/batch_normalization_39/FusedBatchNorm']\n",
      "resnet_model/conv2d_40/Conv2D []\n",
      "resnet_model/conv2d_40/kernel ['resnet_model/conv2d_40/Conv2D']\n",
      "resnet_model/batch_normalization_40/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_40/gamma ['resnet_model/batch_normalization_40/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_40/beta ['resnet_model/batch_normalization_40/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_40/moving_mean ['resnet_model/batch_normalization_40/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_40/moving_variance ['resnet_model/batch_normalization_40/FusedBatchNorm']\n",
      "resnet_model/conv2d_41/Conv2D []\n",
      "resnet_model/conv2d_41/kernel ['resnet_model/conv2d_41/Conv2D']\n",
      "resnet_model/batch_normalization_41/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_41/gamma ['resnet_model/batch_normalization_41/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_41/beta ['resnet_model/batch_normalization_41/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_41/moving_mean ['resnet_model/batch_normalization_41/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_41/moving_variance ['resnet_model/batch_normalization_41/FusedBatchNorm']\n",
      "resnet_model/conv2d_42/Conv2D []\n",
      "resnet_model/conv2d_42/kernel ['resnet_model/conv2d_42/Conv2D']\n",
      "resnet_model/batch_normalization_42/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_42/gamma ['resnet_model/batch_normalization_42/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_42/beta ['resnet_model/batch_normalization_42/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_42/moving_mean ['resnet_model/batch_normalization_42/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_42/moving_variance ['resnet_model/batch_normalization_42/FusedBatchNorm']\n",
      "resnet_model/conv2d_43/Conv2D []\n",
      "resnet_model/conv2d_43/kernel ['resnet_model/conv2d_43/Conv2D']\n",
      "resnet_model/batch_normalization_43/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_43/gamma ['resnet_model/batch_normalization_43/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_43/beta ['resnet_model/batch_normalization_43/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_43/moving_mean ['resnet_model/batch_normalization_43/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_43/moving_variance ['resnet_model/batch_normalization_43/FusedBatchNorm']\n",
      "resnet_model/conv2d_44/Conv2D []\n",
      "resnet_model/conv2d_44/kernel ['resnet_model/conv2d_44/Conv2D']\n",
      "resnet_model/batch_normalization_44/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_44/gamma ['resnet_model/batch_normalization_44/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_44/beta ['resnet_model/batch_normalization_44/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_44/moving_mean ['resnet_model/batch_normalization_44/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_44/moving_variance ['resnet_model/batch_normalization_44/FusedBatchNorm']\n",
      "resnet_model/conv2d_45/Conv2D []\n",
      "resnet_model/conv2d_45/kernel ['resnet_model/conv2d_45/Conv2D']\n",
      "resnet_model/batch_normalization_45/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_45/gamma ['resnet_model/batch_normalization_45/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_45/beta ['resnet_model/batch_normalization_45/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_45/moving_mean ['resnet_model/batch_normalization_45/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_45/moving_variance ['resnet_model/batch_normalization_45/FusedBatchNorm']\n",
      "resnet_model/conv2d_46/Conv2D []\n",
      "resnet_model/conv2d_46/kernel ['resnet_model/conv2d_46/Conv2D']\n",
      "resnet_model/batch_normalization_46/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_46/gamma ['resnet_model/batch_normalization_46/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_46/beta ['resnet_model/batch_normalization_46/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_46/moving_mean ['resnet_model/batch_normalization_46/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_46/moving_variance ['resnet_model/batch_normalization_46/FusedBatchNorm']\n",
      "resnet_model/conv2d_47/Conv2D []\n",
      "resnet_model/conv2d_47/kernel ['resnet_model/conv2d_47/Conv2D']\n",
      "resnet_model/batch_normalization_47/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_47/gamma ['resnet_model/batch_normalization_47/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_47/beta ['resnet_model/batch_normalization_47/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_47/moving_mean ['resnet_model/batch_normalization_47/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_47/moving_variance ['resnet_model/batch_normalization_47/FusedBatchNorm']\n",
      "resnet_model/conv2d_48/Conv2D []\n",
      "resnet_model/conv2d_48/kernel ['resnet_model/conv2d_48/Conv2D']\n",
      "resnet_model/batch_normalization_48/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_48/gamma ['resnet_model/batch_normalization_48/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_48/beta ['resnet_model/batch_normalization_48/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_48/moving_mean ['resnet_model/batch_normalization_48/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_48/moving_variance ['resnet_model/batch_normalization_48/FusedBatchNorm']\n",
      "resnet_model/conv2d_49/Conv2D []\n",
      "resnet_model/conv2d_49/kernel ['resnet_model/conv2d_49/Conv2D']\n",
      "resnet_model/batch_normalization_49/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_49/gamma ['resnet_model/batch_normalization_49/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_49/beta ['resnet_model/batch_normalization_49/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_49/moving_mean ['resnet_model/batch_normalization_49/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_49/moving_variance ['resnet_model/batch_normalization_49/FusedBatchNorm']\n",
      "resnet_model/conv2d_50/Conv2D []\n",
      "resnet_model/conv2d_50/kernel ['resnet_model/conv2d_50/Conv2D']\n",
      "resnet_model/batch_normalization_50/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_50/gamma ['resnet_model/batch_normalization_50/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_50/beta ['resnet_model/batch_normalization_50/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_50/moving_mean ['resnet_model/batch_normalization_50/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_50/moving_variance ['resnet_model/batch_normalization_50/FusedBatchNorm']\n",
      "resnet_model/conv2d_51/Conv2D []\n",
      "resnet_model/conv2d_51/kernel ['resnet_model/conv2d_51/Conv2D']\n",
      "resnet_model/batch_normalization_51/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_51/gamma ['resnet_model/batch_normalization_51/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_51/beta ['resnet_model/batch_normalization_51/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_51/moving_mean ['resnet_model/batch_normalization_51/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_51/moving_variance ['resnet_model/batch_normalization_51/FusedBatchNorm']\n",
      "resnet_model/conv2d_52/Conv2D []\n",
      "resnet_model/conv2d_52/kernel ['resnet_model/conv2d_52/Conv2D']\n",
      "resnet_model/batch_normalization_52/FusedBatchNorm []\n",
      "resnet_model/batch_normalization_52/gamma ['resnet_model/batch_normalization_52/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_52/beta ['resnet_model/batch_normalization_52/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_52/moving_mean ['resnet_model/batch_normalization_52/FusedBatchNorm']\n",
      "resnet_model/batch_normalization_52/moving_variance ['resnet_model/batch_normalization_52/FusedBatchNorm']\n",
      "resnet_model/dense/MatMul []\n",
      "resnet_model/dense/kernel ['resnet_model/dense/MatMul']\n",
      "resnet_model/dense/BiasAdd []\n",
      "resnet_model/dense/bias ['resnet_model/dense/BiasAdd']\n"
     ]
    }
   ],
   "source": [
    "for i in list(G.nodes):\n",
    "    print(i, list(G.neighbors(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b1f2f54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('resnet_model/conv2d/kernel', 'resnet_model/conv2d/Conv2D')\n",
      "('resnet_model/batch_normalization/gamma', 'resnet_model/batch_normalization/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization/beta', 'resnet_model/batch_normalization/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization/moving_mean', 'resnet_model/batch_normalization/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization/moving_variance', 'resnet_model/batch_normalization/FusedBatchNorm')\n",
      "('resnet_model/conv2d_1/kernel', 'resnet_model/conv2d_1/Conv2D')\n",
      "('resnet_model/batch_normalization_1/gamma', 'resnet_model/batch_normalization_1/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_1/beta', 'resnet_model/batch_normalization_1/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_1/moving_mean', 'resnet_model/batch_normalization_1/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_1/moving_variance', 'resnet_model/batch_normalization_1/FusedBatchNorm')\n",
      "('resnet_model/conv2d_2/kernel', 'resnet_model/conv2d_2/Conv2D')\n",
      "('resnet_model/batch_normalization_2/gamma', 'resnet_model/batch_normalization_2/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_2/beta', 'resnet_model/batch_normalization_2/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_2/moving_mean', 'resnet_model/batch_normalization_2/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_2/moving_variance', 'resnet_model/batch_normalization_2/FusedBatchNorm')\n",
      "('resnet_model/conv2d_3/kernel', 'resnet_model/conv2d_3/Conv2D')\n",
      "('resnet_model/batch_normalization_3/gamma', 'resnet_model/batch_normalization_3/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_3/beta', 'resnet_model/batch_normalization_3/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_3/moving_mean', 'resnet_model/batch_normalization_3/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_3/moving_variance', 'resnet_model/batch_normalization_3/FusedBatchNorm')\n",
      "('resnet_model/conv2d_4/kernel', 'resnet_model/conv2d_4/Conv2D')\n",
      "('resnet_model/batch_normalization_4/gamma', 'resnet_model/batch_normalization_4/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_4/beta', 'resnet_model/batch_normalization_4/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_4/moving_mean', 'resnet_model/batch_normalization_4/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_4/moving_variance', 'resnet_model/batch_normalization_4/FusedBatchNorm')\n",
      "('resnet_model/conv2d_5/kernel', 'resnet_model/conv2d_5/Conv2D')\n",
      "('resnet_model/batch_normalization_5/gamma', 'resnet_model/batch_normalization_5/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_5/beta', 'resnet_model/batch_normalization_5/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_5/moving_mean', 'resnet_model/batch_normalization_5/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_5/moving_variance', 'resnet_model/batch_normalization_5/FusedBatchNorm')\n",
      "('resnet_model/conv2d_6/kernel', 'resnet_model/conv2d_6/Conv2D')\n",
      "('resnet_model/batch_normalization_6/gamma', 'resnet_model/batch_normalization_6/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_6/beta', 'resnet_model/batch_normalization_6/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_6/moving_mean', 'resnet_model/batch_normalization_6/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_6/moving_variance', 'resnet_model/batch_normalization_6/FusedBatchNorm')\n",
      "('resnet_model/conv2d_7/kernel', 'resnet_model/conv2d_7/Conv2D')\n",
      "('resnet_model/batch_normalization_7/gamma', 'resnet_model/batch_normalization_7/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_7/beta', 'resnet_model/batch_normalization_7/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_7/moving_mean', 'resnet_model/batch_normalization_7/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_7/moving_variance', 'resnet_model/batch_normalization_7/FusedBatchNorm')\n",
      "('resnet_model/conv2d_8/kernel', 'resnet_model/conv2d_8/Conv2D')\n",
      "('resnet_model/batch_normalization_8/gamma', 'resnet_model/batch_normalization_8/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_8/beta', 'resnet_model/batch_normalization_8/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_8/moving_mean', 'resnet_model/batch_normalization_8/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_8/moving_variance', 'resnet_model/batch_normalization_8/FusedBatchNorm')\n",
      "('resnet_model/conv2d_9/kernel', 'resnet_model/conv2d_9/Conv2D')\n",
      "('resnet_model/batch_normalization_9/gamma', 'resnet_model/batch_normalization_9/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_9/beta', 'resnet_model/batch_normalization_9/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_9/moving_mean', 'resnet_model/batch_normalization_9/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_9/moving_variance', 'resnet_model/batch_normalization_9/FusedBatchNorm')\n",
      "('resnet_model/conv2d_10/kernel', 'resnet_model/conv2d_10/Conv2D')\n",
      "('resnet_model/batch_normalization_10/gamma', 'resnet_model/batch_normalization_10/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_10/beta', 'resnet_model/batch_normalization_10/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_10/moving_mean', 'resnet_model/batch_normalization_10/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_10/moving_variance', 'resnet_model/batch_normalization_10/FusedBatchNorm')\n",
      "('resnet_model/conv2d_11/kernel', 'resnet_model/conv2d_11/Conv2D')\n",
      "('resnet_model/batch_normalization_11/gamma', 'resnet_model/batch_normalization_11/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_11/beta', 'resnet_model/batch_normalization_11/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_11/moving_mean', 'resnet_model/batch_normalization_11/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_11/moving_variance', 'resnet_model/batch_normalization_11/FusedBatchNorm')\n",
      "('resnet_model/conv2d_12/kernel', 'resnet_model/conv2d_12/Conv2D')\n",
      "('resnet_model/batch_normalization_12/gamma', 'resnet_model/batch_normalization_12/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_12/beta', 'resnet_model/batch_normalization_12/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_12/moving_mean', 'resnet_model/batch_normalization_12/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_12/moving_variance', 'resnet_model/batch_normalization_12/FusedBatchNorm')\n",
      "('resnet_model/conv2d_13/kernel', 'resnet_model/conv2d_13/Conv2D')\n",
      "('resnet_model/batch_normalization_13/gamma', 'resnet_model/batch_normalization_13/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_13/beta', 'resnet_model/batch_normalization_13/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_13/moving_mean', 'resnet_model/batch_normalization_13/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_13/moving_variance', 'resnet_model/batch_normalization_13/FusedBatchNorm')\n",
      "('resnet_model/conv2d_14/kernel', 'resnet_model/conv2d_14/Conv2D')\n",
      "('resnet_model/batch_normalization_14/gamma', 'resnet_model/batch_normalization_14/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_14/beta', 'resnet_model/batch_normalization_14/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_14/moving_mean', 'resnet_model/batch_normalization_14/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_14/moving_variance', 'resnet_model/batch_normalization_14/FusedBatchNorm')\n",
      "('resnet_model/conv2d_15/kernel', 'resnet_model/conv2d_15/Conv2D')\n",
      "('resnet_model/batch_normalization_15/gamma', 'resnet_model/batch_normalization_15/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_15/beta', 'resnet_model/batch_normalization_15/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_15/moving_mean', 'resnet_model/batch_normalization_15/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_15/moving_variance', 'resnet_model/batch_normalization_15/FusedBatchNorm')\n",
      "('resnet_model/conv2d_16/kernel', 'resnet_model/conv2d_16/Conv2D')\n",
      "('resnet_model/batch_normalization_16/gamma', 'resnet_model/batch_normalization_16/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_16/beta', 'resnet_model/batch_normalization_16/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_16/moving_mean', 'resnet_model/batch_normalization_16/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_16/moving_variance', 'resnet_model/batch_normalization_16/FusedBatchNorm')\n",
      "('resnet_model/conv2d_17/kernel', 'resnet_model/conv2d_17/Conv2D')\n",
      "('resnet_model/batch_normalization_17/gamma', 'resnet_model/batch_normalization_17/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_17/beta', 'resnet_model/batch_normalization_17/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_17/moving_mean', 'resnet_model/batch_normalization_17/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_17/moving_variance', 'resnet_model/batch_normalization_17/FusedBatchNorm')\n",
      "('resnet_model/conv2d_18/kernel', 'resnet_model/conv2d_18/Conv2D')\n",
      "('resnet_model/batch_normalization_18/gamma', 'resnet_model/batch_normalization_18/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_18/beta', 'resnet_model/batch_normalization_18/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_18/moving_mean', 'resnet_model/batch_normalization_18/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_18/moving_variance', 'resnet_model/batch_normalization_18/FusedBatchNorm')\n",
      "('resnet_model/conv2d_19/kernel', 'resnet_model/conv2d_19/Conv2D')\n",
      "('resnet_model/batch_normalization_19/gamma', 'resnet_model/batch_normalization_19/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_19/beta', 'resnet_model/batch_normalization_19/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_19/moving_mean', 'resnet_model/batch_normalization_19/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_19/moving_variance', 'resnet_model/batch_normalization_19/FusedBatchNorm')\n",
      "('resnet_model/conv2d_20/kernel', 'resnet_model/conv2d_20/Conv2D')\n",
      "('resnet_model/batch_normalization_20/gamma', 'resnet_model/batch_normalization_20/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_20/beta', 'resnet_model/batch_normalization_20/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_20/moving_mean', 'resnet_model/batch_normalization_20/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_20/moving_variance', 'resnet_model/batch_normalization_20/FusedBatchNorm')\n",
      "('resnet_model/conv2d_21/kernel', 'resnet_model/conv2d_21/Conv2D')\n",
      "('resnet_model/batch_normalization_21/gamma', 'resnet_model/batch_normalization_21/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_21/beta', 'resnet_model/batch_normalization_21/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_21/moving_mean', 'resnet_model/batch_normalization_21/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_21/moving_variance', 'resnet_model/batch_normalization_21/FusedBatchNorm')\n",
      "('resnet_model/conv2d_22/kernel', 'resnet_model/conv2d_22/Conv2D')\n",
      "('resnet_model/batch_normalization_22/gamma', 'resnet_model/batch_normalization_22/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_22/beta', 'resnet_model/batch_normalization_22/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_22/moving_mean', 'resnet_model/batch_normalization_22/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_22/moving_variance', 'resnet_model/batch_normalization_22/FusedBatchNorm')\n",
      "('resnet_model/conv2d_23/kernel', 'resnet_model/conv2d_23/Conv2D')\n",
      "('resnet_model/batch_normalization_23/gamma', 'resnet_model/batch_normalization_23/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_23/beta', 'resnet_model/batch_normalization_23/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_23/moving_mean', 'resnet_model/batch_normalization_23/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_23/moving_variance', 'resnet_model/batch_normalization_23/FusedBatchNorm')\n",
      "('resnet_model/conv2d_24/kernel', 'resnet_model/conv2d_24/Conv2D')\n",
      "('resnet_model/batch_normalization_24/gamma', 'resnet_model/batch_normalization_24/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_24/beta', 'resnet_model/batch_normalization_24/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_24/moving_mean', 'resnet_model/batch_normalization_24/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_24/moving_variance', 'resnet_model/batch_normalization_24/FusedBatchNorm')\n",
      "('resnet_model/conv2d_25/kernel', 'resnet_model/conv2d_25/Conv2D')\n",
      "('resnet_model/batch_normalization_25/gamma', 'resnet_model/batch_normalization_25/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_25/beta', 'resnet_model/batch_normalization_25/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_25/moving_mean', 'resnet_model/batch_normalization_25/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_25/moving_variance', 'resnet_model/batch_normalization_25/FusedBatchNorm')\n",
      "('resnet_model/conv2d_26/kernel', 'resnet_model/conv2d_26/Conv2D')\n",
      "('resnet_model/batch_normalization_26/gamma', 'resnet_model/batch_normalization_26/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_26/beta', 'resnet_model/batch_normalization_26/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_26/moving_mean', 'resnet_model/batch_normalization_26/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_26/moving_variance', 'resnet_model/batch_normalization_26/FusedBatchNorm')\n",
      "('resnet_model/conv2d_27/kernel', 'resnet_model/conv2d_27/Conv2D')\n",
      "('resnet_model/batch_normalization_27/gamma', 'resnet_model/batch_normalization_27/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_27/beta', 'resnet_model/batch_normalization_27/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_27/moving_mean', 'resnet_model/batch_normalization_27/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_27/moving_variance', 'resnet_model/batch_normalization_27/FusedBatchNorm')\n",
      "('resnet_model/conv2d_28/kernel', 'resnet_model/conv2d_28/Conv2D')\n",
      "('resnet_model/batch_normalization_28/gamma', 'resnet_model/batch_normalization_28/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_28/beta', 'resnet_model/batch_normalization_28/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_28/moving_mean', 'resnet_model/batch_normalization_28/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_28/moving_variance', 'resnet_model/batch_normalization_28/FusedBatchNorm')\n",
      "('resnet_model/conv2d_29/kernel', 'resnet_model/conv2d_29/Conv2D')\n",
      "('resnet_model/batch_normalization_29/gamma', 'resnet_model/batch_normalization_29/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_29/beta', 'resnet_model/batch_normalization_29/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_29/moving_mean', 'resnet_model/batch_normalization_29/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_29/moving_variance', 'resnet_model/batch_normalization_29/FusedBatchNorm')\n",
      "('resnet_model/conv2d_30/kernel', 'resnet_model/conv2d_30/Conv2D')\n",
      "('resnet_model/batch_normalization_30/gamma', 'resnet_model/batch_normalization_30/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_30/beta', 'resnet_model/batch_normalization_30/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_30/moving_mean', 'resnet_model/batch_normalization_30/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_30/moving_variance', 'resnet_model/batch_normalization_30/FusedBatchNorm')\n",
      "('resnet_model/conv2d_31/kernel', 'resnet_model/conv2d_31/Conv2D')\n",
      "('resnet_model/batch_normalization_31/gamma', 'resnet_model/batch_normalization_31/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_31/beta', 'resnet_model/batch_normalization_31/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_31/moving_mean', 'resnet_model/batch_normalization_31/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_31/moving_variance', 'resnet_model/batch_normalization_31/FusedBatchNorm')\n",
      "('resnet_model/conv2d_32/kernel', 'resnet_model/conv2d_32/Conv2D')\n",
      "('resnet_model/batch_normalization_32/gamma', 'resnet_model/batch_normalization_32/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_32/beta', 'resnet_model/batch_normalization_32/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_32/moving_mean', 'resnet_model/batch_normalization_32/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_32/moving_variance', 'resnet_model/batch_normalization_32/FusedBatchNorm')\n",
      "('resnet_model/conv2d_33/kernel', 'resnet_model/conv2d_33/Conv2D')\n",
      "('resnet_model/batch_normalization_33/gamma', 'resnet_model/batch_normalization_33/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_33/beta', 'resnet_model/batch_normalization_33/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_33/moving_mean', 'resnet_model/batch_normalization_33/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_33/moving_variance', 'resnet_model/batch_normalization_33/FusedBatchNorm')\n",
      "('resnet_model/conv2d_34/kernel', 'resnet_model/conv2d_34/Conv2D')\n",
      "('resnet_model/batch_normalization_34/gamma', 'resnet_model/batch_normalization_34/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_34/beta', 'resnet_model/batch_normalization_34/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_34/moving_mean', 'resnet_model/batch_normalization_34/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_34/moving_variance', 'resnet_model/batch_normalization_34/FusedBatchNorm')\n",
      "('resnet_model/conv2d_35/kernel', 'resnet_model/conv2d_35/Conv2D')\n",
      "('resnet_model/batch_normalization_35/gamma', 'resnet_model/batch_normalization_35/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_35/beta', 'resnet_model/batch_normalization_35/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_35/moving_mean', 'resnet_model/batch_normalization_35/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_35/moving_variance', 'resnet_model/batch_normalization_35/FusedBatchNorm')\n",
      "('resnet_model/conv2d_36/kernel', 'resnet_model/conv2d_36/Conv2D')\n",
      "('resnet_model/batch_normalization_36/gamma', 'resnet_model/batch_normalization_36/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_36/beta', 'resnet_model/batch_normalization_36/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_36/moving_mean', 'resnet_model/batch_normalization_36/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_36/moving_variance', 'resnet_model/batch_normalization_36/FusedBatchNorm')\n",
      "('resnet_model/conv2d_37/kernel', 'resnet_model/conv2d_37/Conv2D')\n",
      "('resnet_model/batch_normalization_37/gamma', 'resnet_model/batch_normalization_37/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_37/beta', 'resnet_model/batch_normalization_37/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_37/moving_mean', 'resnet_model/batch_normalization_37/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_37/moving_variance', 'resnet_model/batch_normalization_37/FusedBatchNorm')\n",
      "('resnet_model/conv2d_38/kernel', 'resnet_model/conv2d_38/Conv2D')\n",
      "('resnet_model/batch_normalization_38/gamma', 'resnet_model/batch_normalization_38/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_38/beta', 'resnet_model/batch_normalization_38/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_38/moving_mean', 'resnet_model/batch_normalization_38/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_38/moving_variance', 'resnet_model/batch_normalization_38/FusedBatchNorm')\n",
      "('resnet_model/conv2d_39/kernel', 'resnet_model/conv2d_39/Conv2D')\n",
      "('resnet_model/batch_normalization_39/gamma', 'resnet_model/batch_normalization_39/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_39/beta', 'resnet_model/batch_normalization_39/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_39/moving_mean', 'resnet_model/batch_normalization_39/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_39/moving_variance', 'resnet_model/batch_normalization_39/FusedBatchNorm')\n",
      "('resnet_model/conv2d_40/kernel', 'resnet_model/conv2d_40/Conv2D')\n",
      "('resnet_model/batch_normalization_40/gamma', 'resnet_model/batch_normalization_40/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_40/beta', 'resnet_model/batch_normalization_40/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_40/moving_mean', 'resnet_model/batch_normalization_40/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_40/moving_variance', 'resnet_model/batch_normalization_40/FusedBatchNorm')\n",
      "('resnet_model/conv2d_41/kernel', 'resnet_model/conv2d_41/Conv2D')\n",
      "('resnet_model/batch_normalization_41/gamma', 'resnet_model/batch_normalization_41/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_41/beta', 'resnet_model/batch_normalization_41/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_41/moving_mean', 'resnet_model/batch_normalization_41/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_41/moving_variance', 'resnet_model/batch_normalization_41/FusedBatchNorm')\n",
      "('resnet_model/conv2d_42/kernel', 'resnet_model/conv2d_42/Conv2D')\n",
      "('resnet_model/batch_normalization_42/gamma', 'resnet_model/batch_normalization_42/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_42/beta', 'resnet_model/batch_normalization_42/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_42/moving_mean', 'resnet_model/batch_normalization_42/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_42/moving_variance', 'resnet_model/batch_normalization_42/FusedBatchNorm')\n",
      "('resnet_model/conv2d_43/kernel', 'resnet_model/conv2d_43/Conv2D')\n",
      "('resnet_model/batch_normalization_43/gamma', 'resnet_model/batch_normalization_43/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_43/beta', 'resnet_model/batch_normalization_43/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_43/moving_mean', 'resnet_model/batch_normalization_43/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_43/moving_variance', 'resnet_model/batch_normalization_43/FusedBatchNorm')\n",
      "('resnet_model/conv2d_44/kernel', 'resnet_model/conv2d_44/Conv2D')\n",
      "('resnet_model/batch_normalization_44/gamma', 'resnet_model/batch_normalization_44/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_44/beta', 'resnet_model/batch_normalization_44/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_44/moving_mean', 'resnet_model/batch_normalization_44/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_44/moving_variance', 'resnet_model/batch_normalization_44/FusedBatchNorm')\n",
      "('resnet_model/conv2d_45/kernel', 'resnet_model/conv2d_45/Conv2D')\n",
      "('resnet_model/batch_normalization_45/gamma', 'resnet_model/batch_normalization_45/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_45/beta', 'resnet_model/batch_normalization_45/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_45/moving_mean', 'resnet_model/batch_normalization_45/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_45/moving_variance', 'resnet_model/batch_normalization_45/FusedBatchNorm')\n",
      "('resnet_model/conv2d_46/kernel', 'resnet_model/conv2d_46/Conv2D')\n",
      "('resnet_model/batch_normalization_46/gamma', 'resnet_model/batch_normalization_46/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_46/beta', 'resnet_model/batch_normalization_46/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_46/moving_mean', 'resnet_model/batch_normalization_46/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_46/moving_variance', 'resnet_model/batch_normalization_46/FusedBatchNorm')\n",
      "('resnet_model/conv2d_47/kernel', 'resnet_model/conv2d_47/Conv2D')\n",
      "('resnet_model/batch_normalization_47/gamma', 'resnet_model/batch_normalization_47/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_47/beta', 'resnet_model/batch_normalization_47/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_47/moving_mean', 'resnet_model/batch_normalization_47/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_47/moving_variance', 'resnet_model/batch_normalization_47/FusedBatchNorm')\n",
      "('resnet_model/conv2d_48/kernel', 'resnet_model/conv2d_48/Conv2D')\n",
      "('resnet_model/batch_normalization_48/gamma', 'resnet_model/batch_normalization_48/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_48/beta', 'resnet_model/batch_normalization_48/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_48/moving_mean', 'resnet_model/batch_normalization_48/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_48/moving_variance', 'resnet_model/batch_normalization_48/FusedBatchNorm')\n",
      "('resnet_model/conv2d_49/kernel', 'resnet_model/conv2d_49/Conv2D')\n",
      "('resnet_model/batch_normalization_49/gamma', 'resnet_model/batch_normalization_49/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_49/beta', 'resnet_model/batch_normalization_49/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_49/moving_mean', 'resnet_model/batch_normalization_49/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_49/moving_variance', 'resnet_model/batch_normalization_49/FusedBatchNorm')\n",
      "('resnet_model/conv2d_50/kernel', 'resnet_model/conv2d_50/Conv2D')\n",
      "('resnet_model/batch_normalization_50/gamma', 'resnet_model/batch_normalization_50/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_50/beta', 'resnet_model/batch_normalization_50/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_50/moving_mean', 'resnet_model/batch_normalization_50/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_50/moving_variance', 'resnet_model/batch_normalization_50/FusedBatchNorm')\n",
      "('resnet_model/conv2d_51/kernel', 'resnet_model/conv2d_51/Conv2D')\n",
      "('resnet_model/batch_normalization_51/gamma', 'resnet_model/batch_normalization_51/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_51/beta', 'resnet_model/batch_normalization_51/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_51/moving_mean', 'resnet_model/batch_normalization_51/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_51/moving_variance', 'resnet_model/batch_normalization_51/FusedBatchNorm')\n",
      "('resnet_model/conv2d_52/kernel', 'resnet_model/conv2d_52/Conv2D')\n",
      "('resnet_model/batch_normalization_52/gamma', 'resnet_model/batch_normalization_52/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_52/beta', 'resnet_model/batch_normalization_52/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_52/moving_mean', 'resnet_model/batch_normalization_52/FusedBatchNorm')\n",
      "('resnet_model/batch_normalization_52/moving_variance', 'resnet_model/batch_normalization_52/FusedBatchNorm')\n",
      "('resnet_model/dense/kernel', 'resnet_model/dense/MatMul')\n",
      "('resnet_model/dense/bias', 'resnet_model/dense/BiasAdd')\n"
     ]
    }
   ],
   "source": [
    "for i in list(G.edges):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a19ccd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "biases = {}\n",
    "fusedbatchnorm = {}\n",
    "\n",
    "for node in graph_def.node:\n",
    "    if node.op == 'Conv2D':\n",
    "        for i in node.input:\n",
    "            inp = master_dict[i]\n",
    "            if inp.op == 'Identity':\n",
    "                inp = master_dict[inp.input[0]]\n",
    "                if inp.op == 'Const' and inp.attr['dtype'].type<=1:\n",
    "                    weights[node.name] = tensor_util.MakeNdarray(inp.attr['value'].tensor)\n",
    "    elif node.op == 'MatMul':\n",
    "        for i in node.input:\n",
    "            inp = master_dict[i]\n",
    "            if inp.op == 'Identity':\n",
    "                inp = master_dict[inp.input[0]]   \n",
    "                #print(inp.name)\n",
    "                if inp.op == 'Const' and inp.attr['dtype'].type<=1:\n",
    "                    weights[node.name] = tensor_util.MakeNdarray(inp.attr['value'].tensor)\n",
    "    elif node.op == 'FusedBatchNorm':\n",
    "        batchnorm_list = []\n",
    "        for i in node.input:\n",
    "            inp = master_dict[i]\n",
    "            if inp.op == 'Identity':\n",
    "                inp = master_dict[inp.input[0]]   \n",
    "                #print(inp.name)\n",
    "                if inp.op == 'Const' and inp.attr['dtype'].type<=1:\n",
    "                    batchnorm_list.append(tensor_util.MakeNdarray(inp.attr['value'].tensor))\n",
    "                    fusedbatchnorm[node.name] = batchnorm_list\n",
    "                    \n",
    "    elif node.op == 'BiasAdd':\n",
    "        for i in node.input:\n",
    "            inp = master_dict[i]\n",
    "            if inp.op == 'Identity':\n",
    "                inp = master_dict[inp.input[0]]\n",
    "                if inp.op == 'Const' and inp.attr['dtype'].type<=1:\n",
    "                    biases[node.name] = tensor_util.MakeNdarray(inp.attr['value'].tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4551c93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.5944636 , 1.9815539 , 0.8526842 , 1.501561  , 1.5698198 ,\n",
      "       1.0347265 , 0.9573454 , 1.373299  , 0.8140592 , 0.8948228 ,\n",
      "       1.0514498 , 1.2239406 , 1.0086318 , 0.91958696, 0.9001943 ,\n",
      "       2.8174558 , 0.8309089 , 1.1902237 , 1.1014653 , 1.6110836 ,\n",
      "       1.0747343 , 3.254274  , 0.88804764, 3.7319186 , 3.8282413 ,\n",
      "       0.8771013 , 1.3457507 , 1.0313803 , 2.15569   , 0.90294355,\n",
      "       0.7863676 , 0.8100658 , 0.9331585 , 1.3547935 , 0.7949937 ,\n",
      "       0.8994442 , 1.2455972 , 1.3669853 , 1.3023825 , 1.7853003 ,\n",
      "       2.0771263 , 2.5315194 , 0.8632579 , 1.0345632 , 0.8624157 ,\n",
      "       0.8746563 , 1.0630227 , 2.9541578 , 0.86795706, 1.2082759 ,\n",
      "       1.197648  , 3.3943307 , 1.2359158 , 1.1736696 , 1.0318273 ,\n",
      "       0.8399722 , 2.7101457 , 1.092414  , 0.70500344, 1.050954  ,\n",
      "       1.794127  , 0.94030464, 2.3249917 , 0.8985398 ], dtype=float32), array([ 3.3952718 , -1.4526453 ,  1.7600641 ,  3.545317  , -0.681961  ,\n",
      "        1.8170512 ,  1.0765904 , -0.58844084,  1.7646067 ,  1.6282673 ,\n",
      "        1.7082471 ,  0.7706829 ,  1.2753172 ,  1.6377854 ,  1.6411253 ,\n",
      "       -4.228004  ,  1.8071895 ,  0.77692115,  1.2689028 ,  3.813834  ,\n",
      "        1.6194109 , -4.1939735 ,  1.6957794 ,  7.1639414 , -4.647857  ,\n",
      "        1.7127047 ,  0.96605366,  1.3781679 ,  5.023895  ,  1.8060215 ,\n",
      "        1.8313905 ,  1.7233092 ,  1.7625902 ,  3.3848693 ,  1.9824041 ,\n",
      "        1.7629979 ,  1.2632338 , -0.4283847 ,  0.22377282, -1.9416432 ,\n",
      "        3.9065187 , -2.2993839 ,  1.7346056 ,  2.4067612 ,  1.8035184 ,\n",
      "        1.7013582 ,  1.5929232 , -3.5712585 ,  1.6030282 ,  1.815452  ,\n",
      "        0.76862776,  7.8361487 ,  0.82723916,  1.6864198 ,  1.5049874 ,\n",
      "        1.7447284 , -3.0532799 ,  1.6545016 ,  1.7193714 ,  1.389571  ,\n",
      "        3.4842324 ,  1.6548927 ,  4.292693  ,  1.7065245 ], dtype=float32), array([ 2.86445546e+00,  2.87505364e+00,  1.08391546e-01,  2.75079274e+00,\n",
      "        2.16891742e+00, -3.72054756e-01, -1.29701746e+00, -1.34022743e-01,\n",
      "        1.75407007e-01, -2.12707460e-01,  3.55726592e-02,  5.43377459e-01,\n",
      "        2.82690430e+00,  1.78024992e-01, -2.60938182e-02,  2.82488680e+00,\n",
      "       -2.06228480e-01,  3.49509984e-01, -4.48655635e-01,  1.28268754e+00,\n",
      "       -3.81452233e-01,  2.77468038e+00,  2.70629615e-01, -1.19806061e+01,\n",
      "        8.44875526e+00,  3.00457478e-01, -5.70635128e+00, -7.81961232e-02,\n",
      "        4.55931473e+00,  9.36130434e-03,  5.82976267e-03,  1.24159217e-01,\n",
      "        9.53376517e-02,  1.96095026e+00,  4.09664847e-02, -2.78115720e-02,\n",
      "        2.41589594e+00,  5.23378086e+00, -3.57150078e+00,  2.30921912e+00,\n",
      "       -4.40425682e+00,  6.42726851e+00, -2.81477347e-02, -1.76400924e+00,\n",
      "        3.11826289e-01,  4.87475276e-01,  2.44013257e-02, -2.36582994e+00,\n",
      "        1.37059893e-02,  4.08043563e-02, -3.37379813e-01,  1.17186232e+01,\n",
      "       -8.35665226e-01, -6.64453804e-02,  2.42174625e-01,  6.43100217e-02,\n",
      "       -3.00666356e+00, -1.08103588e-01, -8.67795423e-02,  2.18438208e-01,\n",
      "       -2.39588594e+00, -7.70998746e-02, -4.49502230e+00, -5.59132360e-02],\n",
      "      dtype=float32), array([ 14272.226 ,  10756.085 ,   2087.7192,  14274.385 ,   4541.9673,\n",
      "         5702.633 ,   7948.4883,   7182.6807,   2001.775 ,   3389.4915,\n",
      "         1869.7488,  17979.902 ,   4368.896 ,   2548.1165,   2485.772 ,\n",
      "        11395.867 ,   1784.1105,  15631.804 ,   7361.8516,   2615.8691,\n",
      "         1986.809 ,  19388.23  ,   2986.1367, 129535.83  ,  35801.42  ,\n",
      "         2496.9263,  13431.499 ,   5186.005 ,  24213.328 ,   1849.2721,\n",
      "          602.2293,   1631.5251,   3111.5327,   8847.217 ,    597.3861,\n",
      "         1723.8391,   6442.6646,  15918.177 ,  20697.314 ,   9803.098 ,\n",
      "        22586.096 ,  23410.727 ,   2550.7305,   3996.9453,   2208.4446,\n",
      "         3248.7766,   2199.2217,  21569.775 ,   1909.4523,   3690.4656,\n",
      "        17144.828 , 134940.3   ,  18844.012 ,   3577.5046,   5084.374 ,\n",
      "         1779.2256,  12091.138 ,   2657.9497,    592.6989,   6586.3115,\n",
      "         5568.7495,   3113.0737,  25601.816 ,   2491.037 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for i in fusedbatchnorm:\n",
    "    print(fusedbatchnorm[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "df57970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 resnet_model/batch_normalization/FusedBatchNorm (4, 64)\n",
      "3 resnet_model/batch_normalization_1/FusedBatchNorm (4, 256)\n",
      "1 resnet_model/batch_normalization_2/FusedBatchNorm (4, 64)\n",
      "2 resnet_model/batch_normalization_3/FusedBatchNorm (4, 64)\n",
      "4 resnet_model/batch_normalization_4/FusedBatchNorm (4, 256)\n",
      "5 resnet_model/batch_normalization_5/FusedBatchNorm (4, 64)\n",
      "6 resnet_model/batch_normalization_6/FusedBatchNorm (4, 64)\n",
      "7 resnet_model/batch_normalization_7/FusedBatchNorm (4, 256)\n",
      "8 resnet_model/batch_normalization_8/FusedBatchNorm (4, 64)\n",
      "9 resnet_model/batch_normalization_9/FusedBatchNorm (4, 64)\n",
      "10 resnet_model/batch_normalization_10/FusedBatchNorm (4, 256)\n",
      "13 resnet_model/batch_normalization_11/FusedBatchNorm (4, 512)\n",
      "11 resnet_model/batch_normalization_12/FusedBatchNorm (4, 128)\n",
      "12 resnet_model/batch_normalization_13/FusedBatchNorm (4, 128)\n",
      "14 resnet_model/batch_normalization_14/FusedBatchNorm (4, 512)\n",
      "15 resnet_model/batch_normalization_15/FusedBatchNorm (4, 128)\n",
      "16 resnet_model/batch_normalization_16/FusedBatchNorm (4, 128)\n",
      "17 resnet_model/batch_normalization_17/FusedBatchNorm (4, 512)\n",
      "18 resnet_model/batch_normalization_18/FusedBatchNorm (4, 128)\n",
      "19 resnet_model/batch_normalization_19/FusedBatchNorm (4, 128)\n",
      "20 resnet_model/batch_normalization_20/FusedBatchNorm (4, 512)\n",
      "21 resnet_model/batch_normalization_21/FusedBatchNorm (4, 128)\n",
      "22 resnet_model/batch_normalization_22/FusedBatchNorm (4, 128)\n",
      "23 resnet_model/batch_normalization_23/FusedBatchNorm (4, 512)\n",
      "26 resnet_model/batch_normalization_24/FusedBatchNorm (4, 1024)\n",
      "24 resnet_model/batch_normalization_25/FusedBatchNorm (4, 256)\n",
      "25 resnet_model/batch_normalization_26/FusedBatchNorm (4, 256)\n",
      "27 resnet_model/batch_normalization_27/FusedBatchNorm (4, 1024)\n",
      "28 resnet_model/batch_normalization_28/FusedBatchNorm (4, 256)\n",
      "29 resnet_model/batch_normalization_29/FusedBatchNorm (4, 256)\n",
      "30 resnet_model/batch_normalization_30/FusedBatchNorm (4, 1024)\n",
      "31 resnet_model/batch_normalization_31/FusedBatchNorm (4, 256)\n",
      "32 resnet_model/batch_normalization_32/FusedBatchNorm (4, 256)\n",
      "33 resnet_model/batch_normalization_33/FusedBatchNorm (4, 1024)\n",
      "34 resnet_model/batch_normalization_34/FusedBatchNorm (4, 256)\n",
      "35 resnet_model/batch_normalization_35/FusedBatchNorm (4, 256)\n",
      "36 resnet_model/batch_normalization_36/FusedBatchNorm (4, 1024)\n",
      "37 resnet_model/batch_normalization_37/FusedBatchNorm (4, 256)\n",
      "38 resnet_model/batch_normalization_38/FusedBatchNorm (4, 256)\n",
      "39 resnet_model/batch_normalization_39/FusedBatchNorm (4, 1024)\n",
      "40 resnet_model/batch_normalization_40/FusedBatchNorm (4, 256)\n",
      "41 resnet_model/batch_normalization_41/FusedBatchNorm (4, 256)\n",
      "42 resnet_model/batch_normalization_42/FusedBatchNorm (4, 1024)\n",
      "45 resnet_model/batch_normalization_43/FusedBatchNorm (4, 2048)\n",
      "43 resnet_model/batch_normalization_44/FusedBatchNorm (4, 512)\n",
      "44 resnet_model/batch_normalization_45/FusedBatchNorm (4, 512)\n",
      "46 resnet_model/batch_normalization_46/FusedBatchNorm (4, 2048)\n",
      "47 resnet_model/batch_normalization_47/FusedBatchNorm (4, 512)\n",
      "48 resnet_model/batch_normalization_48/FusedBatchNorm (4, 512)\n",
      "49 resnet_model/batch_normalization_49/FusedBatchNorm (4, 2048)\n",
      "50 resnet_model/batch_normalization_50/FusedBatchNorm (4, 512)\n",
      "51 resnet_model/batch_normalization_51/FusedBatchNorm (4, 512)\n",
      "52 resnet_model/batch_normalization_52/FusedBatchNorm (4, 2048)\n"
     ]
    }
   ],
   "source": [
    "fusedbatchnorm_new = {}\n",
    "count = -1\n",
    "replace = {1:3,11:13, 24:26, 43:45}\n",
    "layer_count = [3,13,26,45]\n",
    "for i in fusedbatchnorm:\n",
    "    count += 1\n",
    "    if count in layer_count:\n",
    "        count+=1\n",
    "        print(count, i, np.shape(fusedbatchnorm[i]))\n",
    "        fusedbatchnorm_new[count] = fusedbatchnorm[i]\n",
    "    elif count in replace:\n",
    "        count1 = replace[count]\n",
    "        print(count1, i, np.shape(fusedbatchnorm[i]))\n",
    "        fusedbatchnorm_new[count1] = fusedbatchnorm[i]\n",
    "        del replace[count]\n",
    "        count -= 1\n",
    "    else:\n",
    "        print(count, i, np.shape(fusedbatchnorm[i]))\n",
    "        fusedbatchnorm_new[count] = fusedbatchnorm[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "53139ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 resnet_model/conv2d/Conv2D (7, 7, 3, 64)\n",
      "3 resnet_model/conv2d_1/Conv2D (1, 1, 64, 256)\n",
      "1 resnet_model/conv2d_2/Conv2D (1, 1, 64, 64)\n",
      "2 resnet_model/conv2d_3/Conv2D (3, 3, 64, 64)\n",
      "4 resnet_model/conv2d_4/Conv2D (1, 1, 64, 256)\n",
      "5 resnet_model/conv2d_5/Conv2D (1, 1, 256, 64)\n",
      "6 resnet_model/conv2d_6/Conv2D (3, 3, 64, 64)\n",
      "7 resnet_model/conv2d_7/Conv2D (1, 1, 64, 256)\n",
      "8 resnet_model/conv2d_8/Conv2D (1, 1, 256, 64)\n",
      "9 resnet_model/conv2d_9/Conv2D (3, 3, 64, 64)\n",
      "10 resnet_model/conv2d_10/Conv2D (1, 1, 64, 256)\n",
      "14 resnet_model/conv2d_11/Conv2D (1, 1, 256, 512)\n",
      "11 resnet_model/conv2d_12/Conv2D (1, 1, 256, 128)\n",
      "12 resnet_model/conv2d_13/Conv2D (3, 3, 128, 128)\n",
      "13 resnet_model/conv2d_14/Conv2D (1, 1, 128, 512)\n",
      "15 resnet_model/conv2d_15/Conv2D (1, 1, 512, 128)\n",
      "16 resnet_model/conv2d_16/Conv2D (3, 3, 128, 128)\n",
      "17 resnet_model/conv2d_17/Conv2D (1, 1, 128, 512)\n",
      "18 resnet_model/conv2d_18/Conv2D (1, 1, 512, 128)\n",
      "19 resnet_model/conv2d_19/Conv2D (3, 3, 128, 128)\n",
      "20 resnet_model/conv2d_20/Conv2D (1, 1, 128, 512)\n",
      "21 resnet_model/conv2d_21/Conv2D (1, 1, 512, 128)\n",
      "22 resnet_model/conv2d_22/Conv2D (3, 3, 128, 128)\n",
      "23 resnet_model/conv2d_23/Conv2D (1, 1, 128, 512)\n",
      "27 resnet_model/conv2d_24/Conv2D (1, 1, 512, 1024)\n",
      "24 resnet_model/conv2d_25/Conv2D (1, 1, 512, 256)\n",
      "25 resnet_model/conv2d_26/Conv2D (3, 3, 256, 256)\n",
      "26 resnet_model/conv2d_27/Conv2D (1, 1, 256, 1024)\n",
      "28 resnet_model/conv2d_28/Conv2D (1, 1, 1024, 256)\n",
      "29 resnet_model/conv2d_29/Conv2D (3, 3, 256, 256)\n",
      "30 resnet_model/conv2d_30/Conv2D (1, 1, 256, 1024)\n",
      "31 resnet_model/conv2d_31/Conv2D (1, 1, 1024, 256)\n",
      "32 resnet_model/conv2d_32/Conv2D (3, 3, 256, 256)\n",
      "33 resnet_model/conv2d_33/Conv2D (1, 1, 256, 1024)\n",
      "34 resnet_model/conv2d_34/Conv2D (1, 1, 1024, 256)\n",
      "35 resnet_model/conv2d_35/Conv2D (3, 3, 256, 256)\n",
      "36 resnet_model/conv2d_36/Conv2D (1, 1, 256, 1024)\n",
      "37 resnet_model/conv2d_37/Conv2D (1, 1, 1024, 256)\n",
      "38 resnet_model/conv2d_38/Conv2D (3, 3, 256, 256)\n",
      "39 resnet_model/conv2d_39/Conv2D (1, 1, 256, 1024)\n",
      "40 resnet_model/conv2d_40/Conv2D (1, 1, 1024, 256)\n",
      "41 resnet_model/conv2d_41/Conv2D (3, 3, 256, 256)\n",
      "42 resnet_model/conv2d_42/Conv2D (1, 1, 256, 1024)\n",
      "46 resnet_model/conv2d_43/Conv2D (1, 1, 1024, 2048)\n",
      "43 resnet_model/conv2d_44/Conv2D (1, 1, 1024, 512)\n",
      "44 resnet_model/conv2d_45/Conv2D (3, 3, 512, 512)\n",
      "45 resnet_model/conv2d_46/Conv2D (1, 1, 512, 2048)\n",
      "47 resnet_model/conv2d_47/Conv2D (1, 1, 2048, 512)\n",
      "48 resnet_model/conv2d_48/Conv2D (3, 3, 512, 512)\n",
      "49 resnet_model/conv2d_49/Conv2D (1, 1, 512, 2048)\n",
      "50 resnet_model/conv2d_50/Conv2D (1, 1, 2048, 512)\n",
      "51 resnet_model/conv2d_51/Conv2D (3, 3, 512, 512)\n",
      "52 resnet_model/conv2d_52/Conv2D (1, 1, 512, 2048)\n",
      "53 resnet_model/dense/MatMul (2048, 1001)\n"
     ]
    }
   ],
   "source": [
    "weights_new = {}\n",
    "replace = {1:3,11:14, 24:27, 43:46}\n",
    "layer_count = [3,14,27,46]\n",
    "count = -1\n",
    "for i in weights:\n",
    "    count+=1\n",
    "    if count in layer_count:\n",
    "        count+=1\n",
    "        print(count, i, np.shape(weights[i]))\n",
    "        weights_new[count] = weights[i]\n",
    "    elif count in replace:\n",
    "        count1 = replace[count]\n",
    "        print(count1, i, np.shape(weights[i]))\n",
    "        weights_new[count1] = weights[i]\n",
    "        del replace[count]\n",
    "        count -= 1\n",
    "    else:\n",
    "        print(count, i, np.shape(weights[i]))\n",
    "        weights_new[count] = weights[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6a07d32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 64, 256)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(weights_new[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "61c41ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 resnet_model/dense/BiasAdd (1001,)\n"
     ]
    }
   ],
   "source": [
    "bias_new = {}\n",
    "count = -1\n",
    "for i in biases:\n",
    "    count+=1\n",
    "    print(count, i, np.shape(biases[i]))\n",
    "    bias_new[count] = biases[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3f38e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ff7a126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33093e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_conv [array([[[[ 2.82526277e-02, -1.18737184e-02,  1.51488732e-03, ...,\n",
      "          -1.07003953e-02, -5.27982824e-02, -1.36667420e-03],\n",
      "         [ 5.86827798e-03,  5.04415408e-02,  3.46324709e-03, ...,\n",
      "           1.01423981e-02,  1.39493728e-02,  1.67549420e-02],\n",
      "         [-2.44090753e-03, -4.86173332e-02,  2.69966386e-03, ...,\n",
      "          -3.44439060e-04,  3.48098315e-02,  6.28910400e-03]],\n",
      "\n",
      "        [[ 1.81872323e-02, -7.20698107e-03,  4.80302610e-03, ...,\n",
      "          -7.43396254e-03, -8.56800564e-03,  1.16849300e-02],\n",
      "         [ 1.87554304e-02,  5.12730293e-02,  4.50406177e-03, ...,\n",
      "           1.39413681e-02,  1.26296384e-02, -1.73004344e-02],\n",
      "         [ 1.90453827e-02, -3.87909152e-02,  4.25842637e-03, ...,\n",
      "           2.75742816e-04, -1.27962548e-02, -8.35626759e-03]],\n",
      "\n",
      "        [[ 1.58849321e-02, -1.06073255e-02,  1.30999666e-02, ...,\n",
      "          -2.26797583e-03, -3.98984266e-04,  3.39989027e-04],\n",
      "         [ 3.61421369e-02,  5.02430499e-02,  1.22699486e-02, ...,\n",
      "           1.19910473e-02,  2.02837810e-02, -1.96981970e-02],\n",
      "         [ 2.17959806e-02, -3.86004597e-02,  1.12379901e-02, ...,\n",
      "          -2.07756506e-03, -3.40645364e-03, -3.78638096e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.30153252e-02, -8.60502943e-03,  6.38643000e-03, ...,\n",
      "          -4.49256925e-03,  3.48024699e-03, -1.40979560e-02],\n",
      "         [-9.35578942e-02,  4.61557060e-02,  1.53722311e-03, ...,\n",
      "           1.21013075e-02,  5.05337631e-03,  3.30474339e-02],\n",
      "         [-7.69589692e-02, -3.51354294e-02,  2.22769519e-03, ...,\n",
      "           9.18304977e-06, -1.15465783e-02,  2.29630154e-02]],\n",
      "\n",
      "        [[-4.73558307e-02, -4.07940615e-03,  4.76515992e-03, ...,\n",
      "          -9.73805040e-03, -1.03890402e-02,  1.62366014e-02],\n",
      "         [-1.24100089e-01,  4.78516519e-02, -9.90210217e-04, ...,\n",
      "           1.10340826e-02, -6.77202828e-03,  5.49102016e-02],\n",
      "         [-7.13113099e-02, -2.86470409e-02,  6.20829698e-04, ...,\n",
      "          -2.17762636e-03, -1.58942658e-02,  3.44766974e-02]],\n",
      "\n",
      "        [[ 1.85429510e-02, -1.12518407e-02,  1.12506151e-02, ...,\n",
      "          -1.51338596e-02, -5.66656142e-03, -1.30050071e-02],\n",
      "         [-2.68079005e-02,  3.64737920e-02,  4.55197273e-03, ...,\n",
      "           5.53486776e-03,  1.12653999e-02,  2.46754289e-03],\n",
      "         [ 1.43940765e-02, -3.56382579e-02,  5.08728763e-03, ...,\n",
      "          -7.46753719e-03,  1.61169283e-02,  1.12382937e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 7.99009297e-03, -9.49061289e-03, -4.21846565e-03, ...,\n",
      "          -1.23715792e-02, -3.82804796e-02, -5.90979494e-03],\n",
      "         [-7.68794632e-03,  5.46954982e-02, -1.03303632e-02, ...,\n",
      "           1.40626412e-02,  1.99436247e-02,  2.51518637e-02],\n",
      "         [ 3.70471564e-04, -3.70203964e-02, -9.80611611e-03, ...,\n",
      "          -4.95379185e-03,  2.27415562e-02,  1.38941938e-02]],\n",
      "\n",
      "        [[ 2.48856675e-02, -9.57963988e-03, -2.37837038e-03, ...,\n",
      "          -1.08526833e-02,  2.24138368e-02, -2.40965877e-02],\n",
      "         [ 2.42966190e-02,  4.93442900e-02, -1.32921906e-02, ...,\n",
      "           1.47738317e-02,  2.67323572e-02,  1.14357602e-02],\n",
      "         [ 2.91274227e-02, -3.05654686e-02, -1.42364930e-02, ...,\n",
      "          -8.36174563e-03, -3.00847553e-02, -2.51545687e-03]],\n",
      "\n",
      "        [[ 7.67260045e-02, -1.19650066e-02, -2.10191216e-03, ...,\n",
      "           1.79589365e-03,  2.02653632e-02, -1.33340694e-02],\n",
      "         [ 1.49444759e-01,  5.00719361e-02, -1.52172269e-02, ...,\n",
      "           1.83409695e-02,  1.56401172e-02,  8.53796005e-02],\n",
      "         [ 1.17180273e-01, -2.56576538e-02, -1.85890812e-02, ...,\n",
      "          -2.50462536e-03, -5.22738546e-02,  1.17943510e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.89151186e-02, -1.06457584e-02, -1.19606184e-03, ...,\n",
      "          -7.13960640e-03,  7.56816342e-02,  8.62411484e-02],\n",
      "         [ 1.33888470e-02,  4.24321182e-02, -1.93305630e-02, ...,\n",
      "           8.93499516e-03,  3.26688178e-02,  1.71118364e-01],\n",
      "         [-9.38678440e-03, -2.88689751e-02, -1.87061988e-02, ...,\n",
      "          -1.06920488e-02, -4.56195511e-02,  1.51734307e-01]],\n",
      "\n",
      "        [[-7.93561861e-02, -8.69292021e-03,  1.06180850e-02, ...,\n",
      "          -8.22936464e-03,  5.34521677e-02,  2.43676770e-02],\n",
      "         [-1.76872283e-01,  4.03351039e-02, -6.91946782e-03, ...,\n",
      "           1.14902109e-02,  2.45164465e-02,  1.30252065e-02],\n",
      "         [-1.30214587e-01, -2.94868350e-02, -1.32359739e-03, ...,\n",
      "          -8.08166154e-03, -3.32693383e-02,  1.78283844e-02]],\n",
      "\n",
      "        [[-1.53617216e-02, -1.02823023e-02,  1.44553250e-02, ...,\n",
      "          -1.23689836e-02,  2.81683691e-02, -1.52645903e-02],\n",
      "         [-1.22947149e-01,  3.72432098e-02, -2.82740779e-03, ...,\n",
      "           1.07275983e-02,  1.61965452e-02, -4.08420824e-02],\n",
      "         [-7.92325959e-02, -3.09139602e-02,  1.91061670e-04, ...,\n",
      "          -1.06926244e-02, -1.36199640e-02, -2.90216487e-02]]],\n",
      "\n",
      "\n",
      "       [[[-2.74732877e-02, -1.59629062e-02,  5.87167032e-03, ...,\n",
      "          -1.18064405e-02, -5.19699305e-02, -1.52737210e-02],\n",
      "         [-7.46604949e-02,  5.22083789e-02, -1.98963331e-03, ...,\n",
      "           1.27452025e-02,  7.53643783e-03, -1.96208209e-02],\n",
      "         [-3.34048420e-02, -3.39833461e-02, -1.99538236e-03, ...,\n",
      "          -9.30251833e-03,  3.30174603e-02, -1.65446047e-02]],\n",
      "\n",
      "        [[-6.57535121e-02, -1.23513499e-02, -4.16519074e-03, ...,\n",
      "          -1.22041989e-03,  2.09396798e-02,  3.62350084e-02],\n",
      "         [-1.52494013e-01,  4.94739972e-02, -1.83443855e-02, ...,\n",
      "           2.37025358e-02,  2.67230812e-02,  8.47681686e-02],\n",
      "         [-8.80744159e-02, -2.57136654e-02, -2.17252262e-02, ...,\n",
      "          -3.12197860e-03, -2.06513535e-02,  6.63726628e-02]],\n",
      "\n",
      "        [[ 1.99921392e-02, -1.76080931e-02,  1.81755237e-03, ...,\n",
      "           3.69562432e-02,  3.51557694e-02,  1.03931516e-01],\n",
      "         [ 6.10242449e-02,  4.46803048e-02, -1.41719123e-02, ...,\n",
      "           5.15808910e-02,  2.07974892e-02,  1.46060020e-01],\n",
      "         [ 8.05315524e-02, -2.88072433e-02, -1.85981095e-02, ...,\n",
      "           2.20173039e-02, -5.11762947e-02,  1.40093669e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.15528561e-01, -1.67486407e-02,  8.49904679e-03, ...,\n",
      "           4.99674492e-03,  7.98972845e-02, -1.11083500e-01],\n",
      "         [ 3.32334489e-01,  4.24566194e-02, -9.70878359e-03, ...,\n",
      "           1.92873720e-02,  1.25060824e-03, -3.40990961e-01],\n",
      "         [ 2.16480315e-01, -2.68480480e-02, -8.96557700e-03, ...,\n",
      "          -6.44540135e-03, -7.85448179e-02, -2.04899684e-01]],\n",
      "\n",
      "        [[-8.99803787e-02, -8.51823762e-03,  2.25046948e-02, ...,\n",
      "          -8.74274992e-04,  6.35959804e-02, -9.58404392e-02],\n",
      "         [-8.15074593e-02,  4.37885672e-02,  3.69152403e-03, ...,\n",
      "           1.71142723e-02,  6.33937493e-03, -2.73919165e-01],\n",
      "         [-9.73245725e-02, -2.61962153e-02,  8.95403326e-03, ...,\n",
      "          -7.23934872e-03, -5.64266555e-02, -1.84837982e-01]],\n",
      "\n",
      "        [[-9.46454927e-02, -1.17739988e-02,  2.49665454e-02, ...,\n",
      "          -7.38179125e-03,  3.05740479e-02, -1.17530329e-02],\n",
      "         [-2.11111471e-01,  3.85808311e-02,  5.31885307e-03, ...,\n",
      "           1.61544569e-02,  3.10361455e-03, -8.36645439e-02],\n",
      "         [-1.75075874e-01, -3.21811885e-02,  9.45197884e-03, ...,\n",
      "          -1.05473688e-02, -2.80730613e-02, -6.67640790e-02]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 2.31804699e-02, -1.62718501e-02,  1.22078890e-02, ...,\n",
      "          -1.22131845e-02, -2.02786643e-02, -2.14508991e-03],\n",
      "         [ 2.30488200e-02,  4.41800952e-02,  3.59291583e-03, ...,\n",
      "           1.27932075e-02,  6.47032401e-03, -5.39429188e-02],\n",
      "         [ 2.03978457e-02, -2.67958529e-02,  5.69844292e-03, ...,\n",
      "          -8.20858125e-03,  2.51460597e-02, -3.12512405e-02]],\n",
      "\n",
      "        [[-4.64516319e-02, -1.34653188e-02,  1.61393601e-02, ...,\n",
      "          -2.20572166e-02,  5.05596139e-02,  1.47165358e-03],\n",
      "         [-1.77852944e-01,  4.04180661e-02,  4.32515051e-03, ...,\n",
      "           7.27979047e-03,  1.37663782e-02, -5.00506982e-02],\n",
      "         [-1.09063022e-01, -2.11244933e-02,  6.98045455e-03, ...,\n",
      "          -2.00869981e-02, -6.30094185e-02, -4.20499854e-02]],\n",
      "\n",
      "        [[-1.83006614e-01, -1.79655701e-02,  1.82811301e-02, ...,\n",
      "           1.56401389e-03,  9.29453745e-02,  4.12672907e-02],\n",
      "         [-4.11783189e-01,  3.40776965e-02,  8.74394365e-03, ...,\n",
      "           2.33494844e-02,  1.98237225e-02,  8.06325078e-02],\n",
      "         [-2.76736170e-01, -2.83147153e-02,  1.31541817e-02, ...,\n",
      "          -5.05925808e-03, -8.54580775e-02,  4.26753834e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.36167026e-02, -1.07590063e-02,  2.19804980e-02, ...,\n",
      "          -8.83348845e-03,  1.40453711e-01,  3.20528477e-01],\n",
      "         [ 1.85792699e-01,  3.76442447e-02,  1.02089429e-02, ...,\n",
      "           1.29263047e-02, -3.70457745e-03,  6.66479290e-01],\n",
      "         [ 1.32038444e-01, -2.75047179e-02,  2.28339490e-02, ...,\n",
      "          -1.19996015e-02, -1.22367747e-01,  4.83815670e-01]],\n",
      "\n",
      "        [[ 8.34956467e-02, -9.09057911e-03,  2.50242520e-02, ...,\n",
      "          -1.67011786e-02,  1.20522320e-01,  1.36462688e-01],\n",
      "         [ 2.50555605e-01,  4.07686047e-02,  1.08884834e-02, ...,\n",
      "           7.53540406e-03, -7.55708572e-03,  3.96415204e-01],\n",
      "         [ 1.49690762e-01, -3.11034787e-02,  2.43526250e-02, ...,\n",
      "          -1.65321939e-02, -1.09688722e-01,  2.64446586e-01]],\n",
      "\n",
      "        [[ 3.69576029e-02, -1.27014471e-02,  3.19833457e-02, ...,\n",
      "          -1.48784053e-02,  9.22970548e-02,  6.54868260e-02],\n",
      "         [ 9.63706747e-02,  4.39107306e-02,  1.59802549e-02, ...,\n",
      "           1.22494521e-02,  8.10312852e-03,  1.78935930e-01],\n",
      "         [ 2.95156911e-02, -2.96487771e-02,  2.69996542e-02, ...,\n",
      "          -1.38547905e-02, -7.72434175e-02,  1.32773802e-01]]],\n",
      "\n",
      "\n",
      "       [[[ 4.22548056e-02, -8.30464344e-03,  5.34065207e-03, ...,\n",
      "          -8.06468353e-03, -4.70053628e-02,  4.45614867e-02],\n",
      "         [ 9.77012664e-02,  3.83502319e-02, -5.37837343e-03, ...,\n",
      "           1.17106764e-02, -4.59602941e-03,  6.98771998e-02],\n",
      "         [ 6.38262108e-02, -2.08319575e-02, -1.72756368e-03, ...,\n",
      "          -8.19445588e-03,  4.25621867e-02,  4.83920909e-02]],\n",
      "\n",
      "        [[ 4.59470600e-02, -4.77699284e-03,  7.04339007e-03, ...,\n",
      "          -1.82104297e-02,  3.14848162e-02,  4.64068204e-02],\n",
      "         [ 3.89483608e-02,  3.78783308e-02, -6.85291924e-03, ...,\n",
      "           7.33014196e-03,  3.90656322e-04,  1.52848229e-01],\n",
      "         [ 4.57218140e-02, -1.34090437e-02, -8.30697361e-04, ...,\n",
      "          -1.85202472e-02, -3.45353335e-02,  9.25581828e-02]],\n",
      "\n",
      "        [[-4.66161780e-02, -1.22223441e-02,  9.35023464e-03, ...,\n",
      "          -1.31351836e-02,  6.08736612e-02,  9.18865502e-02],\n",
      "         [-1.92336142e-01,  3.18407975e-02, -1.01881009e-03, ...,\n",
      "           7.55425170e-03, -8.62357323e-04,  2.88297594e-01],\n",
      "         [-1.15666650e-01, -2.35320851e-02,  6.74636895e-03, ...,\n",
      "          -1.94703583e-02, -5.66169359e-02,  1.95824102e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.10239179e-02, -9.81471874e-03,  9.81596112e-03, ...,\n",
      "          -1.36731779e-02,  1.20193027e-01, -1.26708716e-01],\n",
      "         [-3.72992679e-02,  3.05935629e-02, -3.00194928e-03, ...,\n",
      "           8.85152724e-03, -5.07611316e-03, -6.25461042e-02],\n",
      "         [ 7.84674310e-04, -2.91344281e-02,  1.12569630e-02, ...,\n",
      "          -1.38232643e-02, -9.49400812e-02, -8.74437019e-02]],\n",
      "\n",
      "        [[ 3.32221799e-02, -4.22911346e-03,  1.13633750e-02, ...,\n",
      "          -1.41841583e-02,  9.59840789e-02, -1.23203963e-01],\n",
      "         [ 9.95653942e-02,  4.03233357e-02, -4.36036801e-03, ...,\n",
      "           8.42505507e-03, -1.50266392e-02, -1.58158958e-01],\n",
      "         [ 6.55353814e-02, -2.76978761e-02,  1.06595978e-02, ...,\n",
      "          -1.31017175e-02, -9.93799716e-02, -1.52014121e-01]],\n",
      "\n",
      "        [[ 2.50522885e-02, -1.08845932e-02,  1.29567981e-02, ...,\n",
      "          -1.67823900e-02,  6.55406937e-02, -3.34061496e-02],\n",
      "         [ 1.00219429e-01,  4.24924381e-02, -4.06364352e-03, ...,\n",
      "           8.98410939e-03, -1.98677508e-03, -9.19047296e-02],\n",
      "         [ 6.97101504e-02, -3.41515057e-02,  8.97936709e-03, ...,\n",
      "          -1.51484888e-02, -8.06454644e-02, -8.53376985e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 1.46303158e-02, -9.15218703e-03,  5.24803856e-03, ...,\n",
      "          -3.63799883e-03, -5.51798902e-02, -7.19531113e-03],\n",
      "         [ 6.12211153e-02,  2.67034862e-02, -4.38000960e-03, ...,\n",
      "           1.38858845e-02,  1.62421225e-03,  6.91889692e-03],\n",
      "         [ 1.86353922e-02, -2.39325576e-02,  5.56383107e-04, ...,\n",
      "          -6.68733614e-03,  7.36468807e-02,  3.71867418e-02]],\n",
      "\n",
      "        [[ 3.52302976e-02, -3.27857491e-03,  7.14091491e-03, ...,\n",
      "          -9.93822515e-03,  2.38756705e-02, -2.10771449e-02],\n",
      "         [ 6.34438619e-02,  3.12160589e-02, -7.72275496e-03, ...,\n",
      "           1.49217555e-02,  3.86624038e-03, -1.16395289e-02],\n",
      "         [ 3.35849188e-02, -1.63664240e-02, -1.32562651e-03, ...,\n",
      "          -1.30512416e-02, -7.29435496e-03, -1.24825155e-02]],\n",
      "\n",
      "        [[ 4.10873676e-03, -4.66612726e-03,  1.21031692e-02, ...,\n",
      "          -7.87103828e-03,  5.80726229e-02, -4.19587009e-02],\n",
      "         [-2.23153979e-02,  2.99241953e-02,  8.01213668e-04, ...,\n",
      "           1.82199273e-02,  9.57238674e-03, -8.57376456e-02],\n",
      "         [-2.01183017e-02, -1.96383689e-02,  7.32050464e-03, ...,\n",
      "          -1.07293837e-02, -2.17854325e-02, -7.95444921e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.71692297e-02, -3.16392444e-03,  2.40169745e-03, ...,\n",
      "          -9.67177004e-03,  9.26117748e-02, -1.16062798e-02],\n",
      "         [-8.63026828e-02,  3.55335064e-02, -1.06153013e-02, ...,\n",
      "           1.85809545e-02, -2.19932254e-02, -1.47949710e-01],\n",
      "         [-6.07556999e-02, -2.66596545e-02,  1.74473948e-03, ...,\n",
      "          -4.85855900e-03, -8.82942155e-02, -8.43590796e-02]],\n",
      "\n",
      "        [[ 1.15142548e-02,  2.20947526e-03,  5.08834422e-03, ...,\n",
      "          -1.04352133e-02,  6.78158402e-02,  4.14623357e-02],\n",
      "         [ 7.41827395e-03,  4.52373996e-02, -1.10873608e-02, ...,\n",
      "           1.56368576e-02, -2.37460397e-02, -3.25448737e-02],\n",
      "         [ 7.84576032e-03, -2.45320965e-02,  5.84031455e-04, ...,\n",
      "          -8.31448287e-03, -8.92601907e-02, -3.36888898e-03]],\n",
      "\n",
      "        [[ 4.79146978e-03, -4.22942545e-03,  1.15078716e-02, ...,\n",
      "          -2.12721284e-02,  4.96782959e-02,  2.05268860e-02],\n",
      "         [ 2.75192987e-02,  4.36737053e-02, -5.71439136e-03, ...,\n",
      "           9.46100149e-03, -8.58635467e-04, -1.79863740e-02],\n",
      "         [ 2.71184333e-02, -3.31169143e-02,  3.97488568e-03, ...,\n",
      "          -1.41424611e-02, -6.35233149e-02,  1.29984575e-03]]]],\n",
      "      dtype=float32), array([ 1.5829111e-09, -1.9272978e-10,  1.4708530e-10, -3.3394246e-11,\n",
      "       -1.0394472e-09, -2.2981408e-09, -5.2869503e-10, -3.1592794e-11,\n",
      "        1.8323251e-10, -4.9787726e-12,  2.1595645e-09, -1.3711804e-10,\n",
      "       -1.2207793e-09, -1.8223448e-09, -2.4185174e-09, -6.8378503e-10,\n",
      "       -4.4311914e-09,  4.9836388e-09, -3.2121539e-09,  2.0617887e-09,\n",
      "        2.9162595e-09, -3.3172360e-09,  2.6172473e-10,  1.2767545e-10,\n",
      "       -4.1365911e-09,  3.1397021e-10,  9.8183450e-10,  2.9085953e-10,\n",
      "       -2.2326749e-09, -3.5986544e-11,  1.9345316e-09,  2.4486041e-10,\n",
      "       -3.2064138e-09, -4.0993042e-10, -2.3597533e-09,  2.2365207e-10,\n",
      "        5.3403926e-09, -2.1422985e-11,  3.5645006e-10,  2.6985592e-09,\n",
      "        1.2312432e-09, -6.6246014e-10,  2.1508149e-09, -5.1568672e-10,\n",
      "        7.6417521e-09,  3.6630692e-11,  1.2633139e-09,  1.3274220e-09,\n",
      "       -3.3828521e-10,  9.2130364e-10,  1.1556998e-09,  6.8426276e-10,\n",
      "        1.1804819e-09, -1.1490321e-09,  9.6437758e-10,  3.3418340e-10,\n",
      "        2.5392918e-10, -2.4667539e-09, -1.4590341e-09, -3.2370850e-09,\n",
      "        2.3077633e-09,  6.9913663e-12, -1.0832873e-09, -6.6219047e-10],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "count = -1\n",
    "for layer in model.layers:\n",
    "    if len(layer.get_weights())>0:\n",
    "        print(layer.name, layer.get_weights())\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142dd4c",
   "metadata": {},
   "source": [
    "### Resnet50_v1 tf2 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "cb1819e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import flags\n",
    "import tensorflow as tf\n",
    "\n",
    "for name in list(flags.FLAGS):\n",
    "    delattr(flags.FLAGS,name)\n",
    "\n",
    "#import imagenet_preprocessing\n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras import layers as tf_python_keras_layers\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import regularizers\n",
    "\n",
    "_R_MEAN = 123.68\n",
    "_G_MEAN = 116.78\n",
    "_B_MEAN = 103.94\n",
    "CHANNEL_MEANS = [_R_MEAN, _G_MEAN, _B_MEAN]\n",
    "\n",
    "BATCH_NORM_DECAY = 0.9\n",
    "BATCH_NORM_EPSILON = 1e-5\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    'weight_decay',\n",
    "    default=1e-4,\n",
    "    help=('Weight decay coefficiant for l2 regularization.'))\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    'num_accumulation_steps',\n",
    "    default=8,\n",
    "    help=('number of steps to accumulate with large batch size.'))\n",
    "\n",
    "layers = tf_python_keras_layers\n",
    "\n",
    "\n",
    "def change_keras_layer(use_tf_keras_layers=True):\n",
    "    global layers\n",
    "    if use_tf_keras_layers:\n",
    "        layers = tf.keras.layers\n",
    "    else:\n",
    "        layers = tf_python_keras_layers\n",
    "\n",
    "\n",
    "def _gen_l2_regularizer(use_l2_regularizer=True):\n",
    "    return regularizers.l2(FLAGS.weight_decay) if use_l2_regularizer else None\n",
    "\n",
    "\n",
    "def identity_block(input_tensor,\n",
    "                   kernel_size,\n",
    "                   filters,\n",
    "                   stage,\n",
    "                   block,\n",
    "                   use_l2_regularizer=True):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters1, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2a')(\n",
    "          input_tensor)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '2a')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters2,\n",
    "      kernel_size,\n",
    "      padding='same',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2b')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '2b')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2c')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '2c')(\n",
    "          x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Activation('linear')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor,\n",
    "               kernel_size,\n",
    "               filters,\n",
    "               stage,\n",
    "               block,\n",
    "               strides=(2, 2),\n",
    "               use_l2_regularizer=True):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters1, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2a')(\n",
    "          input_tensor)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '2a')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters2,\n",
    "      kernel_size,\n",
    "      strides=strides,\n",
    "      padding='same',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2b')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '2b')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2c')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '2c')(\n",
    "          x)\n",
    "\n",
    "    shortcut = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      strides=strides,\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '1')(\n",
    "          input_tensor)\n",
    "    shortcut = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '1')(\n",
    "          shortcut)\n",
    "\n",
    "    x = layers.add([shortcut,x])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet50(num_classes,\n",
    "             batch_size=None,\n",
    "             use_l2_regularizer=True,\n",
    "             rescale_inputs=False):\n",
    "    input_shape = (224, 224, 3)\n",
    "    img_input = layers.Input(shape=input_shape)\n",
    "    if rescale_inputs:\n",
    "      # Hub image modules expect inputs in the range [0, 1]. This rescales these\n",
    "      # inputs to the range expected by the trained model.\n",
    "        x = layers.Lambda(\n",
    "        lambda x: x * 255.0 - backend.constant(\n",
    "            CHANNEL_MEANS,\n",
    "            shape=[1, 1, 3],\n",
    "            dtype=x.dtype),\n",
    "        name='rescale')(\n",
    "            img_input)\n",
    "    else:\n",
    "        x = img_input\n",
    "\n",
    "    if backend.image_data_format() == 'channels_first':\n",
    "        x = layers.Lambda(\n",
    "        lambda x: backend.permute_dimensions(x, (0, 3, 1, 2)),\n",
    "        name='transpose')(x)\n",
    "        bn_axis = 1\n",
    "    else:  # channels_last\n",
    "        bn_axis = 3\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(x)\n",
    "    x = layers.Conv2D(\n",
    "      64, (7, 7),\n",
    "      strides=(2, 2),\n",
    "      padding='valid',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name='conv1')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name='bn_conv1')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = conv_block(\n",
    "      x,\n",
    "      3, [64, 64, 256],\n",
    "      stage=2,\n",
    "      block='a',\n",
    "      strides=(1, 1),\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [64, 64, 256],\n",
    "      stage=2,\n",
    "      block='b',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [64, 64, 256],\n",
    "      stage=2,\n",
    "      block='c',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "\n",
    "    x = conv_block(\n",
    "      x,\n",
    "      3, [128, 128, 512],\n",
    "      stage=3,\n",
    "      block='a',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [128, 128, 512],\n",
    "      stage=3,\n",
    "      block='b',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [128, 128, 512],\n",
    "      stage=3,\n",
    "      block='c',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [128, 128, 512],\n",
    "      stage=3,\n",
    "      block='d',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "\n",
    "    x = conv_block(\n",
    "      x,\n",
    "      3, [256, 256, 1024],\n",
    "      stage=4,\n",
    "      block='a',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [256, 256, 1024],\n",
    "      stage=4,\n",
    "      block='b',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [256, 256, 1024],\n",
    "      stage=4,\n",
    "      block='c',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [256, 256, 1024],\n",
    "      stage=4,\n",
    "      block='d',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [256, 256, 1024],\n",
    "      stage=4,\n",
    "      block='e',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [256, 256, 1024],\n",
    "      stage=4,\n",
    "      block='f',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "\n",
    "    x = conv_block(\n",
    "      x,\n",
    "      3, [512, 512, 2048],\n",
    "      stage=5,\n",
    "      block='a',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [512, 512, 2048],\n",
    "      stage=5,\n",
    "      block='b',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [512, 512, 2048],\n",
    "      stage=5,\n",
    "      block='c',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "\n",
    "    rm_axes = [1, 2] if backend.image_data_format() == 'channels_last' else [2, 3]\n",
    "    x = layers.Lambda(lambda x: backend.mean(x, rm_axes), name='reduce_mean')(x)\n",
    "    x = layers.Dense(\n",
    "      num_classes,\n",
    "      kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      bias_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name='fc_2')(\n",
    "          x)\n",
    "\n",
    "  # A softmax that is followed by the model loss must be done cannot be done\n",
    "  # in float16 due to numeric issues. So we pass dtype=float32.\n",
    "    x = layers.Activation('softmax', dtype='float32')(x)\n",
    "\n",
    "  # Create model.\n",
    "    return models.Model(img_input, x, name='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "cb196836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(200, batch_size=None, use_l2_regularizer=False, rescale_inputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b95e4c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9408        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 56, 56, 64)   0           activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4096        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36864       activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16384       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16384       activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, 56, 56, 256)  0           bn2a_branch1[0][0]               \n",
      "                                                                 bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 56, 56, 256)  0           add_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16384       activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36864       activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16384       activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_99 (Add)                    (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 56, 56, 256)  0           add_99[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 56, 56, 256)  0           activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16384       activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36864       activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16384       activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_100 (Add)                   (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 56, 56, 256)  0           add_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 56, 56, 256)  0           activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 56, 56, 128)  32768       activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 56, 56, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 56, 56, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147456      activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131072      activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  65536       activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_101 (Add)                   (None, 28, 28, 512)  0           bn3a_branch1[0][0]               \n",
      "                                                                 bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 28, 28, 512)  0           add_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65536       activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147456      activation_335[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  65536       activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_102 (Add)                   (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 28, 28, 512)  0           add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 28, 28, 512)  0           activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65536       activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147456      activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  65536       activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_103 (Add)                   (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 28, 28, 512)  0           add_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 28, 28, 512)  0           activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65536       activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147456      activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  65536       activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_104 (Add)                   (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 28, 28, 512)  0           add_104[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 28, 28, 512)  0           activation_345[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 28, 28, 256)  131072      activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 28, 28, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 28, 28, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  589824      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 524288      activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 262144      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_105 (Add)                   (None, 14, 14, 1024) 0           bn4a_branch1[0][0]               \n",
      "                                                                 bn4a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 14, 14, 1024) 0           add_105[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262144      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  589824      activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 262144      activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_106 (Add)                   (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 14, 14, 1024) 0           add_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_353 (Activation)     (None, 14, 14, 1024) 0           activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262144      activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  589824      activation_354[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_355 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 262144      activation_355[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_107 (Add)                   (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_353[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 14, 14, 1024) 0           add_107[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 14, 14, 1024) 0           activation_356[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262144      activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  589824      activation_358[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 262144      activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_108 (Add)                   (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 14, 14, 1024) 0           add_108[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 14, 14, 1024) 0           activation_360[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262144      activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  589824      activation_362[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 262144      activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_109 (Add)                   (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 14, 14, 1024) 0           add_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 14, 14, 1024) 0           activation_364[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262144      activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  589824      activation_366[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 262144      activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_110 (Add)                   (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 14, 14, 1024) 0           add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 14, 14, 1024) 0           activation_368[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 14, 14, 512)  524288      activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 14, 14, 512)  2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 14, 14, 512)  0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359296     activation_370[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2097152     activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1048576     activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_111 (Add)                   (None, 7, 7, 2048)   0           bn5a_branch1[0][0]               \n",
      "                                                                 bn5a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 7, 7, 2048)   0           add_111[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1048576     activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359296     activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1048576     activation_374[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_112 (Add)                   (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_372[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 7, 7, 2048)   0           add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 7, 7, 2048)   0           activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1048576     activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359296     activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1048576     activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_113 (Add)                   (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 7, 7, 2048)   0           add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 7, 7, 2048)   0           activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reduce_mean (Lambda)            (None, 2048)         0           activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fc_2 (Dense)                    (None, 200)          409800      reduce_mean[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 200)          0           fc_2[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 23,970,952\n",
      "Trainable params: 23,917,832\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "70804859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"resnet50_v1_tf2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0b50f",
   "metadata": {},
   "source": [
    "### Resnet50_v1 tf1  version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c470ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "#from mlperf_compliance import mlperf_log\n",
    "#from mlperf_compliance import resnet_log_helper\n",
    "\n",
    "\n",
    "_BATCH_NORM_DECAY = 0.9\n",
    "_BATCH_NORM_EPSILON = 1e-5\n",
    "DEFAULT_VERSION = 1\n",
    "DEFAULT_DTYPE = tf.float32\n",
    "CASTABLE_TYPES = (tf.float16,)\n",
    "ALLOWED_TYPES = (DEFAULT_DTYPE,) + CASTABLE_TYPES\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Convenience functions for building the ResNet model.\n",
    "################################################################################\n",
    "def batch_norm(inputs, training, data_format):\n",
    "    \"\"\"Performs a batch normalization using a standard set of parameters.\"\"\"\n",
    "    # We set fused=True for a significant performance boost. See\n",
    "    # https://www.tensorflow.org/performance/performance_guide#common_fused_ops\n",
    "    outputs = tf.keras.layers.BatchNormalization(\n",
    "      axis=1 if data_format == 'channels_first' else 3,\n",
    "      momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, center=True,\n",
    "      scale=True, fused=True)(inputs)\n",
    "\n",
    "    #resnet_log_helper.log_batch_norm(\n",
    "      #input_tensor=inputs, output_tensor=outputs, momentum=_BATCH_NORM_DECAY,\n",
    "      #epsilon=_BATCH_NORM_EPSILON, center=True, scale=True, training=training)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, data_format):\n",
    "    \"\"\"Pads the input along the spatial dimensions independently of input size.\n",
    "\n",
    "    Args:\n",
    "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
    "      [batch, height_in, width_in, channels] depending on data_format.\n",
    "    kernel_size: The kernel to be used in the conv2d or max_pool2d operation.\n",
    "                 Should be a positive integer.\n",
    "    data_format: The input format ('channels_last' or 'channels_first').\n",
    "\n",
    "    Returns:\n",
    "     A tensor with the same format as the input with the data either intact\n",
    "    (if kernel_size == 1) or padded (if kernel_size > 1).\n",
    "    \"\"\"\n",
    "    pad_total = kernel_size - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n",
    "                                    [pad_beg, pad_end], [pad_beg, pad_end]])\n",
    "    else:\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
    "                                    [pad_beg, pad_end], [0, 0]])\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "def conv2d_fixed_padding(inputs, filters, kernel_size, strides, data_format):\n",
    "    \"\"\"Strided 2-D convolution with explicit padding.\"\"\"\n",
    "    # The padding is consistent and is based only on `kernel_size`, not on the\n",
    "    # dimensions of `inputs` (as opposed to using `tf.layers.conv2d` alone).\n",
    "\n",
    "    inputs_for_logging = inputs\n",
    "    if strides > 1:\n",
    "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(\n",
    "      filters=filters, kernel_size=kernel_size, strides=strides,\n",
    "      padding=('SAME' if strides == 1 else 'VALID'), use_bias=False,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          distribution=\"truncated_normal\"),\n",
    "      data_format=data_format)(inputs)\n",
    "\n",
    "    #resnet_log_helper.log_conv2d(\n",
    "      #input_tensor=inputs_for_logging, output_tensor=outputs, stride=strides,\n",
    "      #filters=filters, initializer=mlperf_log.TRUNCATED_NORMAL, use_bias=False)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# ResNet block definitions.\n",
    "################################################################################\n",
    "def _building_block_v1(inputs, filters, training, projection_shortcut, strides,\n",
    "                       data_format):\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def _building_block_v2(inputs, filters, training, projection_shortcut, strides,\n",
    "                       data_format):\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def _bottleneck_block_v1(inputs, filters, training, projection_shortcut,\n",
    "                         strides, data_format):\n",
    "    \"\"\"A single block for ResNet v1, with a bottleneck.\n",
    "\n",
    "    Similar to _building_block_v1(), except using the \"bottleneck\" blocks\n",
    "    described in:\n",
    "    Convolution then batch normalization then ReLU as described by:\n",
    "      Deep Residual Learning for Image Recognition\n",
    "      https://arxiv.org/pdf/1512.03385.pdf\n",
    "      by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.\n",
    "\n",
    "    Args:\n",
    "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
    "      [batch, height_in, width_in, channels] depending on data_format.\n",
    "    filters: The number of filters for the convolutions.\n",
    "    training: A Boolean for whether the model is in training or inference\n",
    "      mode. Needed for batch normalization.\n",
    "    projection_shortcut: The function to use for projection shortcuts\n",
    "      (typically a 1x1 convolution when downsampling the input).\n",
    "    strides: The block's stride. If greater than 1, this block will ultimately\n",
    "      downsample the input.\n",
    "    data_format: The input format ('channels_last' or 'channels_first').\n",
    "\n",
    "    Returns:\n",
    "    The output tensor of the block; shape should match inputs.\n",
    "    \"\"\"\n",
    "    #resnet_log_helper.log_begin_block(\n",
    "      #input_tensor=inputs, block_type=mlperf_log.BOTTLENECK_BLOCK)\n",
    "\n",
    "    shortcut = inputs\n",
    "\n",
    "    if projection_shortcut is not None:\n",
    "        shortcut = projection_shortcut(inputs)\n",
    "        #resnet_log_helper.log_projection(input_tensor=inputs,\n",
    "                                    # output_tensor=shortcut)\n",
    "        shortcut = batch_norm(inputs=shortcut, training=training,\n",
    "                          data_format=data_format)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "      inputs=inputs, filters=filters, kernel_size=1, strides=1,\n",
    "      data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training, data_format)\n",
    "\n",
    "    #mlperf_log.resnet_print(key=mlperf_log.MODEL_HP_RELU)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
    "      data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training, data_format)\n",
    "\n",
    "    #mlperf_log.resnet_print(key=mlperf_log.MODEL_HP_RELU)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "      inputs=inputs, filters=4 * filters, kernel_size=1, strides=1,\n",
    "      data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training, data_format)\n",
    "\n",
    "    #mlperf_log.resnet_print(key=mlperf_log.MODEL_HP_SHORTCUT_ADD)\n",
    "    inputs += shortcut\n",
    "\n",
    "    #mlperf_log.resnet_print(key=mlperf_log.MODEL_HP_RELU)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "\n",
    "    #resnet_log_helper.log_end_block(output_tensor=inputs)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def _bottleneck_block_v2(inputs, filters, training, projection_shortcut,\n",
    "                         strides, data_format):\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def block_layer(inputs, filters, bottleneck, block_fn, blocks, strides,\n",
    "                training, name, data_format):\n",
    "    \"\"\"Creates one layer of blocks for the ResNet model.\n",
    "\n",
    "  Args:\n",
    "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
    "      [batch, height_in, width_in, channels] depending on data_format.\n",
    "    filters: The number of filters for the first convolution of the layer.\n",
    "    bottleneck: Is the block created a bottleneck block.\n",
    "    block_fn: The block to use within the model, either `building_block` or\n",
    "      `bottleneck_block`.\n",
    "    blocks: The number of blocks contained in the layer.\n",
    "    strides: The stride to use for the first convolution of the layer. If\n",
    "      greater than 1, this layer will ultimately downsample the input.\n",
    "    training: Either True or False, whether we are currently training the\n",
    "      model. Needed for batch norm.\n",
    "    name: A string name for the tensor output of the block layer.\n",
    "    data_format: The input format ('channels_last' or 'channels_first').\n",
    "\n",
    "  Returns:\n",
    "    The output tensor of the block layer.\n",
    "  \"\"\"\n",
    "\n",
    "    # Bottleneck blocks end with 4x the number of filters as they start with\n",
    "    filters_out = filters * 4 if bottleneck else filters\n",
    "\n",
    "    def projection_shortcut(inputs):\n",
    "        return conv2d_fixed_padding(\n",
    "        inputs=inputs, filters=filters_out, kernel_size=1, strides=strides,\n",
    "        data_format=data_format)\n",
    "\n",
    "    # Only the first block per block_layer uses projection_shortcut and strides\n",
    "    inputs = block_fn(inputs, filters, training, projection_shortcut, strides,\n",
    "                    data_format)\n",
    "\n",
    "    for _ in range(1, blocks):\n",
    "        inputs = block_fn(inputs, filters, training, None, 1, data_format)\n",
    "\n",
    "    return tf.identity(inputs, name)\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "    \"\"\"Base class for building the Resnet Model.\"\"\"\n",
    "\n",
    "    def __init__(self, resnet_size, bottleneck, num_classes, num_filters,\n",
    "               kernel_size,\n",
    "               conv_stride, first_pool_size, first_pool_stride,\n",
    "               second_pool_size, second_pool_stride, block_sizes, block_strides,\n",
    "               final_size, version=DEFAULT_VERSION, data_format='channels_last',\n",
    "               dtype=DEFAULT_DTYPE):\n",
    "        \"\"\"Creates a model for classifying an image.\n",
    "\n",
    "        Args:\n",
    "            resnet_size: A single integer for the size of the ResNet model.\n",
    "            bottleneck: Use regular blocks or bottleneck blocks.\n",
    "            num_classes: The number of classes used as labels.\n",
    "            num_filters: The number of filters to use for the first block layer\n",
    "            of the model. This number is then doubled for each subsequent block\n",
    "            layer.\n",
    "            kernel_size: The kernel size to use for convolution.\n",
    "            conv_stride: stride size for the initial convolutional layer\n",
    "            first_pool_size: Pool size to be used for the first pooling layer.\n",
    "            If none, the first pooling layer is skipped.\n",
    "            first_pool_stride: stride size for the first pooling layer. Not used\n",
    "            if first_pool_size is None.\n",
    "            second_pool_size: Pool size to be used for the second pooling layer.\n",
    "            second_pool_stride: stride size for the final pooling layer\n",
    "            block_sizes: A list containing n values, where n is the number of sets of\n",
    "            block layers desired. Each value should be the number of blocks in the\n",
    "            i-th set.\n",
    "            block_strides: List of integers representing the desired stride size for\n",
    "            each of the sets of block layers. Should be same length as block_sizes.\n",
    "            final_size: The expected size of the model after the second pooling.\n",
    "            version: Integer representing which version of the ResNet network to use.\n",
    "            See README for details. Valid values: [1, 2]\n",
    "            data_format: Input format ('channels_last', 'channels_first', or None).\n",
    "            If set to None, the format is dependent on whether a GPU is available.\n",
    "            dtype: The TensorFlow dtype to use for calculations. If not specified\n",
    "            tf.float32 is used.\n",
    "\n",
    "        Raises:\n",
    "        ValueError: if invalid version is selected.\n",
    "        \"\"\"\n",
    "        self.resnet_size = resnet_size\n",
    "\n",
    "        self.resnet_version = version\n",
    "        if version not in (1, 2):\n",
    "            raise ValueError(\n",
    "          'Resnet version should be 1 or 2. See README for citations.')\n",
    "\n",
    "        self.bottleneck = bottleneck\n",
    "        if bottleneck:\n",
    "            if version == 1:\n",
    "                self.block_fn = _bottleneck_block_v1\n",
    "            else:\n",
    "                self.block_fn = _bottleneck_block_v2\n",
    "        else:\n",
    "            if version == 1:\n",
    "                self.block_fn = _building_block_v1\n",
    "            else:\n",
    "                self.block_fn = _building_block_v2\n",
    "\n",
    "        if dtype not in ALLOWED_TYPES:\n",
    "            raise ValueError('dtype must be one of: {}'.format(ALLOWED_TYPES))\n",
    "            \n",
    "        print(data_format)\n",
    "        self.data_format = data_format\n",
    "        self.num_classes = num_classes\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv_stride = conv_stride\n",
    "        self.first_pool_size = first_pool_size\n",
    "        self.first_pool_stride = first_pool_stride\n",
    "        self.second_pool_size = second_pool_size\n",
    "        self.second_pool_stride = second_pool_stride\n",
    "        self.block_sizes = block_sizes\n",
    "        self.block_strides = block_strides\n",
    "        self.final_size = final_size\n",
    "        self.dtype = dtype\n",
    "        self.pre_activation = version == 2\n",
    "\n",
    "    def _custom_dtype_getter(self, getter, name, shape=None, dtype=DEFAULT_DTYPE,\n",
    "                           *args, **kwargs):\n",
    "        \"\"\"Creates variables in fp32, then casts to fp16 if necessary.\n",
    "\n",
    "    This function is a custom getter. A custom getter is a function with the\n",
    "    same signature as tf.get_variable, except it has an additional getter\n",
    "    parameter. Custom getters can be passed as the `custom_getter` parameter of\n",
    "    tf.variable_scope. Then, tf.get_variable will call the custom getter,\n",
    "    instead of directly getting a variable itself. This can be used to change\n",
    "    the types of variables that are retrieved with tf.get_variable.\n",
    "    The `getter` parameter is the underlying variable getter, that would have\n",
    "    been called if no custom getter was used. Custom getters typically get a\n",
    "    variable with `getter`, then modify it in some way.\n",
    "\n",
    "    This custom getter will create an fp32 variable. If a low precision\n",
    "    (e.g. float16) variable was requested it will then cast the variable to the\n",
    "    requested dtype. The reason we do not directly create variables in low\n",
    "    precision dtypes is that applying small gradients to such variables may\n",
    "    cause the variable not to change.\n",
    "\n",
    "    Args:\n",
    "      getter: The underlying variable getter, that has the same signature as\n",
    "        tf.get_variable and returns a variable.\n",
    "      name: The name of the variable to get.\n",
    "      shape: The shape of the variable to get.\n",
    "      dtype: The dtype of the variable to get. Note that if this is a low\n",
    "        precision dtype, the variable will be created as a tf.float32 variable,\n",
    "        then cast to the appropriate dtype\n",
    "      *args: Additional arguments to pass unmodified to getter.\n",
    "      **kwargs: Additional keyword arguments to pass unmodified to getter.\n",
    "\n",
    "    Returns:\n",
    "      A variable which is cast to fp16 if necessary.\n",
    "    \"\"\"\n",
    "\n",
    "        if dtype in CASTABLE_TYPES:\n",
    "            var = getter(name, shape, tf.float32, *args, **kwargs)\n",
    "            return tf.cast(var, dtype=dtype, name=name + '_cast')\n",
    "        else:\n",
    "            return getter(name, shape, dtype, *args, **kwargs)\n",
    "\n",
    "    def _model_variable_scope(self):\n",
    "        \"\"\"Returns a variable scope that the model should be created under.\n",
    "\n",
    "    If self.dtype is a castable type, model variable will be created in fp32\n",
    "    then cast to self.dtype before being used.\n",
    "\n",
    "    Returns:\n",
    "      A variable scope for the model.\n",
    "    \"\"\"\n",
    "        return tf.compat.v1.variable_scope('resnet_model',\n",
    "                             custom_getter=self._custom_dtype_getter)\n",
    "\n",
    "    def __call__(self, inputs, training):\n",
    "        \"\"\"Add operations to classify a batch of input images.\n",
    "\n",
    "    Args:\n",
    "      inputs: A Tensor representing a batch of input images.\n",
    "      training: A boolean. Set to True to add operations required only when\n",
    "        training the classifier.\n",
    "\n",
    "    Returns:\n",
    "      A logits Tensor with shape [<batch_size>, self.num_classes].\n",
    "    \"\"\"\n",
    "\n",
    "        # Drop batch size from shape logging.\n",
    "        #mlperf_log.resnet_print(key=mlperf_log.MODEL_HP_INITIAL_SHAPE,\n",
    "                            #value=inputs.shape.as_list()[1:])\n",
    "        img_input = inputs\n",
    "        with self._model_variable_scope():\n",
    "            if self.data_format == 'channels_last':\n",
    "                # Convert the inputs from channels_last (NHWC) to channels_first (NCHW).\n",
    "                # This provides a large performance boost on GPU. See\n",
    "                # https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "                #nputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "\n",
    "                inputs = conv2d_fixed_padding(\n",
    "                inputs=inputs, filters=self.num_filters, kernel_size=self.kernel_size,\n",
    "                strides=self.conv_stride, data_format=self.data_format)\n",
    "                inputs = tf.identity(inputs, 'initial_conv')\n",
    "\n",
    "      # We do not include batch normalization or activation functions in V2\n",
    "      # for the initial conv1 because the first ResNet unit will perform these\n",
    "      # for both the shortcut and non-shortcut paths as part of the first\n",
    "      # block's projection. Cf. Appendix of [2].\n",
    "            if self.resnet_version == 1:\n",
    "                inputs = batch_norm(inputs, training, self.data_format)\n",
    "\n",
    "                #mlperf_log.resnet_print(key=mlperf_log.MODEL_HP_RELU)\n",
    "                inputs = tf.nn.relu(inputs)\n",
    "\n",
    "            if self.first_pool_size:\n",
    "                pooled_inputs = tf.keras.layers.MaxPool2D(\n",
    "                pool_size=self.first_pool_size,\n",
    "                strides=self.first_pool_stride, padding='SAME',\n",
    "                data_format=self.data_format)(inputs)\n",
    "                #resnet_log_helper.log_max_pool(input_tensor=inputs, output_tensor=pooled_inputs)\n",
    "                inputs = tf.identity(pooled_inputs, 'initial_max_pool')\n",
    "\n",
    "            for i, num_blocks in enumerate(self.block_sizes):\n",
    "                num_filters = self.num_filters * (2**i)\n",
    "                inputs = block_layer(\n",
    "                inputs=inputs, filters=num_filters, bottleneck=self.bottleneck,\n",
    "                block_fn=self.block_fn, blocks=num_blocks,\n",
    "                strides=self.block_strides[i], training=training,\n",
    "                name='block_layer{}'.format(i + 1), data_format=self.data_format)\n",
    "\n",
    "      # Only apply the BN and ReLU for model that does pre_activation in each\n",
    "      # building/bottleneck block, eg resnet V2.\n",
    "            if self.pre_activation:\n",
    "                inputs = batch_norm(inputs, training, self.data_format)\n",
    "\n",
    "                #mlperf_log.resnet_print(key=mlperf_log.MODEL_HP_RELU)\n",
    "                inputs = tf.nn.relu(inputs)\n",
    "\n",
    "      # The current top layer has shape\n",
    "      # `batch_size x pool_size x pool_size x final_size`.\n",
    "      # ResNet does an Average Pooling layer over pool_size,\n",
    "      # but that is the same as doing a reduce_mean. We do a reduce_mean\n",
    "      # here because it performs better than AveragePooling2D.\n",
    "            axes = [2, 3] if self.data_format == 'channels_first' else [1, 2]\n",
    "            inputs = tf.reduce_mean(inputs, axes, keepdims=True)\n",
    "            inputs = tf.identity(inputs, 'final_reduce_mean')\n",
    "\n",
    "            inputs = tf.reshape(inputs, [-1, self.final_size])\n",
    "            #mlperf_log.resnet_print(key=mlperf_log.MODEL_HP_DENSE,\n",
    "                              #value=self.num_classes)\n",
    "            inputs = tf.keras.layers.Dense(\n",
    "            units=self.num_classes,\n",
    "            kernel_initializer=tf.random_normal_initializer(stddev=.01))(inputs)\n",
    "            output = tf.identity(inputs, 'final_dense')\n",
    "\n",
    "      # Drop batch size from shape logging.\n",
    "            #mlperf_log.resnet_print(key=mlperf_log.MODEL_HP_FINAL_SHAPE,\n",
    "                              #value=inputs.shape.as_list()[1:])\n",
    "            \n",
    "            return models.Model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d77881e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_block_sizes(resnet_size):\n",
    "    \"\"\"Retrieve the size of each block_layer in the ResNet model.\n",
    "    The number of block layers used for the Resnet model varies according\n",
    "    to the size of the model. This helper grabs the layer set we want, throwing\n",
    "    an error if a non-standard size has been selected.\n",
    "    Args:\n",
    "      resnet_size: The number of convolutional layers needed in the model.\n",
    "    Returns:\n",
    "      A list of block sizes to use in building the model.\n",
    "    Raises:\n",
    "      KeyError: if invalid resnet_size is received.\n",
    "    \"\"\"\n",
    "    choices = {\n",
    "      18: [2, 2, 2, 2],\n",
    "      34: [3, 4, 6, 3],\n",
    "      50: [3, 4, 6, 3],\n",
    "      101: [3, 4, 23, 3],\n",
    "      152: [3, 8, 36, 3],\n",
    "      200: [3, 24, 36, 3]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        return choices[resnet_size]\n",
    "    except KeyError:\n",
    "        err = ('Could not find layers for selected Resnet size.\\n'\n",
    "           'Size received: {}; sizes allowed: {}.'.format(\n",
    "               resnet_size, choices.keys()))\n",
    "    raise ValueError(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e49a4520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "model = Model(resnet_size=50, bottleneck=True, num_classes=200, num_filters=64, kernel_size=7, conv_stride=2,\n",
    "        first_pool_size=3, first_pool_stride=2, second_pool_size=7, second_pool_stride=1, \n",
    "        block_sizes=_get_block_sizes(50),\n",
    "        block_strides=[1, 1, 1, 2], final_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8351bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "input_shape = (224, 224, 3)\n",
    "img_input = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "413e6793",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model(inputs=img_input, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "07ca8de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_128 (TFOpLambd (None, 230, 230, 3)  0           input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1123 (Conv2D)            (None, 112, 112, 64) 9408        tf.compat.v1.pad_128[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.identity_174 (TFOpLambda)    (None, 112, 112, 64) 0           conv2d_1123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1119 (Batch (None, 112, 112, 64) 256         tf.identity_174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1032 (TFOpLambda)    (None, 112, 112, 64) 0           batch_normalization_1119[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 56, 56, 64)   0           tf.nn.relu_1032[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.identity_175 (TFOpLambda)    (None, 56, 56, 64)   0           max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1125 (Conv2D)            (None, 56, 56, 64)   4096        tf.identity_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1121 (Batch (None, 56, 56, 64)   256         conv2d_1125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1033 (TFOpLambda)    (None, 56, 56, 64)   0           batch_normalization_1121[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1126 (Conv2D)            (None, 56, 56, 64)   36864       tf.nn.relu_1033[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1122 (Batch (None, 56, 56, 64)   256         conv2d_1126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1034 (TFOpLambda)    (None, 56, 56, 64)   0           batch_normalization_1122[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1127 (Conv2D)            (None, 56, 56, 256)  16384       tf.nn.relu_1034[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1124 (Conv2D)            (None, 56, 56, 256)  16384       tf.identity_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1123 (Batch (None, 56, 56, 256)  1024        conv2d_1127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1120 (Batch (None, 56, 56, 256)  1024        conv2d_1124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_336 (TFOpL (None, 56, 56, 256)  0           batch_normalization_1123[0][0]   \n",
      "                                                                 batch_normalization_1120[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1035 (TFOpLambda)    (None, 56, 56, 256)  0           tf.__operators__.add_336[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1128 (Conv2D)            (None, 56, 56, 64)   16384       tf.nn.relu_1035[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1124 (Batch (None, 56, 56, 64)   256         conv2d_1128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1036 (TFOpLambda)    (None, 56, 56, 64)   0           batch_normalization_1124[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1129 (Conv2D)            (None, 56, 56, 64)   36864       tf.nn.relu_1036[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1125 (Batch (None, 56, 56, 64)   256         conv2d_1129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1037 (TFOpLambda)    (None, 56, 56, 64)   0           batch_normalization_1125[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1130 (Conv2D)            (None, 56, 56, 256)  16384       tf.nn.relu_1037[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1126 (Batch (None, 56, 56, 256)  1024        conv2d_1130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_337 (TFOpL (None, 56, 56, 256)  0           batch_normalization_1126[0][0]   \n",
      "                                                                 tf.nn.relu_1035[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1038 (TFOpLambda)    (None, 56, 56, 256)  0           tf.__operators__.add_337[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1131 (Conv2D)            (None, 56, 56, 64)   16384       tf.nn.relu_1038[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1127 (Batch (None, 56, 56, 64)   256         conv2d_1131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1039 (TFOpLambda)    (None, 56, 56, 64)   0           batch_normalization_1127[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1132 (Conv2D)            (None, 56, 56, 64)   36864       tf.nn.relu_1039[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1128 (Batch (None, 56, 56, 64)   256         conv2d_1132[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1040 (TFOpLambda)    (None, 56, 56, 64)   0           batch_normalization_1128[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1133 (Conv2D)            (None, 56, 56, 256)  16384       tf.nn.relu_1040[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1129 (Batch (None, 56, 56, 256)  1024        conv2d_1133[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_338 (TFOpL (None, 56, 56, 256)  0           batch_normalization_1129[0][0]   \n",
      "                                                                 tf.nn.relu_1038[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1041 (TFOpLambda)    (None, 56, 56, 256)  0           tf.__operators__.add_338[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.identity_176 (TFOpLambda)    (None, 56, 56, 256)  0           tf.nn.relu_1041[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1135 (Conv2D)            (None, 56, 56, 128)  32768       tf.identity_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1131 (Batch (None, 56, 56, 128)  512         conv2d_1135[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1042 (TFOpLambda)    (None, 56, 56, 128)  0           batch_normalization_1131[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1136 (Conv2D)            (None, 56, 56, 128)  147456      tf.nn.relu_1042[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1132 (Batch (None, 56, 56, 128)  512         conv2d_1136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1043 (TFOpLambda)    (None, 56, 56, 128)  0           batch_normalization_1132[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1137 (Conv2D)            (None, 56, 56, 512)  65536       tf.nn.relu_1043[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1134 (Conv2D)            (None, 56, 56, 512)  131072      tf.identity_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1133 (Batch (None, 56, 56, 512)  2048        conv2d_1137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1130 (Batch (None, 56, 56, 512)  2048        conv2d_1134[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_339 (TFOpL (None, 56, 56, 512)  0           batch_normalization_1133[0][0]   \n",
      "                                                                 batch_normalization_1130[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1044 (TFOpLambda)    (None, 56, 56, 512)  0           tf.__operators__.add_339[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1138 (Conv2D)            (None, 56, 56, 128)  65536       tf.nn.relu_1044[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1134 (Batch (None, 56, 56, 128)  512         conv2d_1138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1045 (TFOpLambda)    (None, 56, 56, 128)  0           batch_normalization_1134[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1139 (Conv2D)            (None, 56, 56, 128)  147456      tf.nn.relu_1045[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1135 (Batch (None, 56, 56, 128)  512         conv2d_1139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1046 (TFOpLambda)    (None, 56, 56, 128)  0           batch_normalization_1135[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1140 (Conv2D)            (None, 56, 56, 512)  65536       tf.nn.relu_1046[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1136 (Batch (None, 56, 56, 512)  2048        conv2d_1140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_340 (TFOpL (None, 56, 56, 512)  0           batch_normalization_1136[0][0]   \n",
      "                                                                 tf.nn.relu_1044[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1047 (TFOpLambda)    (None, 56, 56, 512)  0           tf.__operators__.add_340[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1141 (Conv2D)            (None, 56, 56, 128)  65536       tf.nn.relu_1047[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1137 (Batch (None, 56, 56, 128)  512         conv2d_1141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1048 (TFOpLambda)    (None, 56, 56, 128)  0           batch_normalization_1137[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1142 (Conv2D)            (None, 56, 56, 128)  147456      tf.nn.relu_1048[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1138 (Batch (None, 56, 56, 128)  512         conv2d_1142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1049 (TFOpLambda)    (None, 56, 56, 128)  0           batch_normalization_1138[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1143 (Conv2D)            (None, 56, 56, 512)  65536       tf.nn.relu_1049[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1139 (Batch (None, 56, 56, 512)  2048        conv2d_1143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_341 (TFOpL (None, 56, 56, 512)  0           batch_normalization_1139[0][0]   \n",
      "                                                                 tf.nn.relu_1047[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1050 (TFOpLambda)    (None, 56, 56, 512)  0           tf.__operators__.add_341[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1144 (Conv2D)            (None, 56, 56, 128)  65536       tf.nn.relu_1050[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1140 (Batch (None, 56, 56, 128)  512         conv2d_1144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1051 (TFOpLambda)    (None, 56, 56, 128)  0           batch_normalization_1140[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1145 (Conv2D)            (None, 56, 56, 128)  147456      tf.nn.relu_1051[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1141 (Batch (None, 56, 56, 128)  512         conv2d_1145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1052 (TFOpLambda)    (None, 56, 56, 128)  0           batch_normalization_1141[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1146 (Conv2D)            (None, 56, 56, 512)  65536       tf.nn.relu_1052[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1142 (Batch (None, 56, 56, 512)  2048        conv2d_1146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_342 (TFOpL (None, 56, 56, 512)  0           batch_normalization_1142[0][0]   \n",
      "                                                                 tf.nn.relu_1050[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1053 (TFOpLambda)    (None, 56, 56, 512)  0           tf.__operators__.add_342[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.identity_177 (TFOpLambda)    (None, 56, 56, 512)  0           tf.nn.relu_1053[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1148 (Conv2D)            (None, 56, 56, 256)  131072      tf.identity_177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1144 (Batch (None, 56, 56, 256)  1024        conv2d_1148[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1054 (TFOpLambda)    (None, 56, 56, 256)  0           batch_normalization_1144[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1149 (Conv2D)            (None, 56, 56, 256)  589824      tf.nn.relu_1054[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1145 (Batch (None, 56, 56, 256)  1024        conv2d_1149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1055 (TFOpLambda)    (None, 56, 56, 256)  0           batch_normalization_1145[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1150 (Conv2D)            (None, 56, 56, 1024) 262144      tf.nn.relu_1055[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1147 (Conv2D)            (None, 56, 56, 1024) 524288      tf.identity_177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1146 (Batch (None, 56, 56, 1024) 4096        conv2d_1150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1143 (Batch (None, 56, 56, 1024) 4096        conv2d_1147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_343 (TFOpL (None, 56, 56, 1024) 0           batch_normalization_1146[0][0]   \n",
      "                                                                 batch_normalization_1143[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1056 (TFOpLambda)    (None, 56, 56, 1024) 0           tf.__operators__.add_343[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1151 (Conv2D)            (None, 56, 56, 256)  262144      tf.nn.relu_1056[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1147 (Batch (None, 56, 56, 256)  1024        conv2d_1151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1057 (TFOpLambda)    (None, 56, 56, 256)  0           batch_normalization_1147[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1152 (Conv2D)            (None, 56, 56, 256)  589824      tf.nn.relu_1057[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1148 (Batch (None, 56, 56, 256)  1024        conv2d_1152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1058 (TFOpLambda)    (None, 56, 56, 256)  0           batch_normalization_1148[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1153 (Conv2D)            (None, 56, 56, 1024) 262144      tf.nn.relu_1058[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1149 (Batch (None, 56, 56, 1024) 4096        conv2d_1153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_344 (TFOpL (None, 56, 56, 1024) 0           batch_normalization_1149[0][0]   \n",
      "                                                                 tf.nn.relu_1056[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1059 (TFOpLambda)    (None, 56, 56, 1024) 0           tf.__operators__.add_344[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1154 (Conv2D)            (None, 56, 56, 256)  262144      tf.nn.relu_1059[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1150 (Batch (None, 56, 56, 256)  1024        conv2d_1154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1060 (TFOpLambda)    (None, 56, 56, 256)  0           batch_normalization_1150[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1155 (Conv2D)            (None, 56, 56, 256)  589824      tf.nn.relu_1060[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1151 (Batch (None, 56, 56, 256)  1024        conv2d_1155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1061 (TFOpLambda)    (None, 56, 56, 256)  0           batch_normalization_1151[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1156 (Conv2D)            (None, 56, 56, 1024) 262144      tf.nn.relu_1061[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1152 (Batch (None, 56, 56, 1024) 4096        conv2d_1156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_345 (TFOpL (None, 56, 56, 1024) 0           batch_normalization_1152[0][0]   \n",
      "                                                                 tf.nn.relu_1059[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1062 (TFOpLambda)    (None, 56, 56, 1024) 0           tf.__operators__.add_345[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1157 (Conv2D)            (None, 56, 56, 256)  262144      tf.nn.relu_1062[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1153 (Batch (None, 56, 56, 256)  1024        conv2d_1157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1063 (TFOpLambda)    (None, 56, 56, 256)  0           batch_normalization_1153[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1158 (Conv2D)            (None, 56, 56, 256)  589824      tf.nn.relu_1063[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1154 (Batch (None, 56, 56, 256)  1024        conv2d_1158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1064 (TFOpLambda)    (None, 56, 56, 256)  0           batch_normalization_1154[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1159 (Conv2D)            (None, 56, 56, 1024) 262144      tf.nn.relu_1064[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1155 (Batch (None, 56, 56, 1024) 4096        conv2d_1159[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_346 (TFOpL (None, 56, 56, 1024) 0           batch_normalization_1155[0][0]   \n",
      "                                                                 tf.nn.relu_1062[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1065 (TFOpLambda)    (None, 56, 56, 1024) 0           tf.__operators__.add_346[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1160 (Conv2D)            (None, 56, 56, 256)  262144      tf.nn.relu_1065[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1156 (Batch (None, 56, 56, 256)  1024        conv2d_1160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1066 (TFOpLambda)    (None, 56, 56, 256)  0           batch_normalization_1156[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1161 (Conv2D)            (None, 56, 56, 256)  589824      tf.nn.relu_1066[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1157 (Batch (None, 56, 56, 256)  1024        conv2d_1161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1067 (TFOpLambda)    (None, 56, 56, 256)  0           batch_normalization_1157[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1162 (Conv2D)            (None, 56, 56, 1024) 262144      tf.nn.relu_1067[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1158 (Batch (None, 56, 56, 1024) 4096        conv2d_1162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_347 (TFOpL (None, 56, 56, 1024) 0           batch_normalization_1158[0][0]   \n",
      "                                                                 tf.nn.relu_1065[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1068 (TFOpLambda)    (None, 56, 56, 1024) 0           tf.__operators__.add_347[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1163 (Conv2D)            (None, 56, 56, 256)  262144      tf.nn.relu_1068[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1159 (Batch (None, 56, 56, 256)  1024        conv2d_1163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1069 (TFOpLambda)    (None, 56, 56, 256)  0           batch_normalization_1159[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1164 (Conv2D)            (None, 56, 56, 256)  589824      tf.nn.relu_1069[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1160 (Batch (None, 56, 56, 256)  1024        conv2d_1164[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1070 (TFOpLambda)    (None, 56, 56, 256)  0           batch_normalization_1160[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1165 (Conv2D)            (None, 56, 56, 1024) 262144      tf.nn.relu_1070[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1161 (Batch (None, 56, 56, 1024) 4096        conv2d_1165[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_348 (TFOpL (None, 56, 56, 1024) 0           batch_normalization_1161[0][0]   \n",
      "                                                                 tf.nn.relu_1068[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1071 (TFOpLambda)    (None, 56, 56, 1024) 0           tf.__operators__.add_348[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.identity_178 (TFOpLambda)    (None, 56, 56, 1024) 0           tf.nn.relu_1071[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1167 (Conv2D)            (None, 56, 56, 512)  524288      tf.identity_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1163 (Batch (None, 56, 56, 512)  2048        conv2d_1167[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1072 (TFOpLambda)    (None, 56, 56, 512)  0           batch_normalization_1163[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_130 (TFOpLambd (None, 58, 58, 512)  0           tf.nn.relu_1072[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1168 (Conv2D)            (None, 28, 28, 512)  2359296     tf.compat.v1.pad_130[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1164 (Batch (None, 28, 28, 512)  2048        conv2d_1168[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1073 (TFOpLambda)    (None, 28, 28, 512)  0           batch_normalization_1164[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.pad_129 (TFOpLambd (None, 56, 56, 1024) 0           tf.identity_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1169 (Conv2D)            (None, 28, 28, 2048) 1048576     tf.nn.relu_1073[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1166 (Conv2D)            (None, 28, 28, 2048) 2097152     tf.compat.v1.pad_129[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1165 (Batch (None, 28, 28, 2048) 8192        conv2d_1169[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1162 (Batch (None, 28, 28, 2048) 8192        conv2d_1166[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_349 (TFOpL (None, 28, 28, 2048) 0           batch_normalization_1165[0][0]   \n",
      "                                                                 batch_normalization_1162[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1074 (TFOpLambda)    (None, 28, 28, 2048) 0           tf.__operators__.add_349[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1170 (Conv2D)            (None, 28, 28, 512)  1048576     tf.nn.relu_1074[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1166 (Batch (None, 28, 28, 512)  2048        conv2d_1170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1075 (TFOpLambda)    (None, 28, 28, 512)  0           batch_normalization_1166[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1171 (Conv2D)            (None, 28, 28, 512)  2359296     tf.nn.relu_1075[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1167 (Batch (None, 28, 28, 512)  2048        conv2d_1171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1076 (TFOpLambda)    (None, 28, 28, 512)  0           batch_normalization_1167[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1172 (Conv2D)            (None, 28, 28, 2048) 1048576     tf.nn.relu_1076[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1168 (Batch (None, 28, 28, 2048) 8192        conv2d_1172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_350 (TFOpL (None, 28, 28, 2048) 0           batch_normalization_1168[0][0]   \n",
      "                                                                 tf.nn.relu_1074[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1077 (TFOpLambda)    (None, 28, 28, 2048) 0           tf.__operators__.add_350[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1173 (Conv2D)            (None, 28, 28, 512)  1048576     tf.nn.relu_1077[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1169 (Batch (None, 28, 28, 512)  2048        conv2d_1173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1078 (TFOpLambda)    (None, 28, 28, 512)  0           batch_normalization_1169[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1174 (Conv2D)            (None, 28, 28, 512)  2359296     tf.nn.relu_1078[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1170 (Batch (None, 28, 28, 512)  2048        conv2d_1174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1079 (TFOpLambda)    (None, 28, 28, 512)  0           batch_normalization_1170[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1175 (Conv2D)            (None, 28, 28, 2048) 1048576     tf.nn.relu_1079[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1171 (Batch (None, 28, 28, 2048) 8192        conv2d_1175[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_351 (TFOpL (None, 28, 28, 2048) 0           batch_normalization_1171[0][0]   \n",
      "                                                                 tf.nn.relu_1077[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1080 (TFOpLambda)    (None, 28, 28, 2048) 0           tf.__operators__.add_351[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.identity_179 (TFOpLambda)    (None, 28, 28, 2048) 0           tf.nn.relu_1080[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_20 (TFOpLam (None, 1, 1, 2048)   0           tf.identity_179[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.identity_180 (TFOpLambda)    (None, 1, 1, 2048)   0           tf.math.reduce_mean_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_20 (TFOpLambda)      (None, 2048)         0           tf.identity_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 200)          409800      tf.reshape_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.identity_181 (TFOpLambda)    (None, 200)          0           dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,970,952\n",
      "Trainable params: 23,917,832\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7ba982e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model1.save(\"renet50_v1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a292fa",
   "metadata": {},
   "source": [
    "### Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c53ab969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "model = ResNet50()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2c459090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"resnet50.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
